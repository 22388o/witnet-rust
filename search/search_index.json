{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Witnet-rust \u00b6 Witnet-rust is an open-source implementation of the Witnet protocol written in Rust . The Witnet protocol, as outlined by the Witnet Whitepaper , allows a network of computers to act as a \"decentralized oracle\" that retrieves, attests and delivers information to smart contracts in a tamper-resistant way. This Decentralized Oracle Network (DON) maintains and distributes a block chain data structure that serves as a common ledger for the operation of the protocol as well as for the wit token, which is central for incentivizing the network players to abide by the protocol and make them liable for any misbehavior. Active network participants earn wit tokens for fulfilling the data retrieval, attestation and delivery tasks coming from different smart contract platforms such as Ethereum . Witnet-rust is the first open-source implementation of the Witnet protocol and leverages the Rust programming language to achieve utmost speed, memory safety and fearless concurrency without compromising on performance. Tip See \" Why Rust? \" for a more technical overview on why we chose Rust. Get started \u00b6 Installation \u00b6 Witnet-rust is an open-source native app providing \"full node\" functionality of the Witnet Decentralized Oracle Network protocol. It is available under the GNU General Public License v3.0 . We have installation guides for several operating systems: Installing Witnet-rust on GNU/Linux Installing Witnet-rust on macOS Installing Witnet-rust on Windows Compiling Witnet-rust on from source code Roadmap \u00b6 Witnet-rust is an ambitious effort in its early days. We are currently working towards launching our first testnet. As you can guess from our datailed roadmap and GitHub issues , there are still a lot of missing features (and a whole lot more that would be nice to have yet not critical for our testnet launch). Contributing \u00b6 See the contributing guide to get more information on how to contribute to Rust-witnet development, and the roadmap to find out what features are coming soon.","title":"Home"},{"location":"#witnet-rust","text":"Witnet-rust is an open-source implementation of the Witnet protocol written in Rust . The Witnet protocol, as outlined by the Witnet Whitepaper , allows a network of computers to act as a \"decentralized oracle\" that retrieves, attests and delivers information to smart contracts in a tamper-resistant way. This Decentralized Oracle Network (DON) maintains and distributes a block chain data structure that serves as a common ledger for the operation of the protocol as well as for the wit token, which is central for incentivizing the network players to abide by the protocol and make them liable for any misbehavior. Active network participants earn wit tokens for fulfilling the data retrieval, attestation and delivery tasks coming from different smart contract platforms such as Ethereum . Witnet-rust is the first open-source implementation of the Witnet protocol and leverages the Rust programming language to achieve utmost speed, memory safety and fearless concurrency without compromising on performance. Tip See \" Why Rust? \" for a more technical overview on why we chose Rust.","title":"Witnet-rust"},{"location":"#get-started","text":"","title":"Get started"},{"location":"#installation","text":"Witnet-rust is an open-source native app providing \"full node\" functionality of the Witnet Decentralized Oracle Network protocol. It is available under the GNU General Public License v3.0 . We have installation guides for several operating systems: Installing Witnet-rust on GNU/Linux Installing Witnet-rust on macOS Installing Witnet-rust on Windows Compiling Witnet-rust on from source code","title":"Installation"},{"location":"#roadmap","text":"Witnet-rust is an ambitious effort in its early days. We are currently working towards launching our first testnet. As you can guess from our datailed roadmap and GitHub issues , there are still a lot of missing features (and a whole lot more that would be nice to have yet not critical for our testnet launch).","title":"Roadmap"},{"location":"#contributing","text":"See the contributing guide to get more information on how to contribute to Rust-witnet development, and the roadmap to find out what features are coming soon.","title":"Contributing"},{"location":"contributing/","text":"Contributing to Witnet-rust \u00b6 Thank you for being interested in contributing to Witnet! The following is a set of guidelines and helpful pointers for contributing to Witnet The keyword here is guidelines, not rules. As such, use your best judgement and feel free to propose changes to even this document. Code of conduct \u00b6 Everyone participating in this project is governed by the Witnet Code of Conduct . By participating, you are expected to uphold this code as well. I just have a question \u00b6 Please don't file an issue with questions. It's easier for you and for us if you go directly to our Gitter chatroom , since it will keep our repositories clean and you will get a faster response. How can I contribute? \u00b6 Find an area you can help with and do it. Open source is about collaboration and open participation. Try to make your code look like what already exists and submit a pull request. The list of issues is a good place to start, especially the ones tagged as \"good first issue\" or \"help wanted\" (but don't let that stop you from looking at others). If you're looking for additional ideas, the code includes TODO comments for minor to major improvements. Grep is your friend. Additional tests are rewarded with an immense amount of positive karma. More documentation or updates/fixes to existing documentation are also very welcome. However, if submitting a PR consisting of documentation changes only, please try to ensure that the change is significantly more substantial than one or two lines. For example, working through an install document and making changes and updates throughout as you find issues is worth a PR. For typos and other small changes, either contact one of the developers, or if you think it's a significant enough error to cause problems for other users, please feel free to open an issue. Reporting bugs \u00b6 This section guides you through submitting a bug report. This helps contributors and maintainers understand your report, reproduce the behavior, and in turn squash the bug. Before submitting a bug report, please make sure that you've searched through the issues and that there isn't already an issue describing the same issue you are having. How do I submit a good bug report? \u00b6 Bugs are tracked as GitHub issues . Explain the problem and include additional details to help maintainers reproduce the problem: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps. Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. If you're providing snippets in the issue, use Markdown code blocks. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Post a screenshot or a dump of the developer console If the problem wasn't triggered by a specific action, describe what you were doing before the problem happened and share more information using the guidelines below. Provide more context by answering these questions: Did the problem start happening recently (e.g. after updating to a new version) or was this always a problem? If the problem started happening recently, can you reproduce the problem in an older version of Witnet-rust? What's the most recent version in which the problem doesn't happen? Can you reliably reproduce the issue? If not, provide details about how often the problem happens and under which conditions it normally happens. Include details about your configuration and environment: Which version of rustc are you using? You can get the exact version by running rustc --version --verbose in your terminal. What's your operating system and version? Suggesting enhancements \u00b6 This section guides you through submitting an enhancement suggestion, including completely new features and minor improvements to existing functionality. Following these guidelines helps maintainers and the community understand your suggestion. Before creating enhancement suggestions, please double check that there is not already an existing feature suggestion for your feature, as you might find out that you don't need to create one. When you are creating an enhancement suggestion, please include as many details as possible. How Do I Submit A Good Enhancement Suggestion? \u00b6 Enhancement suggestions are tracked as GitHub issues. Create an issue on that repository and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps. Include copy/pasteable snippets which you use in those examples, as Markdown code blocks. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users and isn't something that can or should be implemented as a community package. Your First Code Contribution \u00b6 Unsure where to begin contributing? You can start by looking through these good first issue issues: Good first issue - issues which should only require a few lines of code, and a test or two. Copyright \u00b6 These guidelines are inspired by: AragonJS Contributing Guidelines , published under the Creative Commons Zero v1.0 Universal License . Grin Contributing Guide , published under the Apache License 2.0 .","title":"Contributing"},{"location":"contributing/#contributing-to-witnet-rust","text":"Thank you for being interested in contributing to Witnet! The following is a set of guidelines and helpful pointers for contributing to Witnet The keyword here is guidelines, not rules. As such, use your best judgement and feel free to propose changes to even this document.","title":"Contributing to Witnet-rust"},{"location":"contributing/#code-of-conduct","text":"Everyone participating in this project is governed by the Witnet Code of Conduct . By participating, you are expected to uphold this code as well.","title":"Code of conduct"},{"location":"contributing/#i-just-have-a-question","text":"Please don't file an issue with questions. It's easier for you and for us if you go directly to our Gitter chatroom , since it will keep our repositories clean and you will get a faster response.","title":"I just have a question"},{"location":"contributing/#how-can-i-contribute","text":"Find an area you can help with and do it. Open source is about collaboration and open participation. Try to make your code look like what already exists and submit a pull request. The list of issues is a good place to start, especially the ones tagged as \"good first issue\" or \"help wanted\" (but don't let that stop you from looking at others). If you're looking for additional ideas, the code includes TODO comments for minor to major improvements. Grep is your friend. Additional tests are rewarded with an immense amount of positive karma. More documentation or updates/fixes to existing documentation are also very welcome. However, if submitting a PR consisting of documentation changes only, please try to ensure that the change is significantly more substantial than one or two lines. For example, working through an install document and making changes and updates throughout as you find issues is worth a PR. For typos and other small changes, either contact one of the developers, or if you think it's a significant enough error to cause problems for other users, please feel free to open an issue.","title":"How can I contribute?"},{"location":"contributing/#reporting-bugs","text":"This section guides you through submitting a bug report. This helps contributors and maintainers understand your report, reproduce the behavior, and in turn squash the bug. Before submitting a bug report, please make sure that you've searched through the issues and that there isn't already an issue describing the same issue you are having.","title":"Reporting bugs"},{"location":"contributing/#how-do-i-submit-a-good-bug-report","text":"Bugs are tracked as GitHub issues . Explain the problem and include additional details to help maintainers reproduce the problem: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps. Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. If you're providing snippets in the issue, use Markdown code blocks. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Post a screenshot or a dump of the developer console If the problem wasn't triggered by a specific action, describe what you were doing before the problem happened and share more information using the guidelines below. Provide more context by answering these questions: Did the problem start happening recently (e.g. after updating to a new version) or was this always a problem? If the problem started happening recently, can you reproduce the problem in an older version of Witnet-rust? What's the most recent version in which the problem doesn't happen? Can you reliably reproduce the issue? If not, provide details about how often the problem happens and under which conditions it normally happens. Include details about your configuration and environment: Which version of rustc are you using? You can get the exact version by running rustc --version --verbose in your terminal. What's your operating system and version?","title":"How do I submit a good bug report?"},{"location":"contributing/#suggesting-enhancements","text":"This section guides you through submitting an enhancement suggestion, including completely new features and minor improvements to existing functionality. Following these guidelines helps maintainers and the community understand your suggestion. Before creating enhancement suggestions, please double check that there is not already an existing feature suggestion for your feature, as you might find out that you don't need to create one. When you are creating an enhancement suggestion, please include as many details as possible.","title":"Suggesting enhancements"},{"location":"contributing/#how-do-i-submit-a-good-enhancement-suggestion","text":"Enhancement suggestions are tracked as GitHub issues. Create an issue on that repository and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps. Include copy/pasteable snippets which you use in those examples, as Markdown code blocks. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users and isn't something that can or should be implemented as a community package.","title":"How Do I Submit A Good Enhancement Suggestion?"},{"location":"contributing/#your-first-code-contribution","text":"Unsure where to begin contributing? You can start by looking through these good first issue issues: Good first issue - issues which should only require a few lines of code, and a test or two.","title":"Your First Code Contribution"},{"location":"contributing/#copyright","text":"These guidelines are inspired by: AragonJS Contributing Guidelines , published under the Creative Commons Zero v1.0 Universal License . Grin Contributing Guide , published under the Apache License 2.0 .","title":"Copyright"},{"location":"development/","text":"Development \u00b6 witnet-rust is built using The Rust Programming language and following the Rust 2018 Edition Guide as its code styling convention. Installing \u00b6 We have installation guides for several operating systems: Installing Witnet-rust on GNU/Linux Installing Witnet-rust on macOS Installing Witnet-rust on Windows Compiling Witnet-rust on from source code Running the CLI \u00b6 Synopsis \u00b6 RUST_LOG=witnet=[error | info | debug | main | trace] cargo run \\ [node [ --address address] [--config config_filename]] Components \u00b6 Node \u00b6 --address <address> -d <address> Read server address from <address> argument. --config <file_path> -c <file_path> Read configuration from the given <file_path> argument (defaults to ./witnet.toml ). Development Scripts \u00b6 There are some useful scripts to run with the just tool: clippy : run clippy style checking. docs-build : compile docs into static files. docs-deploy : deploy compiled docs into gh-pages branch. docs-dev : run local documentation server at localhost : 8000 . fmt : run code formatter. install-clippy : install clippy library. install-rustfmt : install rustfmt library. install-setup : install dev tools ( clippy and rustfmt ). server : run witnet server component. travis : run travis build. Installing the just tool just is a command runner tool widely used in the Rust ecosystem. You can install it with a single line: cargo install just","title":"Development"},{"location":"development/#development","text":"witnet-rust is built using The Rust Programming language and following the Rust 2018 Edition Guide as its code styling convention.","title":"Development"},{"location":"development/#installing","text":"We have installation guides for several operating systems: Installing Witnet-rust on GNU/Linux Installing Witnet-rust on macOS Installing Witnet-rust on Windows Compiling Witnet-rust on from source code","title":"Installing"},{"location":"development/#running-the-cli","text":"","title":"Running the CLI"},{"location":"development/#synopsis","text":"RUST_LOG=witnet=[error | info | debug | main | trace] cargo run \\ [node [ --address address] [--config config_filename]]","title":"Synopsis"},{"location":"development/#components","text":"","title":"Components"},{"location":"development/#node","text":"--address <address> -d <address> Read server address from <address> argument. --config <file_path> -c <file_path> Read configuration from the given <file_path> argument (defaults to ./witnet.toml ).","title":"Node"},{"location":"development/#development-scripts","text":"There are some useful scripts to run with the just tool: clippy : run clippy style checking. docs-build : compile docs into static files. docs-deploy : deploy compiled docs into gh-pages branch. docs-dev : run local documentation server at localhost : 8000 . fmt : run code formatter. install-clippy : install clippy library. install-rustfmt : install rustfmt library. install-setup : install dev tools ( clippy and rustfmt ). server : run witnet server component. travis : run travis build. Installing the just tool just is a command runner tool widely used in the Rust ecosystem. You can install it with a single line: cargo install just","title":"Development Scripts"},{"location":"glossary/","text":"Glossary \u00b6 Conditional payment : a Witnet transaction encumbered with a small program that defines how, when and by whom the enclosed value can be spent. Conditional payments can consume data coming from Witnet data requests, so they can be used to trigger release of funds upon the result of real world events without having to resort to more complex, stateful, turing-complete smart contracts. Data request : a digital document declaring one or more data sources and how data coming from those sources can be normalized and combined together in order to present it as a single data point to be consumed by other programs. Decentralized network : an overlay network in which multiple untrusted computers have been set to communicate with each other as peers using a network protocol, with the purpose of fulfilling some common utility, without any of them having prominent or absolute control over the network and without chance for anyone to disrupt the functioning of the network. Oracle : an entity providing smart contracts with information from outside their containing network. Tamper resistance is the main point of smart contracts, so they should only employ decentralized oracles in which they do not need to trust the messenger . Otherwise, the oracle entity would become a single point of failure . Smart contract : a deterministic computer program with a high degree of resistance to tampering and censorship due to its concurrent execution by a decentralized network of processors owned by untrusted parties whose incentives deter them from colluding to alter the output of the program.","title":"Glossary"},{"location":"glossary/#glossary","text":"Conditional payment : a Witnet transaction encumbered with a small program that defines how, when and by whom the enclosed value can be spent. Conditional payments can consume data coming from Witnet data requests, so they can be used to trigger release of funds upon the result of real world events without having to resort to more complex, stateful, turing-complete smart contracts. Data request : a digital document declaring one or more data sources and how data coming from those sources can be normalized and combined together in order to present it as a single data point to be consumed by other programs. Decentralized network : an overlay network in which multiple untrusted computers have been set to communicate with each other as peers using a network protocol, with the purpose of fulfilling some common utility, without any of them having prominent or absolute control over the network and without chance for anyone to disrupt the functioning of the network. Oracle : an entity providing smart contracts with information from outside their containing network. Tamper resistance is the main point of smart contracts, so they should only employ decentralized oracles in which they do not need to trust the messenger . Otherwise, the oracle entity would become a single point of failure . Smart contract : a deterministic computer program with a high degree of resistance to tampering and censorship due to its concurrent execution by a decentralized network of processors owned by untrusted parties whose incentives deter them from colluding to alter the output of the program.","title":"Glossary"},{"location":"roadmap/","text":"Witnet-rust Development Roadmap \u00b6 Witnet is an open initiative and Witnet-rust is and an open source project that will be developed by Witnet Foundation in collaboration with a number of other organizations and independent developers. This means that Witnet Foundation can't set the roadmap unilaterally. However, Witnet Foundation has a strong commitment to ensure the following milestones are met: September 2018 : a user-facing demo/prototype that will let users explore the potential of the protocol being built. Done! Sheikah desktop client is already out ! 2019 Q1 testnet-1 : a functional test network implementing the essential features of the Witnet protocol. Done! testnet-1 is already out ! 2019 Q3 : bridge node software for Ethereum. 2019 Q4 : mainnet release. Given the experimental nature of the technologies and network protocols under development, these dates and deliverables may be subject to change due to reasons beyond the control of Witnet Foundation.","title":"Roadmap"},{"location":"roadmap/#witnet-rust-development-roadmap","text":"Witnet is an open initiative and Witnet-rust is and an open source project that will be developed by Witnet Foundation in collaboration with a number of other organizations and independent developers. This means that Witnet Foundation can't set the roadmap unilaterally. However, Witnet Foundation has a strong commitment to ensure the following milestones are met: September 2018 : a user-facing demo/prototype that will let users explore the potential of the protocol being built. Done! Sheikah desktop client is already out ! 2019 Q1 testnet-1 : a functional test network implementing the essential features of the Witnet protocol. Done! testnet-1 is already out ! 2019 Q3 : bridge node software for Ethereum. 2019 Q4 : mainnet release. Given the experimental nature of the technologies and network protocols under development, these dates and deliverables may be subject to change due to reasons beyond the control of Witnet Foundation.","title":"Witnet-rust Development Roadmap"},{"location":"advanced/constants/","text":"Page under construction. Check back soon. \u00b6","title":"Network constants"},{"location":"advanced/constants/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"advanced/whitepaper-differences/","text":"Page under construction. Check back soon. \u00b6","title":"Differences with the whitepaper"},{"location":"advanced/whitepaper-differences/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"architecture/block-mgmt/","text":"Page under construction. Check back soon. \u00b6","title":"Block Management"},{"location":"architecture/block-mgmt/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"architecture/json-rpc-server/","text":"JsonRpcServer \u00b6 The JSON-RPC interface is implemented using a JsonRpcServer actor which handles the new incoming connections and spawns a JsonRpc actor for each new connection. The JsonRpc actor handles the JSON-RPC protocol, parses the input stream as JSON-RPC, executes the request and generates an appropriate response. The supported JSON-RPC methods are implemented in json_rpc_methods.rs . See JSON-RPC for further information. API \u00b6 The JsonRpcServer does not expose any public API, once it is started it will read the necessary parameters from the ConfigManager and automatically handle all the incoming connections. Incoming: Others -> JsonRpcServer \u00b6 These are the messages supported by the JsonRpcServer : Message Input type Output type Description InboundTcpConnect TcpStream () Request to create a session from an incoming TCP connection Unregister Addr<JsonRpc> () Removes a closed connection from the list of open connections However, they are internal messages: the InboundTcpConnect is sent by the stream listener and the Unregister is sent by the JsonRpc actor. Outgoing messages: JsonRpcServer -> Others \u00b6 These are the messages sent by the EpochManager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request the configuration GetConfig \u00b6 This message is sent to the ConfigManager actor when the JsonRpcServer actor is started. The return value is used to initialize the protocol constants (checkpoint period and epoch zero timestamp). For further information, see ConfigManager . Incoming: Others -> JsonRpc \u00b6 The JsonRpc actor does not have any message handlers. Outgoing messages: JsonRpc -> Others \u00b6 Message Destination Input type Output type Description Unregister JsonRpcServer Addr<JsonRpc> () Removes a closed connection from the list of open connections The JsonRpc actor only sends one Unregister message to its parent when the connection closes. Further information \u00b6 The full source code of the JsonRpcServer can be found at server.rs .","title":"JSON-RPC Server"},{"location":"architecture/json-rpc-server/#jsonrpcserver","text":"The JSON-RPC interface is implemented using a JsonRpcServer actor which handles the new incoming connections and spawns a JsonRpc actor for each new connection. The JsonRpc actor handles the JSON-RPC protocol, parses the input stream as JSON-RPC, executes the request and generates an appropriate response. The supported JSON-RPC methods are implemented in json_rpc_methods.rs . See JSON-RPC for further information.","title":"JsonRpcServer"},{"location":"architecture/json-rpc-server/#api","text":"The JsonRpcServer does not expose any public API, once it is started it will read the necessary parameters from the ConfigManager and automatically handle all the incoming connections.","title":"API"},{"location":"architecture/json-rpc-server/#incoming-others-jsonrpcserver","text":"These are the messages supported by the JsonRpcServer : Message Input type Output type Description InboundTcpConnect TcpStream () Request to create a session from an incoming TCP connection Unregister Addr<JsonRpc> () Removes a closed connection from the list of open connections However, they are internal messages: the InboundTcpConnect is sent by the stream listener and the Unregister is sent by the JsonRpc actor.","title":"Incoming: Others -&gt; JsonRpcServer"},{"location":"architecture/json-rpc-server/#outgoing-messages-jsonrpcserver-others","text":"These are the messages sent by the EpochManager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request the configuration","title":"Outgoing messages: JsonRpcServer -&gt; Others"},{"location":"architecture/json-rpc-server/#getconfig","text":"This message is sent to the ConfigManager actor when the JsonRpcServer actor is started. The return value is used to initialize the protocol constants (checkpoint period and epoch zero timestamp). For further information, see ConfigManager .","title":"GetConfig"},{"location":"architecture/json-rpc-server/#incoming-others-jsonrpc","text":"The JsonRpc actor does not have any message handlers.","title":"Incoming: Others -&gt; JsonRpc"},{"location":"architecture/json-rpc-server/#outgoing-messages-jsonrpc-others","text":"Message Destination Input type Output type Description Unregister JsonRpcServer Addr<JsonRpc> () Removes a closed connection from the list of open connections The JsonRpc actor only sends one Unregister message to its parent when the connection closes.","title":"Outgoing messages: JsonRpc -&gt; Others"},{"location":"architecture/json-rpc-server/#further-information","text":"The full source code of the JsonRpcServer can be found at server.rs .","title":"Further information"},{"location":"architecture/mempool-mgmt/","text":"Page under construction. Check back soon. \u00b6","title":"Mempool Management"},{"location":"architecture/mempool-mgmt/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"architecture/overview/","text":"Page under construction. Check back soon. \u00b6","title":"Overview"},{"location":"architecture/overview/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"architecture/session/","text":"Session \u00b6 Session is the actor that encapsulates the entire business logic of the Witnet network protocol . Its responsibilities include: Session consolidation by following the Handshake protocol Blockchain synchronization (after consolidation) by triggering the Block Download process Real-time inventory management by supporting Inventory Broadcasting Actor creation and registration \u00b6 The creation of the session actor is performed by the SessionsManager actor upon reception of a Create message: // Create a session actor Session :: create ( move | ctx | { // Get local peer address let local_addr = msg . stream . local_addr (). unwrap (); // Get remote peer address let remote_addr = msg . stream . peer_addr (). unwrap (); // Split TCP stream into read and write parts let ( r , w ) = msg . stream . split (); // Add stream in session actor from the read part of the tcp stream Session :: add_stream ( FramedRead :: new ( r , P2PCodec ), ctx ); // Create the session actor and store in its state the write part of the tcp stream Session :: new ( local_addr , remote_addr , msg . session_type , FramedWrite :: new ( w , P2PCodec , ctx ), handshake_timeout , ) }); API \u00b6 Incoming: Others -> Session \u00b6 These are the messages supported by the Session handlers: Message Input type Output type Description GetPeers () () Request peers from a session AnnounceItems Vec<InventoryEntry> () Announce new inventory entries RequestBlock InventoryEntry () Request a Block` from a session SendInventoryItem InventoryItem () Send a InventoryItem to a session GetPeers \u00b6 Ask the peer on the other side of the connection for their own list of peer addresses. AnnounceItems \u00b6 Announce new inventory entries. Outgoing messages: Session -> Others \u00b6 These are the messages sent by the Session: Message Destination Input type Output type Description Register SessionsManager SocketAddr, Addr<Session>, SessionType SessionsResult<()> Request to register a new session Unregister SessionsManager SocketAddr, SessionType, SessionStatus SessionsResult<()> Request to unregister a session Register \u00b6 This message is sent to the SessionsManager actor when the session actor is started to register this session. The returned value is a Result for easy verification of the success of the operation. For further information, see SessionsManager . Unregister \u00b6 This message is sent to the SessionsManager actor when the session actor is stopped to unregister this session. The returned value is a Result for easy verification of the success of the operation. For further information, see SessionsManager . Further information \u00b6 The full source code of the Session actor can be found at session.rs .","title":"Session"},{"location":"architecture/session/#session","text":"Session is the actor that encapsulates the entire business logic of the Witnet network protocol . Its responsibilities include: Session consolidation by following the Handshake protocol Blockchain synchronization (after consolidation) by triggering the Block Download process Real-time inventory management by supporting Inventory Broadcasting","title":"Session"},{"location":"architecture/session/#actor-creation-and-registration","text":"The creation of the session actor is performed by the SessionsManager actor upon reception of a Create message: // Create a session actor Session :: create ( move | ctx | { // Get local peer address let local_addr = msg . stream . local_addr (). unwrap (); // Get remote peer address let remote_addr = msg . stream . peer_addr (). unwrap (); // Split TCP stream into read and write parts let ( r , w ) = msg . stream . split (); // Add stream in session actor from the read part of the tcp stream Session :: add_stream ( FramedRead :: new ( r , P2PCodec ), ctx ); // Create the session actor and store in its state the write part of the tcp stream Session :: new ( local_addr , remote_addr , msg . session_type , FramedWrite :: new ( w , P2PCodec , ctx ), handshake_timeout , ) });","title":"Actor creation and registration"},{"location":"architecture/session/#api","text":"","title":"API"},{"location":"architecture/session/#incoming-others-session","text":"These are the messages supported by the Session handlers: Message Input type Output type Description GetPeers () () Request peers from a session AnnounceItems Vec<InventoryEntry> () Announce new inventory entries RequestBlock InventoryEntry () Request a Block` from a session SendInventoryItem InventoryItem () Send a InventoryItem to a session","title":"Incoming: Others -&gt; Session"},{"location":"architecture/session/#getpeers","text":"Ask the peer on the other side of the connection for their own list of peer addresses.","title":"GetPeers"},{"location":"architecture/session/#announceitems","text":"Announce new inventory entries.","title":"AnnounceItems"},{"location":"architecture/session/#outgoing-messages-session-others","text":"These are the messages sent by the Session: Message Destination Input type Output type Description Register SessionsManager SocketAddr, Addr<Session>, SessionType SessionsResult<()> Request to register a new session Unregister SessionsManager SocketAddr, SessionType, SessionStatus SessionsResult<()> Request to unregister a session","title":"Outgoing messages: Session -&gt; Others"},{"location":"architecture/session/#register","text":"This message is sent to the SessionsManager actor when the session actor is started to register this session. The returned value is a Result for easy verification of the success of the operation. For further information, see SessionsManager .","title":"Register"},{"location":"architecture/session/#unregister","text":"This message is sent to the SessionsManager actor when the session actor is stopped to unregister this session. The returned value is a Result for easy verification of the success of the operation. For further information, see SessionsManager .","title":"Unregister"},{"location":"architecture/session/#further-information","text":"The full source code of the Session actor can be found at session.rs .","title":"Further information"},{"location":"architecture/storage/","text":"Persistent Storage \u00b6 From the perspective of software architecture, persistent storage is one of the key elements to maintaining a distributed block chain. Its role is allowing nodes in the network to preserve important data structures that need to be kept over time for trustless validation of new chain objects. Namely, those structures are: The UTXO set Data requests Transactions Blocks Generic Storage Trait \u00b6 Witnet-rust features a generic Storage Rust trait ( storage.rs ) that exposes a key/value API with the elemental CRUD methods (create, read, update, delete) while abstracting away from specific storage backend implementations. pub trait Storage < ConnData , Key , Value > { /** **/ } The meaning of the generic types is the following: Generic type Description ConnData Type of the data needed by the constructor for creating a connection to the storage backend. Key Type of the keys used to identify the records in the storage. Value Type of the values in the storage. As of PR #21 , Witnet-rust incorporates implementations for the following storage backends: rocks.rs : persists data into the local file system using the performant RocksDB engine. in_memory.rs : keeps data in a HashMap that lives in the memory heap. Warning In-memory storage is implemented only for the sake of testing the Storage trait. It is obviously not a viable persistence solution as data is totally wiped as soon as references to the storage go out of scope or the app dies. Instantiation \u00b6 All implementors of the Storage trait can be instantiated with the witnet_storage::storage::new() constructor, which must be used as a static method. Signature fn new ( connection_data : ConnData ) -> Result < Box < Self >> ; Tip Please note that the witnet_storage::storage::new() method wraps the return type into a Box . This is to ensure the value is allocated into the heap and to allow a reference to it (the Box itself) to outlive the constructor. Example use witnet_storage :: backends :: in_memory :: InMemoryStorage ; let storage : & InMemoryStorage = InMemoryStorage :: new (). unwrap (); Creating and updating records with the put() Method \u00b6 The witnet_storage::storage::put() method allows creating or replacing a value in the storage under a certain key. Signature fn put ( & mut self , key : Key , value : Value ) -> Result < () > ; Example // Put value \"bar\" into key \"foo\" storage . put ( b\"foo\" , b\"bar\" . to_vec ()) ? ; // Update value of \"foo\" to be \"beer\" storage . put ( b\"foo\" , b\"beer\" . to_vec ()) ? ; Getting records with the get() method \u00b6 The witnet_storage::storage::get() method allows reading the value in the storage under a certain key. Signature fn get ( & self , key : Key ) -> Result < Option < Value >> ; Example match storage . get ( b\"foo\" ) { Ok ( Some ( value )) => , // Found a value Ok ( None ) => , // The key didn't exist Err ( error ) => // Error while reading } Deleting records with the delete() method \u00b6 The witnet_storage::storage::delete() method allows deleting a record in the storage given its key. Signature fn delete ( & mut self , key : Key ) -> Result < () > ; Example storage . delete ( b\"foo\" ) ? ; RocksDB Storage Backend \u00b6 The RocksDB storage backend ( rocks.rs ) is one of the bundled storage backends in Witnet-rust. It implements all the methods of the Storage trait for the RocksStorage struct: /// Data structure for the RocksDB storage whose only member is a /// rocksdb::DB object. pub struct RocksStorage { db : DB } The actual implementor looks like this (function bodies and some lifetime annotations have been omitted for brevity): // Implement the Storage generic trait for the RocksStorage storage // data structure. impl Storage <& str , & [ u8 ], Vec < u8 >> for RocksStorage { fn new ( path : & str ) -> Result < Box < Self >> ; fn put ( & mut self , key : & [ u8 ], value : Vec < u8 > ) -> Result < () > ; fn get ( & self , key : & [ u8 ]) -> Result < Option < Vec < u8 >>> ; fn delete ( & mut self , key : & [ u8 ]) -> Result < () > ; } These are the specific types for this implementor: Generic type Specific type ConnData &str Key &[u8] Value Vec<u8> The full source code of the Storage implementor for RocksStorage can be found at rocks.rs . Storable trait \u00b6 The Storable trait defines a conversion from any type to bytes. It is useful because the storage backends expect keys and values to be raw bytes, so the data needs to be serialized and deserialized. The simplest way to implement this trait is to add #[derive(Serialize, Deserialize)] from serde to the type definition: #[derive(Serialize, Deserialize)] struct Foo { data : Vec < String > } The default implementation uses MessagePack , but the implementor is free to choose a different encoding for their custom types. The preferred way to work with this trait is using the StorageHelper , described below: StorageHelper trait \u00b6 To enable better ergonomics when working with the storage, users can import the StorageHelper trait which adds two additional methods to the Storage : pub trait StorageHelper { /// Insert an element into the storage fn put_t < T : Storable > ( & mut self , key : & [ u8 ], value : T ) -> StorageResult < () > ; /// Get an element from the storage fn get_t < T : Storable > ( & mut self , key : & [ u8 ]) -> StorageResult < Option < T >> ; } This trait is implemented by default for all the storage backends which work with raw bytes. It allows for inserting and removing typed values, as long as the types implement the Storable trait. Example \u00b6 use witnet_storage :: storage :: { Storage , StorageHelper }; use witnet_storage :: error :: StorageResult ; use witnet_storage :: backends :: in_memory :: InMemoryStorage ; fn main () -> StorageResult < () > { // Create an InMemoryStorage for testing let mut s = InMemoryStorage :: new (()) ? ; // Insert a String let v1 : String = \"hello!\" . to_string (); s . put_t ( b\"str\" , v1 . clone ()) ? ; // Get that String back let v2 : String = s . get_t ( b\"str\" ) ? . unwrap (); assert_eq ! ( v1 , v2 ); // Insert a i32 let x1 : i32 = 54 ; s . put_t ( b\"int\" , x1 . clone ()) ? ; // Get that i32 back let x2 = s . get_t :: < i32 > ( b\"int\" ) ? . unwrap (); assert_eq ! ( x1 , x2 ); Ok (()) } Safety \u00b6 This trait allows for inserting and removing typed values, although there is no type safety, the user is responsible to make sure the get_t method specifies the correct type. In most cases the conversion will fail and the get_t method will return an error. But it is possible to get a valid result from a different type.","title":"Persistent Storage"},{"location":"architecture/storage/#persistent-storage","text":"From the perspective of software architecture, persistent storage is one of the key elements to maintaining a distributed block chain. Its role is allowing nodes in the network to preserve important data structures that need to be kept over time for trustless validation of new chain objects. Namely, those structures are: The UTXO set Data requests Transactions Blocks","title":"Persistent Storage"},{"location":"architecture/storage/#generic-storage-trait","text":"Witnet-rust features a generic Storage Rust trait ( storage.rs ) that exposes a key/value API with the elemental CRUD methods (create, read, update, delete) while abstracting away from specific storage backend implementations. pub trait Storage < ConnData , Key , Value > { /** **/ } The meaning of the generic types is the following: Generic type Description ConnData Type of the data needed by the constructor for creating a connection to the storage backend. Key Type of the keys used to identify the records in the storage. Value Type of the values in the storage. As of PR #21 , Witnet-rust incorporates implementations for the following storage backends: rocks.rs : persists data into the local file system using the performant RocksDB engine. in_memory.rs : keeps data in a HashMap that lives in the memory heap. Warning In-memory storage is implemented only for the sake of testing the Storage trait. It is obviously not a viable persistence solution as data is totally wiped as soon as references to the storage go out of scope or the app dies.","title":"Generic Storage Trait"},{"location":"architecture/storage/#instantiation","text":"All implementors of the Storage trait can be instantiated with the witnet_storage::storage::new() constructor, which must be used as a static method. Signature fn new ( connection_data : ConnData ) -> Result < Box < Self >> ; Tip Please note that the witnet_storage::storage::new() method wraps the return type into a Box . This is to ensure the value is allocated into the heap and to allow a reference to it (the Box itself) to outlive the constructor. Example use witnet_storage :: backends :: in_memory :: InMemoryStorage ; let storage : & InMemoryStorage = InMemoryStorage :: new (). unwrap ();","title":"Instantiation"},{"location":"architecture/storage/#creating-and-updating-records-with-the-put-method","text":"The witnet_storage::storage::put() method allows creating or replacing a value in the storage under a certain key. Signature fn put ( & mut self , key : Key , value : Value ) -> Result < () > ; Example // Put value \"bar\" into key \"foo\" storage . put ( b\"foo\" , b\"bar\" . to_vec ()) ? ; // Update value of \"foo\" to be \"beer\" storage . put ( b\"foo\" , b\"beer\" . to_vec ()) ? ;","title":"Creating and updating records with the put() Method"},{"location":"architecture/storage/#getting-records-with-the-get-method","text":"The witnet_storage::storage::get() method allows reading the value in the storage under a certain key. Signature fn get ( & self , key : Key ) -> Result < Option < Value >> ; Example match storage . get ( b\"foo\" ) { Ok ( Some ( value )) => , // Found a value Ok ( None ) => , // The key didn't exist Err ( error ) => // Error while reading }","title":"Getting records with the get() method"},{"location":"architecture/storage/#deleting-records-with-the-delete-method","text":"The witnet_storage::storage::delete() method allows deleting a record in the storage given its key. Signature fn delete ( & mut self , key : Key ) -> Result < () > ; Example storage . delete ( b\"foo\" ) ? ;","title":"Deleting records with the delete() method"},{"location":"architecture/storage/#rocksdb-storage-backend","text":"The RocksDB storage backend ( rocks.rs ) is one of the bundled storage backends in Witnet-rust. It implements all the methods of the Storage trait for the RocksStorage struct: /// Data structure for the RocksDB storage whose only member is a /// rocksdb::DB object. pub struct RocksStorage { db : DB } The actual implementor looks like this (function bodies and some lifetime annotations have been omitted for brevity): // Implement the Storage generic trait for the RocksStorage storage // data structure. impl Storage <& str , & [ u8 ], Vec < u8 >> for RocksStorage { fn new ( path : & str ) -> Result < Box < Self >> ; fn put ( & mut self , key : & [ u8 ], value : Vec < u8 > ) -> Result < () > ; fn get ( & self , key : & [ u8 ]) -> Result < Option < Vec < u8 >>> ; fn delete ( & mut self , key : & [ u8 ]) -> Result < () > ; } These are the specific types for this implementor: Generic type Specific type ConnData &str Key &[u8] Value Vec<u8> The full source code of the Storage implementor for RocksStorage can be found at rocks.rs .","title":"RocksDB Storage Backend"},{"location":"architecture/storage/#storable-trait","text":"The Storable trait defines a conversion from any type to bytes. It is useful because the storage backends expect keys and values to be raw bytes, so the data needs to be serialized and deserialized. The simplest way to implement this trait is to add #[derive(Serialize, Deserialize)] from serde to the type definition: #[derive(Serialize, Deserialize)] struct Foo { data : Vec < String > } The default implementation uses MessagePack , but the implementor is free to choose a different encoding for their custom types. The preferred way to work with this trait is using the StorageHelper , described below:","title":"Storable trait"},{"location":"architecture/storage/#storagehelper-trait","text":"To enable better ergonomics when working with the storage, users can import the StorageHelper trait which adds two additional methods to the Storage : pub trait StorageHelper { /// Insert an element into the storage fn put_t < T : Storable > ( & mut self , key : & [ u8 ], value : T ) -> StorageResult < () > ; /// Get an element from the storage fn get_t < T : Storable > ( & mut self , key : & [ u8 ]) -> StorageResult < Option < T >> ; } This trait is implemented by default for all the storage backends which work with raw bytes. It allows for inserting and removing typed values, as long as the types implement the Storable trait.","title":"StorageHelper trait"},{"location":"architecture/storage/#example","text":"use witnet_storage :: storage :: { Storage , StorageHelper }; use witnet_storage :: error :: StorageResult ; use witnet_storage :: backends :: in_memory :: InMemoryStorage ; fn main () -> StorageResult < () > { // Create an InMemoryStorage for testing let mut s = InMemoryStorage :: new (()) ? ; // Insert a String let v1 : String = \"hello!\" . to_string (); s . put_t ( b\"str\" , v1 . clone ()) ? ; // Get that String back let v2 : String = s . get_t ( b\"str\" ) ? . unwrap (); assert_eq ! ( v1 , v2 ); // Insert a i32 let x1 : i32 = 54 ; s . put_t ( b\"int\" , x1 . clone ()) ? ; // Get that i32 back let x2 = s . get_t :: < i32 > ( b\"int\" ) ? . unwrap (); assert_eq ! ( x1 , x2 ); Ok (()) }","title":"Example"},{"location":"architecture/storage/#safety","text":"This trait allows for inserting and removing typed values, although there is no type safety, the user is responsible to make sure the get_t method specifies the correct type. In most cases the conversion will fail and the get_t method will return an error. But it is possible to get a valid result from a different type.","title":"Safety"},{"location":"architecture/utxo-mgmt/","text":"Page under construction. Check back soon. \u00b6","title":"UTXO Management"},{"location":"architecture/utxo-mgmt/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"architecture/witscript/","text":"Page under construction. Check back soon. \u00b6","title":"Witscript Parser"},{"location":"architecture/witscript/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"architecture/managers/chain-manager/","text":"Chain Manager \u00b6 The Chain Manager is the actor in charge of managing the blocks of managing the blocks and transactions of the Witnet blockchain received through the protocol, and also encapsulates the logic of the unspent transaction outputs . Among its responsabilities are the following: Initializing the chain info upon running the node for the first time and persisting it into storage (see Storage Manager ). Recovering the chain info from storage and keeping it in its state. Validating block candidates as they come from a session (see Sessions Manager ). Consolidating multiple block candidates for the same checkpoint into a single valid block. Putting valid blocks into storage by sending them to the storage manager actor. Having a method for letting other components to get blocks by hash or checkpoint . Having a method for letting other components get the epoch of the current tip of the blockchain (e.g. last epoch field required for the handshake in the Witnet network protocol). Validating transactions as they come from any Session . This includes: Iterating over its inputs, adding the value of the inputs to calculate the value of the transaction. Running the output scripts, expecting them all to return TRUE and leave an empty stack. Verifying that the sum of all inputs is greater than or equal to the sum of all the outputs. Keeping valid transactions into memory. This in-memory transaction pool is what we call the mempool . Valid transactions are immediately appended to the mempool. Keeping every unspent transaction output (UTXO) in the block chain in memory. This is called the UTXO set . Updating the UTXO set with valid transactions that have already been anchored into a valid block. This includes: Removing the UTXOs that the transaction spends as inputs. Adding a new UTXO for every output in the transaction. Discovering our eligibility for mining new blocks and resolving data requests. The mining is optional and can be disabled using a configuration flag in witnet.toml : [mining] enabled = false State \u00b6 The state of the actor is an instance of the ChainInfo data structures. /// ChainManager actor #[derive(Default)] pub struct ChainManager { /// Blockchain information data structure chain_info : Option < ChainInfo > , /// Map that relates an epoch with the hashes of the blocks for that epoch // One epoch can have more than one block epoch_to_block_hash : HashMap < Epoch , HashSet < Hash >> , /// Map that stores blocks by their hash blocks : HashMap < Hash , Block > , /// Current Epoch current_epoch : Option < Epoch > , /// Block candidate to update chain_info in the next epoch block_candidate : Option < Block > , } Actor creation and registration \u00b6 The creation of the Chain Manager actor and its registration into the system registry are performed directly by the main process node.rs : let chain_manager_addr = ChainManager :: default (). start (); System :: current (). registry (). set ( chain_manager_addr ); API \u00b6 Incoming: Others -> ChainManager \u00b6 These are the messages supported by the ChainManager handlers: Message Input type Output type Description EpochNotification<EpochPayload> Epoch , EpochPayload () The requested epoch has been reached EpochNotification<EveryEpochPayload> Epoch , EveryEpochPayload () A new epoch has been reached EpochNotification<MiningNotification> Epoch , MiningNotification () A new epoch has been reached, try to mine a new block GetHighestBlockCheckpoint () ChainInfoResult Request a copy of the highest block checkpoint AddNewBlock Block Result<(), ChainManagerError> Add a new block and announce it to other sessions AddTransaction Transaction Result<(), ChainManagerError> Add a new transaction and announce it to other sessions GetBlock Hash Result<(), ChainManagerError> Ask for a block identified by its hash GetBlocksEpochRange (Bound<Epoch>, Bound<Epoch>) Result<Vec<(Epoch, InventoryEntry)>, ChainManagerError> Obtain a vector of epochs and block hashes using a range of epochs DiscardExistingInventoryEntries Vec<InventoryEntries> InventoryEntriesResult Discard inventory entries that exist in the BlocksManager Where ChainInfoResult is just: /// Result type for the ChainInfo in ChainManager module. pub type ChainInfoResult < T > = WitnetResult < T , ChainInfoError > ; The way other actors will communicate with the ChainManager is: Get the address of the ChainManager actor from the registry: // Get ChainManager address let chain_manager_addr = System :: current (). registry (). get :: < ChainManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: chain_manager_addr . send ( GetHighestBlockCheckpoint ) . into_actor ( self ) . then ( | res , _act , _ctx | { // Process the response from ChainManager process_get_config_response ( res ) }) . and_then ( | checkpoint , _act , ctx | { // Do something with the checkpoint actix :: fut :: ok (()) }) . wait ( ctx ); For the time being, the handlers for Epoch messages just print a debug message with the notified checkpoint. fn handle ( & mut self , msg : EpochNotification < EpochPayload > , _ctx : & mut Context < Self > ) { debug ! ( \"Epoch notification received {:?}\" , msg . checkpoint ); } Outgoing messages: ChainManager -> Others \u00b6 These are the messages sent by the Chain Manager: Message Destination Input type Output type Description SubscribeEpoch EpochManager Epoch , Addr<ChainManager>, EpochPayload () Subscribe to a particular epoch SubscribeAll EpochManager Addr<ChainManager>, EveryEpochPayload () Subscribe to all epochs GetConfig ConfigManager () Result<Config, io::Error> Request the configuration Get StorageManager &'static [u8] StorageResult<Option<T>> Wrapper to Storage get() method Put StorageManager &'static [u8] , Vec<u8> StorageResult<()> Wrapper to Storage put() method Broadcast<AnnounceItems> SessionsManager Vec<InventoryEntry> () Announce new inventory entries to the sessions AddItem InventoryManager InventoryItem Result<(), InventoryManagerError> Persist the best_candidate.block Broadcast<SendBlock> SessionsManager Block () Send a new block to the sessions Anycast<RequestBlock> SessionsManager InventoryEntry () Request a lost block to a random session SubscribeEpoch \u00b6 This message is sent to the EpochManager actor when the ChainManager actor is started, in order to subscribe to the next epoch (test functionality). Subscribing to the next epoch means that the EpochManager will send an EpochNotification<EpochPayload> back to the ChainManager when the epoch is reached. For further information, see EpochManager . SubscribeAll \u00b6 This message is sent to the EpochManager actor when the Chain Manager actor is started, in order to subscribe to the all epochs. Subscribing to all epochs means that the EpochManager will send an EpochNotification<EveryEpochPayload> back to the ChainManager when every epoch is reached. For further information, see EpochManager . GetConfig \u00b6 This message is sent to the [ ConfigManager ][config_manager] actor when the peers manager actor is started. The return value is used to initialize the list of known peers, and to decide whether or not enable the mining. For further information, see [ ConfigManager ][config_manager]. Get \u00b6 This message is sent to the StorageManager actor when the Chain Manager actor is started. The return value is a ChainInfo structure from the storage which are added to the state of the actor. Put \u00b6 This message is sent to the StorageManager actor to persist the ChainInfo structure The return value is used to check if the storage process has been successful. Broadcast \u00b6 This message is sent to the SessionsManager actor which will broadcast a AnnounceItems message to the open outbound sessions. AddItem \u00b6 This message is sent to the InventoryManager actor as a InventoryItem to persist the block_candidate state. Further information \u00b6 The full source code of the ChainManager can be found at chain_manager.rs .","title":"Chain Manager"},{"location":"architecture/managers/chain-manager/#chain-manager","text":"The Chain Manager is the actor in charge of managing the blocks of managing the blocks and transactions of the Witnet blockchain received through the protocol, and also encapsulates the logic of the unspent transaction outputs . Among its responsabilities are the following: Initializing the chain info upon running the node for the first time and persisting it into storage (see Storage Manager ). Recovering the chain info from storage and keeping it in its state. Validating block candidates as they come from a session (see Sessions Manager ). Consolidating multiple block candidates for the same checkpoint into a single valid block. Putting valid blocks into storage by sending them to the storage manager actor. Having a method for letting other components to get blocks by hash or checkpoint . Having a method for letting other components get the epoch of the current tip of the blockchain (e.g. last epoch field required for the handshake in the Witnet network protocol). Validating transactions as they come from any Session . This includes: Iterating over its inputs, adding the value of the inputs to calculate the value of the transaction. Running the output scripts, expecting them all to return TRUE and leave an empty stack. Verifying that the sum of all inputs is greater than or equal to the sum of all the outputs. Keeping valid transactions into memory. This in-memory transaction pool is what we call the mempool . Valid transactions are immediately appended to the mempool. Keeping every unspent transaction output (UTXO) in the block chain in memory. This is called the UTXO set . Updating the UTXO set with valid transactions that have already been anchored into a valid block. This includes: Removing the UTXOs that the transaction spends as inputs. Adding a new UTXO for every output in the transaction. Discovering our eligibility for mining new blocks and resolving data requests. The mining is optional and can be disabled using a configuration flag in witnet.toml : [mining] enabled = false","title":"Chain Manager"},{"location":"architecture/managers/chain-manager/#state","text":"The state of the actor is an instance of the ChainInfo data structures. /// ChainManager actor #[derive(Default)] pub struct ChainManager { /// Blockchain information data structure chain_info : Option < ChainInfo > , /// Map that relates an epoch with the hashes of the blocks for that epoch // One epoch can have more than one block epoch_to_block_hash : HashMap < Epoch , HashSet < Hash >> , /// Map that stores blocks by their hash blocks : HashMap < Hash , Block > , /// Current Epoch current_epoch : Option < Epoch > , /// Block candidate to update chain_info in the next epoch block_candidate : Option < Block > , }","title":"State"},{"location":"architecture/managers/chain-manager/#actor-creation-and-registration","text":"The creation of the Chain Manager actor and its registration into the system registry are performed directly by the main process node.rs : let chain_manager_addr = ChainManager :: default (). start (); System :: current (). registry (). set ( chain_manager_addr );","title":"Actor creation and registration"},{"location":"architecture/managers/chain-manager/#api","text":"","title":"API"},{"location":"architecture/managers/chain-manager/#incoming-others-chainmanager","text":"These are the messages supported by the ChainManager handlers: Message Input type Output type Description EpochNotification<EpochPayload> Epoch , EpochPayload () The requested epoch has been reached EpochNotification<EveryEpochPayload> Epoch , EveryEpochPayload () A new epoch has been reached EpochNotification<MiningNotification> Epoch , MiningNotification () A new epoch has been reached, try to mine a new block GetHighestBlockCheckpoint () ChainInfoResult Request a copy of the highest block checkpoint AddNewBlock Block Result<(), ChainManagerError> Add a new block and announce it to other sessions AddTransaction Transaction Result<(), ChainManagerError> Add a new transaction and announce it to other sessions GetBlock Hash Result<(), ChainManagerError> Ask for a block identified by its hash GetBlocksEpochRange (Bound<Epoch>, Bound<Epoch>) Result<Vec<(Epoch, InventoryEntry)>, ChainManagerError> Obtain a vector of epochs and block hashes using a range of epochs DiscardExistingInventoryEntries Vec<InventoryEntries> InventoryEntriesResult Discard inventory entries that exist in the BlocksManager Where ChainInfoResult is just: /// Result type for the ChainInfo in ChainManager module. pub type ChainInfoResult < T > = WitnetResult < T , ChainInfoError > ; The way other actors will communicate with the ChainManager is: Get the address of the ChainManager actor from the registry: // Get ChainManager address let chain_manager_addr = System :: current (). registry (). get :: < ChainManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: chain_manager_addr . send ( GetHighestBlockCheckpoint ) . into_actor ( self ) . then ( | res , _act , _ctx | { // Process the response from ChainManager process_get_config_response ( res ) }) . and_then ( | checkpoint , _act , ctx | { // Do something with the checkpoint actix :: fut :: ok (()) }) . wait ( ctx ); For the time being, the handlers for Epoch messages just print a debug message with the notified checkpoint. fn handle ( & mut self , msg : EpochNotification < EpochPayload > , _ctx : & mut Context < Self > ) { debug ! ( \"Epoch notification received {:?}\" , msg . checkpoint ); }","title":"Incoming: Others -&gt; ChainManager"},{"location":"architecture/managers/chain-manager/#outgoing-messages-chainmanager-others","text":"These are the messages sent by the Chain Manager: Message Destination Input type Output type Description SubscribeEpoch EpochManager Epoch , Addr<ChainManager>, EpochPayload () Subscribe to a particular epoch SubscribeAll EpochManager Addr<ChainManager>, EveryEpochPayload () Subscribe to all epochs GetConfig ConfigManager () Result<Config, io::Error> Request the configuration Get StorageManager &'static [u8] StorageResult<Option<T>> Wrapper to Storage get() method Put StorageManager &'static [u8] , Vec<u8> StorageResult<()> Wrapper to Storage put() method Broadcast<AnnounceItems> SessionsManager Vec<InventoryEntry> () Announce new inventory entries to the sessions AddItem InventoryManager InventoryItem Result<(), InventoryManagerError> Persist the best_candidate.block Broadcast<SendBlock> SessionsManager Block () Send a new block to the sessions Anycast<RequestBlock> SessionsManager InventoryEntry () Request a lost block to a random session","title":"Outgoing messages: ChainManager -&gt; Others"},{"location":"architecture/managers/chain-manager/#subscribeepoch","text":"This message is sent to the EpochManager actor when the ChainManager actor is started, in order to subscribe to the next epoch (test functionality). Subscribing to the next epoch means that the EpochManager will send an EpochNotification<EpochPayload> back to the ChainManager when the epoch is reached. For further information, see EpochManager .","title":"SubscribeEpoch"},{"location":"architecture/managers/chain-manager/#subscribeall","text":"This message is sent to the EpochManager actor when the Chain Manager actor is started, in order to subscribe to the all epochs. Subscribing to all epochs means that the EpochManager will send an EpochNotification<EveryEpochPayload> back to the ChainManager when every epoch is reached. For further information, see EpochManager .","title":"SubscribeAll"},{"location":"architecture/managers/chain-manager/#getconfig","text":"This message is sent to the [ ConfigManager ][config_manager] actor when the peers manager actor is started. The return value is used to initialize the list of known peers, and to decide whether or not enable the mining. For further information, see [ ConfigManager ][config_manager].","title":"GetConfig"},{"location":"architecture/managers/chain-manager/#get","text":"This message is sent to the StorageManager actor when the Chain Manager actor is started. The return value is a ChainInfo structure from the storage which are added to the state of the actor.","title":"Get"},{"location":"architecture/managers/chain-manager/#put","text":"This message is sent to the StorageManager actor to persist the ChainInfo structure The return value is used to check if the storage process has been successful.","title":"Put"},{"location":"architecture/managers/chain-manager/#broadcast","text":"This message is sent to the SessionsManager actor which will broadcast a AnnounceItems message to the open outbound sessions.","title":"Broadcast"},{"location":"architecture/managers/chain-manager/#additem","text":"This message is sent to the InventoryManager actor as a InventoryItem to persist the block_candidate state.","title":"AddItem"},{"location":"architecture/managers/chain-manager/#further-information","text":"The full source code of the ChainManager can be found at chain_manager.rs .","title":"Further information"},{"location":"architecture/managers/config-manager/","text":"Config Manager \u00b6 The config manager is the actor in charge of managing the configuration required by the system. Its main responsibilities are the following: Load configuration from a file (if specified when creating the actor) and merge it with the default configuration Store configuration parameters on its state Provide a deep-copy of the configuration to other actors State \u00b6 The state of the Config Manager is defined as library code 'Config' , which contains the actual definition of the Config struct, along with the different loaders ( witnet_config::loaders ). #[derive(Debug, Default)] pub struct ConfigManager { /// Loaded configuration config : Config , /// Configuration file from which to read the configuration when /// the actor starts, if `None` the default configuration is used filename : Option < String > , } Actor creation and registration \u00b6 The creation of the config manager actor and its registration into the system registry are performed directly by the main process as follows: const CONFIG_DEFAULT_FILENAME : & str = \"witnet.toml\" ; let config_manager_addr = ConfigManager :: new ( CONFIG_DEFAULT_FILENAME ). start (); System :: current (). registry (). set ( config_manager_addr ); In case of no configuration file, a default instantiation may be used. All configuration parameters will be set to their default values. let config_manager_addr = ConfigManager :: default (). start (); System :: current (). registry (). set ( config_manager_addr ); API \u00b6 Incoming messages: Others -> Config Manager \u00b6 These are the messages supported by the config manager actor: Message Input type Output type Description GetConfig () ConfigResult Request a deep-copy of the configuration Where ConfigResult is just: /// Result of the GetConfig message handling pub type ConfigResult = Result < Config , io :: Error > ; The way other actors will communicate with the config manager is: Get the address of the config manager from the registry: // Get config manager address let config_manager_addr = System :: current (). registry (). get :: < ConfigManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: config_manager_addr . send ( GetConfig ) . into_actor ( self ) . then ( | res , _act , _ctx | { // Process the response from config manager process_get_config_response ( res ) }) . and_then ( | config , _act , ctx | { // Do something with the config actix :: fut :: ok (()) }) . wait ( ctx ); Outgoing messages: Config manager -> Others \u00b6 The config manager is a simple wrapper over the config library and it does not need to start a communication with other actors in order to perform its functions. Further information \u00b6 The full source code of the Config can be found at config_manager.rs .","title":"Config Manager"},{"location":"architecture/managers/config-manager/#config-manager","text":"The config manager is the actor in charge of managing the configuration required by the system. Its main responsibilities are the following: Load configuration from a file (if specified when creating the actor) and merge it with the default configuration Store configuration parameters on its state Provide a deep-copy of the configuration to other actors","title":"Config Manager"},{"location":"architecture/managers/config-manager/#state","text":"The state of the Config Manager is defined as library code 'Config' , which contains the actual definition of the Config struct, along with the different loaders ( witnet_config::loaders ). #[derive(Debug, Default)] pub struct ConfigManager { /// Loaded configuration config : Config , /// Configuration file from which to read the configuration when /// the actor starts, if `None` the default configuration is used filename : Option < String > , }","title":"State"},{"location":"architecture/managers/config-manager/#actor-creation-and-registration","text":"The creation of the config manager actor and its registration into the system registry are performed directly by the main process as follows: const CONFIG_DEFAULT_FILENAME : & str = \"witnet.toml\" ; let config_manager_addr = ConfigManager :: new ( CONFIG_DEFAULT_FILENAME ). start (); System :: current (). registry (). set ( config_manager_addr ); In case of no configuration file, a default instantiation may be used. All configuration parameters will be set to their default values. let config_manager_addr = ConfigManager :: default (). start (); System :: current (). registry (). set ( config_manager_addr );","title":"Actor creation and registration"},{"location":"architecture/managers/config-manager/#api","text":"","title":"API"},{"location":"architecture/managers/config-manager/#incoming-messages-others-config-manager","text":"These are the messages supported by the config manager actor: Message Input type Output type Description GetConfig () ConfigResult Request a deep-copy of the configuration Where ConfigResult is just: /// Result of the GetConfig message handling pub type ConfigResult = Result < Config , io :: Error > ; The way other actors will communicate with the config manager is: Get the address of the config manager from the registry: // Get config manager address let config_manager_addr = System :: current (). registry (). get :: < ConfigManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: config_manager_addr . send ( GetConfig ) . into_actor ( self ) . then ( | res , _act , _ctx | { // Process the response from config manager process_get_config_response ( res ) }) . and_then ( | config , _act , ctx | { // Do something with the config actix :: fut :: ok (()) }) . wait ( ctx );","title":"Incoming messages: Others -&gt; Config Manager"},{"location":"architecture/managers/config-manager/#outgoing-messages-config-manager-others","text":"The config manager is a simple wrapper over the config library and it does not need to start a communication with other actors in order to perform its functions.","title":"Outgoing messages: Config manager -&gt; Others"},{"location":"architecture/managers/config-manager/#further-information","text":"The full source code of the Config can be found at config_manager.rs .","title":"Further information"},{"location":"architecture/managers/connections-manager/","text":"Connections Manager \u00b6 The connections manager is the actor in charge of providing: A TCP server bound to the address indicated by the configuration file As many TCP clients as requested, connected to the addresses requested by the Sessions Manager State \u00b6 The Connections Manager actor has no proper state. /// Connections manager actor #[derive(Default)] pub struct ConnectionsManager ; Actor creation and registration \u00b6 The creation of the connections manager actor and its registration into the system registry are performed directly by the main process: let connections_manager_addr = ConnectionsManager :: default (). start (); System :: current (). registry (). set ( connections_manager_addr ); API \u00b6 Incoming messages: Others -> Connections Manager \u00b6 These are the messages supported by the connections manager handlers: Message Input type Output type Description InboundTcpConnect TcpStream () Request to create a session from an incoming TCP connection OutboundTcpConnect SocketAddr () Request to create a start a TCP connection to a peer The way other actors will communicate with the connections manager is: Get the address of the connections manager from the registry: // Get connections manager address let connections_manager_addr = System :: current (). registry (). get :: < ConnectionsManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: // Send a message to the connections manager connections_manager_addr . do_send ( OutboundTcpConnect { address }); InboundTcpConnect message \u00b6 The InboundTcpConnect message is sent to the ConnectionsManager by the ConnectionsManager itself. In the started method of the connections manager actor, the server address is requested from the ConfigManager actor and a TCP listener is created and bound to that address: // Get address to launch the server let server_address = \"127.0.0.1:50005\" . parse (). unwrap (); // Bind TCP listener to this address let listener = TcpListener :: bind ( & server_address ). unwrap (); For each incoming TCP connection that comes into the TCP listener, an InboundTcpConnect message is created from the TCP stream and sent to the actor: // Add message stream which returns an InboundTcpConnect for each incoming TCP connection ctx . add_message_stream ( listener . incoming () . map_err ( | _ | ()) . map ( InboundTcpConnect :: new ), ); When an InboundTcpConnect message arrives at the connections manager actor, the creation of a new Inbound session is requested to the SessionsManager : /// Method to handle the InboundTcpConnect message fn handle ( & mut self , msg : InboundTcpConnect , _ctx : & mut Self :: Context ) { // Request the creation of a new session actor from connection ConnectionsManager :: request_session_creation ( msg . stream , SessionType :: Inbound ); } OutboundTcpConnect message \u00b6 The OutboundTcpConnect message is sent to the ConnectionsManager by the SessionsManager . When an OutboundTcpConnect message arrives at the connections manager actor, several actions are performed: Send a ConnectAddr message to the Resolver actor to connect to the requested peer address Handle the result: If an error is returned, do nothing but log it If successful, request the creation of an Outbound session to the SessionsManager /// Method to handle the OutboundTcpConnect message fn handle ( & mut self , msg : OutboundTcpConnect , ctx : & mut Self :: Context ) { // Get resolver from registry and send a ConnectAddr message to it Resolver :: from_registry () . send ( ConnectAddr ( msg . address )) . into_actor ( self ) . then ( | res , _act , _ctx | ConnectionsManager :: process_connect_addr_response ( res )) . wait ( ctx ); } Outgoing messages: Connections Manager -> Others \u00b6 These are the messages sent by the connections manager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request the configuration ConnectAddr Resolver SocketAddr Result<TcpStream, ResolverError> Request a TCP conn to an address Create SessionsManager TcpStream, SessionType () Request the creation of a session GetConfig \u00b6 This message is sent to the ConfigManager actor when the connections manager actor is started. The return value is used to get the TCP server address of the Witnet node and launch it. For further information, see ConfigManager . ConnectAddr \u00b6 This message is sent to the Resolver actor when an OutboundTcpConnect message is received. Upon reception of this message, the Resolver tries to open a TCP connection to the address specified in the message. For further information, see Resolver . Create \u00b6 This message is sent to the SessionsManager actor when a TCP connection is established to request the creation of a session. For further information, see SessionsManager . Further information \u00b6 The full source code of the ConnectionsManager can be found at connections_manager.rs .","title":"Connections Manager"},{"location":"architecture/managers/connections-manager/#connections-manager","text":"The connections manager is the actor in charge of providing: A TCP server bound to the address indicated by the configuration file As many TCP clients as requested, connected to the addresses requested by the Sessions Manager","title":"Connections Manager"},{"location":"architecture/managers/connections-manager/#state","text":"The Connections Manager actor has no proper state. /// Connections manager actor #[derive(Default)] pub struct ConnectionsManager ;","title":"State"},{"location":"architecture/managers/connections-manager/#actor-creation-and-registration","text":"The creation of the connections manager actor and its registration into the system registry are performed directly by the main process: let connections_manager_addr = ConnectionsManager :: default (). start (); System :: current (). registry (). set ( connections_manager_addr );","title":"Actor creation and registration"},{"location":"architecture/managers/connections-manager/#api","text":"","title":"API"},{"location":"architecture/managers/connections-manager/#incoming-messages-others-connections-manager","text":"These are the messages supported by the connections manager handlers: Message Input type Output type Description InboundTcpConnect TcpStream () Request to create a session from an incoming TCP connection OutboundTcpConnect SocketAddr () Request to create a start a TCP connection to a peer The way other actors will communicate with the connections manager is: Get the address of the connections manager from the registry: // Get connections manager address let connections_manager_addr = System :: current (). registry (). get :: < ConnectionsManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: // Send a message to the connections manager connections_manager_addr . do_send ( OutboundTcpConnect { address });","title":"Incoming messages: Others -&gt; Connections Manager"},{"location":"architecture/managers/connections-manager/#inboundtcpconnect-message","text":"The InboundTcpConnect message is sent to the ConnectionsManager by the ConnectionsManager itself. In the started method of the connections manager actor, the server address is requested from the ConfigManager actor and a TCP listener is created and bound to that address: // Get address to launch the server let server_address = \"127.0.0.1:50005\" . parse (). unwrap (); // Bind TCP listener to this address let listener = TcpListener :: bind ( & server_address ). unwrap (); For each incoming TCP connection that comes into the TCP listener, an InboundTcpConnect message is created from the TCP stream and sent to the actor: // Add message stream which returns an InboundTcpConnect for each incoming TCP connection ctx . add_message_stream ( listener . incoming () . map_err ( | _ | ()) . map ( InboundTcpConnect :: new ), ); When an InboundTcpConnect message arrives at the connections manager actor, the creation of a new Inbound session is requested to the SessionsManager : /// Method to handle the InboundTcpConnect message fn handle ( & mut self , msg : InboundTcpConnect , _ctx : & mut Self :: Context ) { // Request the creation of a new session actor from connection ConnectionsManager :: request_session_creation ( msg . stream , SessionType :: Inbound ); }","title":"InboundTcpConnect message"},{"location":"architecture/managers/connections-manager/#outboundtcpconnect-message","text":"The OutboundTcpConnect message is sent to the ConnectionsManager by the SessionsManager . When an OutboundTcpConnect message arrives at the connections manager actor, several actions are performed: Send a ConnectAddr message to the Resolver actor to connect to the requested peer address Handle the result: If an error is returned, do nothing but log it If successful, request the creation of an Outbound session to the SessionsManager /// Method to handle the OutboundTcpConnect message fn handle ( & mut self , msg : OutboundTcpConnect , ctx : & mut Self :: Context ) { // Get resolver from registry and send a ConnectAddr message to it Resolver :: from_registry () . send ( ConnectAddr ( msg . address )) . into_actor ( self ) . then ( | res , _act , _ctx | ConnectionsManager :: process_connect_addr_response ( res )) . wait ( ctx ); }","title":"OutboundTcpConnect message"},{"location":"architecture/managers/connections-manager/#outgoing-messages-connections-manager-others","text":"These are the messages sent by the connections manager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request the configuration ConnectAddr Resolver SocketAddr Result<TcpStream, ResolverError> Request a TCP conn to an address Create SessionsManager TcpStream, SessionType () Request the creation of a session","title":"Outgoing messages: Connections Manager -&gt; Others"},{"location":"architecture/managers/connections-manager/#getconfig","text":"This message is sent to the ConfigManager actor when the connections manager actor is started. The return value is used to get the TCP server address of the Witnet node and launch it. For further information, see ConfigManager .","title":"GetConfig"},{"location":"architecture/managers/connections-manager/#connectaddr","text":"This message is sent to the Resolver actor when an OutboundTcpConnect message is received. Upon reception of this message, the Resolver tries to open a TCP connection to the address specified in the message. For further information, see Resolver .","title":"ConnectAddr"},{"location":"architecture/managers/connections-manager/#create","text":"This message is sent to the SessionsManager actor when a TCP connection is established to request the creation of a session. For further information, see SessionsManager .","title":"Create"},{"location":"architecture/managers/connections-manager/#further-information","text":"The full source code of the ConnectionsManager can be found at connections_manager.rs .","title":"Further information"},{"location":"architecture/managers/epoch-manager/","text":"Epoch Manager \u00b6 The epoch manager is the actor that handles the logic related to epochs: it knows the current epoch based on the current time and the timestamp of checkpoint zero (the start of epoch zero) and allows other actors to subscribe to specific checkpoints. The current epoch can be calculated as: (current_timestamp - checkpoint_zero_timestamp) / checkpoint_period State \u00b6 The state of the actor contains the values needed to determine the current epoch, as well as a list of subscriptions. pub struct EpochManager { /// Checkpoint corresponding to the start of epoch #0 checkpoint_zero_timestamp : Option < i64 > , /// Period between checkpoints checkpoints_period : Option < u16 > , /// Subscriptions to a particular epoch subscriptions_epoch : BTreeMap < Epoch , Vec < Box < dyn SendableNotification >>> , /// Subscriptions to all epochs subscriptions_all : Vec < Box < dyn SendableNotification >> , /// Last epoch that was checked by the epoch monitor process last_checked_epoch : Option < Epoch > , } Actor creation and registration \u00b6 The creation of the epoch manager actor and its registration into the system registry are performed directly by the main process node.rs : let epoch_manager_addr = EpochManager :: default (). start (); System :: current (). registry (). set ( epoch_manager_addr ); API \u00b6 Incoming: Others -> EpochManager \u00b6 These are the messages supported by the EpochManager handlers: Message Input type Output type Description GetEpoch () EpochResult<Epoch> Returns the current epoch id (last checkpoint) SubscribeEpoch Epoch, Box<dyn SendableNotification> () Subscribe to a specific checkpoint (the start that epoch) SubscribeAll Box<dyn SendableNotification> () Subscribe to all future checkpoints SubscribeEpoch and SubscribeAll are created using a helper function as detailed in the section subscribe . The GetEpoch message wraps the current_epoch() method: fn handle ( & mut self , _msg : GetEpoch , _ctx : & mut Self :: Context ) -> EpochResult < Epoch > { let r = self . current_epoch (); debug ! ( \"Current epoch: {:?}\" , r ); r } The EpochResult type is just a wrapper around a result with an EpochManagerError . pub type EpochResult < T > = Result < T , EpochManagerError > ; The EpochManagerError is defined as: pub enum EpochManagerError { /// Epoch zero time is unknown UnknownEpochZero , /// Checkpoint period is unknown UnknownCheckpointPeriod , /// Checkpoint zero is in the future CheckpointZeroInTheFuture , /// Overflow when calculating the epoch timestamp Overflow , } The way other actors will communicate with the epoch manager is: Get the address of the manager from the registry: // Get epoch manager address let epoch_manager_addr = System :: current (). registry (). get :: < EpochManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: // Example epoch_manager_addr . send ( GetEpoch ) . into_actor ( self ) . then ( | res , _act , _ctx | { match res { Ok ( res ) => { // Process EpochResult println ! ( \"GetEpoch returned {:?}\" , res ) }, _ => println ! ( \"Something went really wrong in the actors message passing\" ) }; actix :: fut :: ok (()) }) . wait ( ctx ); Subscribe to a specific checkpoint \u00b6 In order to subscribe to a specific epoch, the actors need the epoch_manager_addr and the current epoch. For example to subscribe to the next checkpoint: // The payload we send with `EpochNotification` struct EpochPayload ; // Get the current epoch from `EpochManager` // let epoch = ... // Get the address of the current actor let self_addr = ctx . address (); // Subscribe to the next epoch with an Update epoch_manager_addr . do_send ( Subscribe :: to_epoch ( Epoch ( epoch . 0 + 1 ), self_addr , EpochPayload , )); The logic is implemented as an EpochNotification<T> handler, where T is one specific payload. /// Handler for EpochNotification<EpochPayload> impl Handler < EpochNotification < EpochPayload >> for BlockManager { type Result = (); fn handle ( & mut self , msg : EpochNotification < EpochPayload > , _ctx : & mut Context < Self > ) { debug ! ( \"Epoch notification received {:?}\" , msg . checkpoint ); } } It is assumed that subscribing cannot fail. However, if the EpochManager skips some checkpoints, all the missed notifications will be sent at the next checkpoint but with the old requested checkpoint in the message. The notifications are sent according to their checkpoint id: the oldest checkpoints first. Subscribe to all new checkpoints \u00b6 In order to receive a notification on each checkpoint, the actors need to subscribe with a cloneable payload. If an actor doesn't need a payload, a type like () or an empty struct can be used. #[derive(Clone)] struct EveryEpochPayload ; // Subscribe to all epochs with a cloneable payload epoch_manager_addr . do_send ( Subscribe :: to_all ( self_addr , EveryEpochPayload , )); The logic is implemented as an EpochNotification<T> handler, where T is one specific payload. /// Handler for EpochNotification<EveryEpochPayload> impl Handler < EpochNotification < EveryEpochPayload >> for BlockManager { type Result = (); fn handle ( & mut self , msg : EpochNotification < EveryEpochPayload > , _ctx : & mut Context < Self > ) { debug ! ( \"Periodic epoch notification received {:?}\" , msg . checkpoint ); } } In case of skipped epochs, the notifications are lost. Outgoing messages: EpochManager -> Others \u00b6 These are the messages sent by the EpochManager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request the configuration EpochNotification<T> * Epoch, T () A notification sent at the start of the requested epoch GetConfig \u00b6 This message is sent to the ConfigManager actor when the epoch manager actor is started. The return value is used to initialize the protocol constants (checkpoint period and epoch zero timestamp). For further information, see ConfigManager . EpochNotification \u00b6 This message is sent to all the actors which are subscribed to the epoch that just started. There are two types of subscriptions: SubscriptionEpoch only sends the EpochNotification once. SubscriptionAll sends an EpochNotification at every checkpoint. The EpochNotification is defined as: #[derive(Message)] pub struct EpochNotification < T : Send > { /// Epoch that has just started pub checkpoint : Epoch , /// Payload for the epoch notification pub payload : T , } Therefore it can be accessed in the message handler as: let epoch = msg . checkpoint ; let payload = msg . payload ; Further information \u00b6 The full source code of the EpochManager can be found at epoch_manager.rs .","title":"Epoch Manager"},{"location":"architecture/managers/epoch-manager/#epoch-manager","text":"The epoch manager is the actor that handles the logic related to epochs: it knows the current epoch based on the current time and the timestamp of checkpoint zero (the start of epoch zero) and allows other actors to subscribe to specific checkpoints. The current epoch can be calculated as: (current_timestamp - checkpoint_zero_timestamp) / checkpoint_period","title":"Epoch Manager"},{"location":"architecture/managers/epoch-manager/#state","text":"The state of the actor contains the values needed to determine the current epoch, as well as a list of subscriptions. pub struct EpochManager { /// Checkpoint corresponding to the start of epoch #0 checkpoint_zero_timestamp : Option < i64 > , /// Period between checkpoints checkpoints_period : Option < u16 > , /// Subscriptions to a particular epoch subscriptions_epoch : BTreeMap < Epoch , Vec < Box < dyn SendableNotification >>> , /// Subscriptions to all epochs subscriptions_all : Vec < Box < dyn SendableNotification >> , /// Last epoch that was checked by the epoch monitor process last_checked_epoch : Option < Epoch > , }","title":"State"},{"location":"architecture/managers/epoch-manager/#actor-creation-and-registration","text":"The creation of the epoch manager actor and its registration into the system registry are performed directly by the main process node.rs : let epoch_manager_addr = EpochManager :: default (). start (); System :: current (). registry (). set ( epoch_manager_addr );","title":"Actor creation and registration"},{"location":"architecture/managers/epoch-manager/#api","text":"","title":"API"},{"location":"architecture/managers/epoch-manager/#incoming-others-epochmanager","text":"These are the messages supported by the EpochManager handlers: Message Input type Output type Description GetEpoch () EpochResult<Epoch> Returns the current epoch id (last checkpoint) SubscribeEpoch Epoch, Box<dyn SendableNotification> () Subscribe to a specific checkpoint (the start that epoch) SubscribeAll Box<dyn SendableNotification> () Subscribe to all future checkpoints SubscribeEpoch and SubscribeAll are created using a helper function as detailed in the section subscribe . The GetEpoch message wraps the current_epoch() method: fn handle ( & mut self , _msg : GetEpoch , _ctx : & mut Self :: Context ) -> EpochResult < Epoch > { let r = self . current_epoch (); debug ! ( \"Current epoch: {:?}\" , r ); r } The EpochResult type is just a wrapper around a result with an EpochManagerError . pub type EpochResult < T > = Result < T , EpochManagerError > ; The EpochManagerError is defined as: pub enum EpochManagerError { /// Epoch zero time is unknown UnknownEpochZero , /// Checkpoint period is unknown UnknownCheckpointPeriod , /// Checkpoint zero is in the future CheckpointZeroInTheFuture , /// Overflow when calculating the epoch timestamp Overflow , } The way other actors will communicate with the epoch manager is: Get the address of the manager from the registry: // Get epoch manager address let epoch_manager_addr = System :: current (). registry (). get :: < EpochManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: // Example epoch_manager_addr . send ( GetEpoch ) . into_actor ( self ) . then ( | res , _act , _ctx | { match res { Ok ( res ) => { // Process EpochResult println ! ( \"GetEpoch returned {:?}\" , res ) }, _ => println ! ( \"Something went really wrong in the actors message passing\" ) }; actix :: fut :: ok (()) }) . wait ( ctx );","title":"Incoming: Others -&gt; EpochManager"},{"location":"architecture/managers/epoch-manager/#subscribe-to-a-specific-checkpoint","text":"In order to subscribe to a specific epoch, the actors need the epoch_manager_addr and the current epoch. For example to subscribe to the next checkpoint: // The payload we send with `EpochNotification` struct EpochPayload ; // Get the current epoch from `EpochManager` // let epoch = ... // Get the address of the current actor let self_addr = ctx . address (); // Subscribe to the next epoch with an Update epoch_manager_addr . do_send ( Subscribe :: to_epoch ( Epoch ( epoch . 0 + 1 ), self_addr , EpochPayload , )); The logic is implemented as an EpochNotification<T> handler, where T is one specific payload. /// Handler for EpochNotification<EpochPayload> impl Handler < EpochNotification < EpochPayload >> for BlockManager { type Result = (); fn handle ( & mut self , msg : EpochNotification < EpochPayload > , _ctx : & mut Context < Self > ) { debug ! ( \"Epoch notification received {:?}\" , msg . checkpoint ); } } It is assumed that subscribing cannot fail. However, if the EpochManager skips some checkpoints, all the missed notifications will be sent at the next checkpoint but with the old requested checkpoint in the message. The notifications are sent according to their checkpoint id: the oldest checkpoints first.","title":"Subscribe to a specific checkpoint"},{"location":"architecture/managers/epoch-manager/#subscribe-to-all-new-checkpoints","text":"In order to receive a notification on each checkpoint, the actors need to subscribe with a cloneable payload. If an actor doesn't need a payload, a type like () or an empty struct can be used. #[derive(Clone)] struct EveryEpochPayload ; // Subscribe to all epochs with a cloneable payload epoch_manager_addr . do_send ( Subscribe :: to_all ( self_addr , EveryEpochPayload , )); The logic is implemented as an EpochNotification<T> handler, where T is one specific payload. /// Handler for EpochNotification<EveryEpochPayload> impl Handler < EpochNotification < EveryEpochPayload >> for BlockManager { type Result = (); fn handle ( & mut self , msg : EpochNotification < EveryEpochPayload > , _ctx : & mut Context < Self > ) { debug ! ( \"Periodic epoch notification received {:?}\" , msg . checkpoint ); } } In case of skipped epochs, the notifications are lost.","title":"Subscribe to all new checkpoints"},{"location":"architecture/managers/epoch-manager/#outgoing-messages-epochmanager-others","text":"These are the messages sent by the EpochManager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request the configuration EpochNotification<T> * Epoch, T () A notification sent at the start of the requested epoch","title":"Outgoing messages: EpochManager -&gt; Others"},{"location":"architecture/managers/epoch-manager/#getconfig","text":"This message is sent to the ConfigManager actor when the epoch manager actor is started. The return value is used to initialize the protocol constants (checkpoint period and epoch zero timestamp). For further information, see ConfigManager .","title":"GetConfig"},{"location":"architecture/managers/epoch-manager/#epochnotification","text":"This message is sent to all the actors which are subscribed to the epoch that just started. There are two types of subscriptions: SubscriptionEpoch only sends the EpochNotification once. SubscriptionAll sends an EpochNotification at every checkpoint. The EpochNotification is defined as: #[derive(Message)] pub struct EpochNotification < T : Send > { /// Epoch that has just started pub checkpoint : Epoch , /// Payload for the epoch notification pub payload : T , } Therefore it can be accessed in the message handler as: let epoch = msg . checkpoint ; let payload = msg . payload ;","title":"EpochNotification"},{"location":"architecture/managers/epoch-manager/#further-information","text":"The full source code of the EpochManager can be found at epoch_manager.rs .","title":"Further information"},{"location":"architecture/managers/inventory-manager/","text":"Page under construction. Check back soon. \u00b6","title":"Inventory Manager"},{"location":"architecture/managers/inventory-manager/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"architecture/managers/managers/","text":"Managers \u00b6 Managers are actors that are in charge of some state and that offer some functionality to other actors (which may be managers as well or not). The way managers offer their functionality is by handling different types of messages that other actors can send to them and by responding to them (if necessary). Also, some managers may have periodic tasks in order to update their state or perform some actions. When possible, the logic of the manager will not be placed in the actor itself, but in a separated library in order to decouple the logic as much as possible from the Actix ecosystem. There can only be one manager actor of each type per system, and they must be registered into the system registry. This way, any other actor can get the address of the any manager and send messages to it. State \u00b6 A manager actor is defined as a struct with some (or no) state: /// Any manager actor #[derive(Default)] pub struct Manager { // Whichever state it might need state : ManagerState , } In order to become actors, the managers must implement the Actor trait: /// Make actor from `Manager` impl Actor for Manager { /// Every actor has to provide execution `Context` in which it can run. type Context = Context < Self > ; /// Method that is executed when the actor is started fn started ( & mut self , _ctx : & mut Self :: Context ) { debug ! ( \"Manager actor has been started!\" ) } } Manager actors require the implementation of the Default trait (as well as Supervised and SystemService traits) to become a service that can be registered in the system registry. Actor creation and registration \u00b6 The creation of a manager actor is usually performed directly by the main process: let manager_addr = Manager :: default (). start (); Once the manager actor is started, the main process registers the manager into the system registry: System :: current (). registry (). set ( manager_addr ); API \u00b6 Messages \u00b6 Messages are defined as structs that contain some input parameters and that must implement the Message trait. In the Message trait, the Result type needs to be specified. This type is the return type of the function that will handle the message when it arrives: /// Message handled by the manager pub struct ManagerMessage { /// Parameter pub param : ParamType , } impl Message for ManagerMessage { type Result = ManagerMessageResult ; } Incoming messages: Other actors -> Manager \u00b6 When a ManagerMessage message arrives at the manager actor, it has to be processed by a handler function. That handler function needs to be defined inside the Handler<ManagerMessage> trait of the manager. This trait must also define the Result type as well, just like it was done in the implementation of the Message trait: /// Handler for ManagerMessage message impl Handler < ManagerMessage > for Manager { type Result = ManagerMessageResult ; fn handle ( & mut self , msg : ManagerMessage , _ : & mut Context < Self > ) -> Self :: Result { // Do things to handle the message } } Outgoing messages: Manager -> Other actors \u00b6 The way the manager will communicate with other actors is: Get the address of the other manager from the registry: // Get other manager address let other_manager_addr = System :: current (). registry (). get :: < OtherManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: // Example other_manager_addr . send ( OtherManagerMessage { other_param }) . into_actor ( self ) . then ( | res , _act , _ctx | { actix :: fut :: ok (()) }) . wait ( ctx );","title":"Introduction"},{"location":"architecture/managers/managers/#managers","text":"Managers are actors that are in charge of some state and that offer some functionality to other actors (which may be managers as well or not). The way managers offer their functionality is by handling different types of messages that other actors can send to them and by responding to them (if necessary). Also, some managers may have periodic tasks in order to update their state or perform some actions. When possible, the logic of the manager will not be placed in the actor itself, but in a separated library in order to decouple the logic as much as possible from the Actix ecosystem. There can only be one manager actor of each type per system, and they must be registered into the system registry. This way, any other actor can get the address of the any manager and send messages to it.","title":"Managers"},{"location":"architecture/managers/managers/#state","text":"A manager actor is defined as a struct with some (or no) state: /// Any manager actor #[derive(Default)] pub struct Manager { // Whichever state it might need state : ManagerState , } In order to become actors, the managers must implement the Actor trait: /// Make actor from `Manager` impl Actor for Manager { /// Every actor has to provide execution `Context` in which it can run. type Context = Context < Self > ; /// Method that is executed when the actor is started fn started ( & mut self , _ctx : & mut Self :: Context ) { debug ! ( \"Manager actor has been started!\" ) } } Manager actors require the implementation of the Default trait (as well as Supervised and SystemService traits) to become a service that can be registered in the system registry.","title":"State"},{"location":"architecture/managers/managers/#actor-creation-and-registration","text":"The creation of a manager actor is usually performed directly by the main process: let manager_addr = Manager :: default (). start (); Once the manager actor is started, the main process registers the manager into the system registry: System :: current (). registry (). set ( manager_addr );","title":"Actor creation and registration"},{"location":"architecture/managers/managers/#api","text":"","title":"API"},{"location":"architecture/managers/managers/#messages","text":"Messages are defined as structs that contain some input parameters and that must implement the Message trait. In the Message trait, the Result type needs to be specified. This type is the return type of the function that will handle the message when it arrives: /// Message handled by the manager pub struct ManagerMessage { /// Parameter pub param : ParamType , } impl Message for ManagerMessage { type Result = ManagerMessageResult ; }","title":"Messages"},{"location":"architecture/managers/managers/#incoming-messages-other-actors-manager","text":"When a ManagerMessage message arrives at the manager actor, it has to be processed by a handler function. That handler function needs to be defined inside the Handler<ManagerMessage> trait of the manager. This trait must also define the Result type as well, just like it was done in the implementation of the Message trait: /// Handler for ManagerMessage message impl Handler < ManagerMessage > for Manager { type Result = ManagerMessageResult ; fn handle ( & mut self , msg : ManagerMessage , _ : & mut Context < Self > ) -> Self :: Result { // Do things to handle the message } }","title":"Incoming messages: Other actors -&gt; Manager"},{"location":"architecture/managers/managers/#outgoing-messages-manager-other-actors","text":"The way the manager will communicate with other actors is: Get the address of the other manager from the registry: // Get other manager address let other_manager_addr = System :: current (). registry (). get :: < OtherManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: // Example other_manager_addr . send ( OtherManagerMessage { other_param }) . into_actor ( self ) . then ( | res , _act , _ctx | { actix :: fut :: ok (()) }) . wait ( ctx );","title":"Outgoing messages: Manager -&gt; Other actors"},{"location":"architecture/managers/peers-manager/","text":"Peers Manager \u00b6 The peers manager is the actor that encapsulates the logic of the peers library, defined under the subcrate witnet_p2p . The library allows to manage a list of peers known to the Witnet node. State \u00b6 The state of the actor is an instance of the Peers library, which contains a list of peers known to the Witnet node. #[derive(Default)] pub struct PeersManager { /// Known peers peers : Peers , } Actor creation and registration \u00b6 The creation of the peers manager actor and its registration into the system registry are performed directly by the main process: let peers_manager_addr = PeersManager :: default (). start (); System :: current (). registry (). set ( peers_manager_addr ); API \u00b6 Incoming: Others -> Peers Manager \u00b6 These are the messages supported by the peers manager handlers: Message Input type Output type Description AddPeers address : SocketAddr PeersResult<Vec<SocketAddr>> Add peers to list RemovePeers address : SocketAddr PeersResult<Vec<SocketAddr>> Remove peers from list GetRandomPeer () PeersResult<Option<SocketAddr>> Get random peer RequestPeers () PeersResult<Vec<SocketAddr>> Get all peers The handling of these messages is basically just calling the corresponding methods from the Peers library that is implemented by peers.rs . For example, the handler of the AddPeers message would be implemented as: /// Handler for AddPeers message impl Handler < AddPeers > for PeersManager { type Result = PeersSocketAddrsResult ; fn handle ( & mut self , msg : AddPeers , _ : & mut Context < Self > ) -> Self :: Result { // Insert address debug ! ( \"Add peer handle for addresses: {:?}\" , msg . addresses ); self . peers . add ( msg . addresses ) } } Being the PeersManager such a simple actor, there are no errors that can arise due to its own logic and thus, returning a PeersResult library generic error may be the right thing to do. The way other actors will communicate with the storage manager is: Get the address of the manager from the registry: // Get peers manager address let peers_manager_addr = System :: current (). registry (). get :: < PeersManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: // Example peers_manager_addr . send ( AddPeers { addresses }) . into_actor ( self ) . then ( | res , _act , _ctx | { match res { Ok ( res ) => { // Process PeersResult println ! ( \"Add peer {:?} returned {:?}\" , addresses , res ) }, _ => println ! ( \"Something went really wrong in the actors message passing\" ) }; actix :: fut :: ok (()) }) . wait ( ctx ); Outgoing messages: Peers Manager -> Others \u00b6 These are the messages sent by the peers manager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request the configuration Get StorageManager &'static [u8] StorageResult<Option<T>> Wrapper to Storage get() method Put StorageManager &'static [u8] , Vec<u8> StorageResult<()> Wrapper to Storage put() method GetConfig \u00b6 This message is sent to the ConfigManager actor when the peers manager actor is started. The return value is used to initialize the list of known peers. For further information, see ConfigManager . Get \u00b6 This message is sent to the StorageManager actor when the peers manager actor is started. The return value is a list of peers from the storage which are added to the list of known peers. Put \u00b6 This message is sent to the StorageManager actor periodically using a period obtained from ConfigManager The return value is used to check if the storage process has been successful. Further information \u00b6 The full source code of the PeersManager can be found at peers_manager.rs .","title":"Peers Manager"},{"location":"architecture/managers/peers-manager/#peers-manager","text":"The peers manager is the actor that encapsulates the logic of the peers library, defined under the subcrate witnet_p2p . The library allows to manage a list of peers known to the Witnet node.","title":"Peers Manager"},{"location":"architecture/managers/peers-manager/#state","text":"The state of the actor is an instance of the Peers library, which contains a list of peers known to the Witnet node. #[derive(Default)] pub struct PeersManager { /// Known peers peers : Peers , }","title":"State"},{"location":"architecture/managers/peers-manager/#actor-creation-and-registration","text":"The creation of the peers manager actor and its registration into the system registry are performed directly by the main process: let peers_manager_addr = PeersManager :: default (). start (); System :: current (). registry (). set ( peers_manager_addr );","title":"Actor creation and registration"},{"location":"architecture/managers/peers-manager/#api","text":"","title":"API"},{"location":"architecture/managers/peers-manager/#incoming-others-peers-manager","text":"These are the messages supported by the peers manager handlers: Message Input type Output type Description AddPeers address : SocketAddr PeersResult<Vec<SocketAddr>> Add peers to list RemovePeers address : SocketAddr PeersResult<Vec<SocketAddr>> Remove peers from list GetRandomPeer () PeersResult<Option<SocketAddr>> Get random peer RequestPeers () PeersResult<Vec<SocketAddr>> Get all peers The handling of these messages is basically just calling the corresponding methods from the Peers library that is implemented by peers.rs . For example, the handler of the AddPeers message would be implemented as: /// Handler for AddPeers message impl Handler < AddPeers > for PeersManager { type Result = PeersSocketAddrsResult ; fn handle ( & mut self , msg : AddPeers , _ : & mut Context < Self > ) -> Self :: Result { // Insert address debug ! ( \"Add peer handle for addresses: {:?}\" , msg . addresses ); self . peers . add ( msg . addresses ) } } Being the PeersManager such a simple actor, there are no errors that can arise due to its own logic and thus, returning a PeersResult library generic error may be the right thing to do. The way other actors will communicate with the storage manager is: Get the address of the manager from the registry: // Get peers manager address let peers_manager_addr = System :: current (). registry (). get :: < PeersManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: // Example peers_manager_addr . send ( AddPeers { addresses }) . into_actor ( self ) . then ( | res , _act , _ctx | { match res { Ok ( res ) => { // Process PeersResult println ! ( \"Add peer {:?} returned {:?}\" , addresses , res ) }, _ => println ! ( \"Something went really wrong in the actors message passing\" ) }; actix :: fut :: ok (()) }) . wait ( ctx );","title":"Incoming: Others -&gt; Peers Manager"},{"location":"architecture/managers/peers-manager/#outgoing-messages-peers-manager-others","text":"These are the messages sent by the peers manager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request the configuration Get StorageManager &'static [u8] StorageResult<Option<T>> Wrapper to Storage get() method Put StorageManager &'static [u8] , Vec<u8> StorageResult<()> Wrapper to Storage put() method","title":"Outgoing messages: Peers Manager -&gt; Others"},{"location":"architecture/managers/peers-manager/#getconfig","text":"This message is sent to the ConfigManager actor when the peers manager actor is started. The return value is used to initialize the list of known peers. For further information, see ConfigManager .","title":"GetConfig"},{"location":"architecture/managers/peers-manager/#get","text":"This message is sent to the StorageManager actor when the peers manager actor is started. The return value is a list of peers from the storage which are added to the list of known peers.","title":"Get"},{"location":"architecture/managers/peers-manager/#put","text":"This message is sent to the StorageManager actor periodically using a period obtained from ConfigManager The return value is used to check if the storage process has been successful.","title":"Put"},{"location":"architecture/managers/peers-manager/#further-information","text":"The full source code of the PeersManager can be found at peers_manager.rs .","title":"Further information"},{"location":"architecture/managers/rad-manager/","text":"RadManager actor \u00b6 This module contains the RadManager actor which is in charge of receiving and executing Data Requests using the RAD Engine .","title":"RAD Manager"},{"location":"architecture/managers/rad-manager/#radmanager-actor","text":"This module contains the RadManager actor which is in charge of receiving and executing Data Requests using the RAD Engine .","title":"RadManager actor"},{"location":"architecture/managers/sessions-manager/","text":"Sessions Manager \u00b6 The sessions manager is the actor that handles incoming (inbound) and outgoing (outbound) sessions. Its responsibilities include: Create new sessions (i.e. starting a session actor) Register / unregister new sessions Keep track of the status of the sessions Periodically check the number of outgoing connections. If less than the configured number of outgoing peers, the sessions manager will: Request a new peer address from the PeersManager . Send a message to the ConnectionsManager to request a new TCP connection to that peer. The sessions manager is the actor that encapsulates the logic of the sessions library, defined under the subcrate witnet_p2p . The library allows to manage the sessions collection present at the Witnet node. State \u00b6 The state of the Sessions Manager is an instance of the Sessions library, which contains the collection of inbound and outbound sessions present at the Witnet node. #[derive(Default)] pub struct SessionsManager { // Registered sessions sessions : Sessions < Addr < Session >> , } The Sessions struct is generic over a type T, which is the type of the reference to the Session . As the actors paradigm is being used, this generic type T is the Addr of the Session actor. Actor creation and registration \u00b6 The creation of the sessions manager actor and its registration into the system registry are performed directly by the main process: let sessions_manager_addr = SessionsManager :: default (). start (); System :: current (). registry (). set ( sessions_manager_addr ); API \u00b6 Incoming messages: Others -> Sessions Manager \u00b6 These are the messages supported by the sessions manager handlers: Message Input type Output type Description Create TcpStream, SessionType () Request to create a new session Register SocketAddr, Addr<Session>, SessionType SessionsResult<()> Request to register a new session Unregister SocketAddr, SessionType, SessionStatus SessionsResult<()> Request to unregister a session Consolidate SocketAddr, SessionType SessionsResult<()> Request to consolidate a session Anycast<T> T, bool () Request to send a T message to a random consolidated outbound Session (when bool flag safu is true, use only outbound sessions in consensus) Broadcast<T> T () Request to send a T message to all the consolidated outbound sesions The handling of these messages is basically just calling the corresponding methods from the Sessions library. For example, the handler of the Register message would be implemented as: pub type SessionsUnitResult = SessionsResult < () > ; /// Handler for Register message. impl Handler < Register > for SessionsManager { type Result = SessionsUnitResult ; fn handle ( & mut self , msg : Register , _ : & mut Context < Self > ) -> Self :: Result { // Call method register session from sessions library self . sessions . register_session ( msg . session_type , msg . address , msg . actor ) } } Being the SessionsManager such a simple actor, there are no errors that can arise due to its own logic and thus, returning just a SessionsResult<()> library generic error may be the right thing to do. The way other actors will communicate with the sessions manager is: Get the address of the sessions manager from the registry: // Get sessions manager address let sessions_manager_addr = System :: current (). registry (). get :: < SessionsManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: session_manager_addr . send ( Register { address : self . address , actor : ctx . address (), session_type : self . session_type , }) . into_actor ( self ) . then ( | res , _act , ctx | { match res { Ok ( Ok ( _ )) => debug ! ( \"Session successfully registered into the Session Manager\" ), _ => debug ! ( \"Session register into Session Manager failed\" ) } actix :: fut :: ok (()) }) . wait ( ctx ); Anycast \u00b6 The handler for Anycast<T> messages is basically just calling the method get_random_anycast_session from the Sessions library to obtain a random Session and forward the T message to it. When bool flag safu is true, use only outbound consolidated sessions in consensus. The return value of the delegated call is processed by act.process_command_response(&res) /// Method to process session SendMessage response fn process_command_response < T > ( & mut self , response : & Result < T :: Result , MailboxError > , ) -> FutureResult < (), (), Self > where T : Message , Session : Handler < T > , { match response { Ok ( _ ) => actix :: fut :: ok (()), Err ( _ ) => actix :: fut :: err (()), } } Broadcast \u00b6 Similarly to the Anycast<T> handler, the handler for Broadcast<T> is just calling the method get_all_consolidated_outbound_sessions from Sessions library and forwards the message T to all the received addresses. This message does not do any error handling, the messages are all assumed to be successfully sent. Outgoing messages: Sessions Manager -> Others \u00b6 These are the messages sent by the sessions manager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request the configuration GetRandomPeer PeersManager () PeersResult<Option<SocketAddr>> Request the address of a peer OutboundTcpConnect ConnectionsManager SocketAddr () Request a TCP conn to an address Anycast<GetPeers> SessionsManager () () Request to forward a GetPeers message to one randomly selected Session GetConfig \u00b6 This message is sent to the ConfigManager actor when the sessions manager actor is started. The returned configuration is used to store some parameters at the Sessions state: Server address: used in the Witnet node to avoid connections with itself. Inbound limit: used to reject incoming connections once the limit has been reached. Outbound limit: used to stop requesting new outgoing connections once the limit has been reached. Handshake timeout: sent to the session upon creation to set a time limit to the handshake process. For further information, see ConfigManager . GetRandomPeer \u00b6 This message is sent to the PeersManager actor when the sessions manager actor detects that the number of outbound sessions registered is less than the configured limit. This detection is done in a bootstrap periodic task. The return value is then processed. If an error happened, nothing occurs. If the PeersManager returned an address, then the SessionsManager checks if it is valid and if so, it sends an OutboundTcpConnect message to the ConnectionsManager to start a new TCP connection to that address. In this context, a valid address means that: The address is not the own Witnet node's server address The address is not one of the already existing outbound connections For further information, see PeersManager . OutboundTcpConnect \u00b6 This message is sent to the ConnectionsManager actor when the sessions manager receives a valid peer address from the PeersManager . It is a best effort message, its return value is not processed and the sessions manager actor does not even wait for its response after sending it. If the operation was successful, the sessions manager will know it by other means (a session will be created and registered into the SessionsManager ). If the operation was not successful, then the sessions manager will detect in its next periodic bootstrap task that there are no new outbound connections and try to create a new one. For further information, see ConnectionsManager . Anycast \u00b6 Due to the SessionsManager having an Anycast<T> handler to forward a T message to one randomly selected Session , this message is periodically sent to itself. It is a best effort message, its return value is not processed and the SessionsManager actor does not even wait for its response after sending it. This message causes SessionManager to forward a GetPeers message to one randomly selected Session actor. Further information \u00b6 The full source code of the SessionsManager can be found at sessions_manager.rs .","title":"Sessions Manager"},{"location":"architecture/managers/sessions-manager/#sessions-manager","text":"The sessions manager is the actor that handles incoming (inbound) and outgoing (outbound) sessions. Its responsibilities include: Create new sessions (i.e. starting a session actor) Register / unregister new sessions Keep track of the status of the sessions Periodically check the number of outgoing connections. If less than the configured number of outgoing peers, the sessions manager will: Request a new peer address from the PeersManager . Send a message to the ConnectionsManager to request a new TCP connection to that peer. The sessions manager is the actor that encapsulates the logic of the sessions library, defined under the subcrate witnet_p2p . The library allows to manage the sessions collection present at the Witnet node.","title":"Sessions Manager"},{"location":"architecture/managers/sessions-manager/#state","text":"The state of the Sessions Manager is an instance of the Sessions library, which contains the collection of inbound and outbound sessions present at the Witnet node. #[derive(Default)] pub struct SessionsManager { // Registered sessions sessions : Sessions < Addr < Session >> , } The Sessions struct is generic over a type T, which is the type of the reference to the Session . As the actors paradigm is being used, this generic type T is the Addr of the Session actor.","title":"State"},{"location":"architecture/managers/sessions-manager/#actor-creation-and-registration","text":"The creation of the sessions manager actor and its registration into the system registry are performed directly by the main process: let sessions_manager_addr = SessionsManager :: default (). start (); System :: current (). registry (). set ( sessions_manager_addr );","title":"Actor creation and registration"},{"location":"architecture/managers/sessions-manager/#api","text":"","title":"API"},{"location":"architecture/managers/sessions-manager/#incoming-messages-others-sessions-manager","text":"These are the messages supported by the sessions manager handlers: Message Input type Output type Description Create TcpStream, SessionType () Request to create a new session Register SocketAddr, Addr<Session>, SessionType SessionsResult<()> Request to register a new session Unregister SocketAddr, SessionType, SessionStatus SessionsResult<()> Request to unregister a session Consolidate SocketAddr, SessionType SessionsResult<()> Request to consolidate a session Anycast<T> T, bool () Request to send a T message to a random consolidated outbound Session (when bool flag safu is true, use only outbound sessions in consensus) Broadcast<T> T () Request to send a T message to all the consolidated outbound sesions The handling of these messages is basically just calling the corresponding methods from the Sessions library. For example, the handler of the Register message would be implemented as: pub type SessionsUnitResult = SessionsResult < () > ; /// Handler for Register message. impl Handler < Register > for SessionsManager { type Result = SessionsUnitResult ; fn handle ( & mut self , msg : Register , _ : & mut Context < Self > ) -> Self :: Result { // Call method register session from sessions library self . sessions . register_session ( msg . session_type , msg . address , msg . actor ) } } Being the SessionsManager such a simple actor, there are no errors that can arise due to its own logic and thus, returning just a SessionsResult<()> library generic error may be the right thing to do. The way other actors will communicate with the sessions manager is: Get the address of the sessions manager from the registry: // Get sessions manager address let sessions_manager_addr = System :: current (). registry (). get :: < SessionsManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: session_manager_addr . send ( Register { address : self . address , actor : ctx . address (), session_type : self . session_type , }) . into_actor ( self ) . then ( | res , _act , ctx | { match res { Ok ( Ok ( _ )) => debug ! ( \"Session successfully registered into the Session Manager\" ), _ => debug ! ( \"Session register into Session Manager failed\" ) } actix :: fut :: ok (()) }) . wait ( ctx );","title":"Incoming messages: Others -&gt; Sessions Manager"},{"location":"architecture/managers/sessions-manager/#anycast","text":"The handler for Anycast<T> messages is basically just calling the method get_random_anycast_session from the Sessions library to obtain a random Session and forward the T message to it. When bool flag safu is true, use only outbound consolidated sessions in consensus. The return value of the delegated call is processed by act.process_command_response(&res) /// Method to process session SendMessage response fn process_command_response < T > ( & mut self , response : & Result < T :: Result , MailboxError > , ) -> FutureResult < (), (), Self > where T : Message , Session : Handler < T > , { match response { Ok ( _ ) => actix :: fut :: ok (()), Err ( _ ) => actix :: fut :: err (()), } }","title":"Anycast"},{"location":"architecture/managers/sessions-manager/#broadcast","text":"Similarly to the Anycast<T> handler, the handler for Broadcast<T> is just calling the method get_all_consolidated_outbound_sessions from Sessions library and forwards the message T to all the received addresses. This message does not do any error handling, the messages are all assumed to be successfully sent.","title":"Broadcast"},{"location":"architecture/managers/sessions-manager/#outgoing-messages-sessions-manager-others","text":"These are the messages sent by the sessions manager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request the configuration GetRandomPeer PeersManager () PeersResult<Option<SocketAddr>> Request the address of a peer OutboundTcpConnect ConnectionsManager SocketAddr () Request a TCP conn to an address Anycast<GetPeers> SessionsManager () () Request to forward a GetPeers message to one randomly selected Session","title":"Outgoing messages: Sessions Manager -&gt; Others"},{"location":"architecture/managers/sessions-manager/#getconfig","text":"This message is sent to the ConfigManager actor when the sessions manager actor is started. The returned configuration is used to store some parameters at the Sessions state: Server address: used in the Witnet node to avoid connections with itself. Inbound limit: used to reject incoming connections once the limit has been reached. Outbound limit: used to stop requesting new outgoing connections once the limit has been reached. Handshake timeout: sent to the session upon creation to set a time limit to the handshake process. For further information, see ConfigManager .","title":"GetConfig"},{"location":"architecture/managers/sessions-manager/#getrandompeer","text":"This message is sent to the PeersManager actor when the sessions manager actor detects that the number of outbound sessions registered is less than the configured limit. This detection is done in a bootstrap periodic task. The return value is then processed. If an error happened, nothing occurs. If the PeersManager returned an address, then the SessionsManager checks if it is valid and if so, it sends an OutboundTcpConnect message to the ConnectionsManager to start a new TCP connection to that address. In this context, a valid address means that: The address is not the own Witnet node's server address The address is not one of the already existing outbound connections For further information, see PeersManager .","title":"GetRandomPeer"},{"location":"architecture/managers/sessions-manager/#outboundtcpconnect","text":"This message is sent to the ConnectionsManager actor when the sessions manager receives a valid peer address from the PeersManager . It is a best effort message, its return value is not processed and the sessions manager actor does not even wait for its response after sending it. If the operation was successful, the sessions manager will know it by other means (a session will be created and registered into the SessionsManager ). If the operation was not successful, then the sessions manager will detect in its next periodic bootstrap task that there are no new outbound connections and try to create a new one. For further information, see ConnectionsManager .","title":"OutboundTcpConnect"},{"location":"architecture/managers/sessions-manager/#anycast_1","text":"Due to the SessionsManager having an Anycast<T> handler to forward a T message to one randomly selected Session , this message is periodically sent to itself. It is a best effort message, its return value is not processed and the SessionsManager actor does not even wait for its response after sending it. This message causes SessionManager to forward a GetPeers message to one randomly selected Session actor.","title":"Anycast"},{"location":"architecture/managers/sessions-manager/#further-information","text":"The full source code of the SessionsManager can be found at sessions_manager.rs .","title":"Further information"},{"location":"architecture/managers/storage-manager/","text":"Storage Manager \u00b6 The storage manager is the actor that encapsulates the logic of the persistent storage library. State \u00b6 The state of the actor is an instance of the RocksStorage backend encapsulated in an option. /// Storage manager actor #[derive(Default)] pub struct StorageManager { /// DB storage storage : Option < RocksStorage > , } The connection to the database is an Option to handle failures in the creation of the connection to the database. Actor creation and registration \u00b6 The creation of the storage manager actor is performed directly by the main process: let storage_manager_addr = StorageManager :: new ( & db_root ). start (); System :: current (). registry (). set ( storage_manager_addr ); The new() method tries to connect to the database specified in the path given as argument. If the connection is not possible for any reason, the storage in the state will be None . Otherwise, the state will contain the handle to the database for future use. Once the storage manager actor is started, the main process registers the actor into the system registry. API \u00b6 Incoming messages: Others -> Storage manager \u00b6 These are the messages supported by the storage manager handlers: Message Input type Output type Description Get &'static [u8] StorageResult<Option<Vec<u8>>> Wrapper to RocksStorage get() method Put &'static [u8] , Vec<u8> StorageResult<()> Wrapper to RocksStorage put() method Delete &'static [u8] StorageResult<()> Wrapper to RocksStorage delete() method The handling of these messages is basically just calling the corresponding method from the Storage trait that is implemented by RocksStorage . For example, the handler of the Get message would be implemented as: /// Handler for Get message. impl Handler < Get > for StorageManager { type Result = StorageResult < Option < Vec < u8 >>> ; fn handle ( & mut self , msg : Get , _ : & mut Context < Self > ) -> Self :: Result { self . storage . as_ref (). unwrap (). get ( msg . key ) } } Being the StorageManager such a simple actor, there are no errors that can arise due to its own logic and thus, returning the StorageResult library generic error may be the right thing to do. The way other actors will communicate with the storage manager is: Get the address of the storage manager from the registry: // Get storage manager address let storage_manager_addr = System :: current (). registry (). get :: < StorageManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: // Example storage_manager_addr . send ( Get { key : PEERS_KEY }) . into_actor ( self ) . then ( | res , _act , _ctx | { match res { Ok ( res ) => { // Process StorageResult match res { Ok ( opt ) => { // Process Option<Vec<u8>> match opt { Some ( vec ) => println ! ( \"PEERS_KEY found in storage, value: {:?}\" , vec ), None => println ! ( \"PEERS_KEY not found in storage\" ) }; }, Err ( _ ) => println ! ( \"Something went wrong when accessing the storage\" ) }; }, _ => println ! ( \"Something went really wrong in the actors message passing\" ) }; actix :: fut :: ok (()) }) . wait ( ctx ); Warning The values used as keys for the storage need to be defined with the static lifetime. Literals can be a good choice for this purpose: pub static PEERS_KEY : & 'static [ u8 ] = b\"peers\" ; Outgoing messages: Storage manager -> Others \u00b6 These are the messages sent by the storage manager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request config info GetConfig \u00b6 This message is sent to the ConfigManager actor when the storage manager actor is started. The return value is used to launch the rocks db storage. For further information, see ConfigManager . Further information \u00b6 The full source code of the StorageManager can be found at storage_manager.rs .","title":"Storage Manager"},{"location":"architecture/managers/storage-manager/#storage-manager","text":"The storage manager is the actor that encapsulates the logic of the persistent storage library.","title":"Storage Manager"},{"location":"architecture/managers/storage-manager/#state","text":"The state of the actor is an instance of the RocksStorage backend encapsulated in an option. /// Storage manager actor #[derive(Default)] pub struct StorageManager { /// DB storage storage : Option < RocksStorage > , } The connection to the database is an Option to handle failures in the creation of the connection to the database.","title":"State"},{"location":"architecture/managers/storage-manager/#actor-creation-and-registration","text":"The creation of the storage manager actor is performed directly by the main process: let storage_manager_addr = StorageManager :: new ( & db_root ). start (); System :: current (). registry (). set ( storage_manager_addr ); The new() method tries to connect to the database specified in the path given as argument. If the connection is not possible for any reason, the storage in the state will be None . Otherwise, the state will contain the handle to the database for future use. Once the storage manager actor is started, the main process registers the actor into the system registry.","title":"Actor creation and registration"},{"location":"architecture/managers/storage-manager/#api","text":"","title":"API"},{"location":"architecture/managers/storage-manager/#incoming-messages-others-storage-manager","text":"These are the messages supported by the storage manager handlers: Message Input type Output type Description Get &'static [u8] StorageResult<Option<Vec<u8>>> Wrapper to RocksStorage get() method Put &'static [u8] , Vec<u8> StorageResult<()> Wrapper to RocksStorage put() method Delete &'static [u8] StorageResult<()> Wrapper to RocksStorage delete() method The handling of these messages is basically just calling the corresponding method from the Storage trait that is implemented by RocksStorage . For example, the handler of the Get message would be implemented as: /// Handler for Get message. impl Handler < Get > for StorageManager { type Result = StorageResult < Option < Vec < u8 >>> ; fn handle ( & mut self , msg : Get , _ : & mut Context < Self > ) -> Self :: Result { self . storage . as_ref (). unwrap (). get ( msg . key ) } } Being the StorageManager such a simple actor, there are no errors that can arise due to its own logic and thus, returning the StorageResult library generic error may be the right thing to do. The way other actors will communicate with the storage manager is: Get the address of the storage manager from the registry: // Get storage manager address let storage_manager_addr = System :: current (). registry (). get :: < StorageManager > (); Use any of the sending methods provided by the address ( do_send() , try_send() , send() ) to send a message to the actor: // Example storage_manager_addr . send ( Get { key : PEERS_KEY }) . into_actor ( self ) . then ( | res , _act , _ctx | { match res { Ok ( res ) => { // Process StorageResult match res { Ok ( opt ) => { // Process Option<Vec<u8>> match opt { Some ( vec ) => println ! ( \"PEERS_KEY found in storage, value: {:?}\" , vec ), None => println ! ( \"PEERS_KEY not found in storage\" ) }; }, Err ( _ ) => println ! ( \"Something went wrong when accessing the storage\" ) }; }, _ => println ! ( \"Something went really wrong in the actors message passing\" ) }; actix :: fut :: ok (()) }) . wait ( ctx ); Warning The values used as keys for the storage need to be defined with the static lifetime. Literals can be a good choice for this purpose: pub static PEERS_KEY : & 'static [ u8 ] = b\"peers\" ;","title":"Incoming messages: Others -&gt; Storage manager"},{"location":"architecture/managers/storage-manager/#outgoing-messages-storage-manager-others","text":"These are the messages sent by the storage manager: Message Destination Input type Output type Description GetConfig ConfigManager () Result<Config, io::Error> Request config info","title":"Outgoing messages: Storage manager -&gt; Others"},{"location":"architecture/managers/storage-manager/#getconfig","text":"This message is sent to the ConfigManager actor when the storage manager actor is started. The return value is used to launch the rocks db storage. For further information, see ConfigManager .","title":"GetConfig"},{"location":"architecture/managers/storage-manager/#further-information","text":"The full source code of the StorageManager can be found at storage_manager.rs .","title":"Further information"},{"location":"architecture/p2p/connections/","text":"Page under construction. Check back soon. \u00b6","title":"Connections"},{"location":"architecture/p2p/connections/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"architecture/p2p/encoding/","text":"Encoding \u00b6 The codec for client -> server transport is a wrapper around the Witnet network protocol which includes an extra u32 to indicate the message length. This limits the size of a message to 4GiB. Field Type Description length u32 message length data [u8; length] message data","title":"Encoding"},{"location":"architecture/p2p/encoding/#encoding","text":"The codec for client -> server transport is a wrapper around the Witnet network protocol which includes an extra u32 to indicate the message length. This limits the size of a message to 4GiB. Field Type Description length u32 message length data [u8; length] message data","title":"Encoding"},{"location":"architecture/p2p/gossip/","text":"Page under construction. Check back soon. \u00b6","title":"Gossiping"},{"location":"architecture/p2p/gossip/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"architecture/rad/overview/","text":"Page under construction. Check back soon. \u00b6","title":"Overview"},{"location":"architecture/rad/overview/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"configuration/cli/","text":"Configuration params in CLI \u00b6 When running the node, you can specify which configuration file to load using the command line option -c or --config . See the help ( --help ) for more information.","title":"Command Line Interface (CLI)"},{"location":"configuration/cli/#configuration-params-in-cli","text":"When running the node, you can specify which configuration file to load using the command line option -c or --config . See the help ( --help ) for more information.","title":"Configuration params in CLI"},{"location":"configuration/environment/","text":"Environment defaults \u00b6 Environments create contention between different instances of the Witnet network (e.g.: testnet vs. mainnet). Each environment comes with a set of default values which you can later override in the configuration file. You can specify which environment to use in the witnet.toml configuration file. At the moment, the available environments are: testnet-1 and mainnet . Defaults for Testnet-1 \u00b6 Section Param Default Value Description connections server_addr \"127.0.0.1:21337\" Server socket address to which it should bind to connections inbound_limit 128 Maximum number of concurrent connections the server should accept connections outbound_limit 1 Maximum number of opened connections to other peers this node has connections known_peers [\"40.121.131.135:21337\"] Other peer addresses this node knows about at start connections bootstrap_peers_period_seconds 30 Period of the outbound peer bootstrapping process (in seconds) connections storage_peers_period_seconds 30 Period of the known peers backup into storage process (in seconds) connections handshake_timeout_seconds 5 Timeout for the handshake process (in seconds) storage db_path \".witnet-rust-testnet-1\" Directory containing the database files consensus_constants checkpoint_zero_timestamp 1548855420 Timestamp at checkpoint 0 (the start of epoch 0) consensus_constants checkpoints_period_seconds 90 Seconds between the start of an epoch and the start of the next one jsonrpc enabled true Enable JSON-RPC server jsonrpc server_address \"127.0.0.1:21338\" JSON-RPC server socket address mining enabled true Enable MiningManager Defaults for Mainnet \u00b6 Section Param Default Value Description connections server_addr \"127.0.0.1:11337\" Server socket address to which it should bind to connections inbound_limit 128 Maximum number of concurrent connections the server should accept connections outbound_limit 8 Maximum number of opened connections to other peers this node has connections known_peers [] Other peer addresses this node knows about at start connections bootstrap_peers_period_seconds 5 Period of the outbound peer bootstrapping process (in seconds) connections storage_peers_period_seconds 30 Period of the known peers backup into storage process (in seconds) connections handshake_timeout_seconds 5 Timeout for the handshake process (in seconds) storage db_path \".witnet-rust-mainnet\" Directory containing the database files consensus_constants checkpoint_zero_timestamp 19_999_999_999_999 Timestamp at checkpoint 0 (the start of epoch 0) consensus_constants checkpoints_period_seconds 90 Seconds between the start of an epoch and the start of the next one jsonrpc enabled true Enable JSON-RPC server jsonrpc server_address \"127.0.0.1:11338\" JSON-RPC server socket address mining enabled true Enable MiningManager","title":"Environment defaults"},{"location":"configuration/environment/#environment-defaults","text":"Environments create contention between different instances of the Witnet network (e.g.: testnet vs. mainnet). Each environment comes with a set of default values which you can later override in the configuration file. You can specify which environment to use in the witnet.toml configuration file. At the moment, the available environments are: testnet-1 and mainnet .","title":"Environment defaults"},{"location":"configuration/environment/#defaults-for-testnet-1","text":"Section Param Default Value Description connections server_addr \"127.0.0.1:21337\" Server socket address to which it should bind to connections inbound_limit 128 Maximum number of concurrent connections the server should accept connections outbound_limit 1 Maximum number of opened connections to other peers this node has connections known_peers [\"40.121.131.135:21337\"] Other peer addresses this node knows about at start connections bootstrap_peers_period_seconds 30 Period of the outbound peer bootstrapping process (in seconds) connections storage_peers_period_seconds 30 Period of the known peers backup into storage process (in seconds) connections handshake_timeout_seconds 5 Timeout for the handshake process (in seconds) storage db_path \".witnet-rust-testnet-1\" Directory containing the database files consensus_constants checkpoint_zero_timestamp 1548855420 Timestamp at checkpoint 0 (the start of epoch 0) consensus_constants checkpoints_period_seconds 90 Seconds between the start of an epoch and the start of the next one jsonrpc enabled true Enable JSON-RPC server jsonrpc server_address \"127.0.0.1:21338\" JSON-RPC server socket address mining enabled true Enable MiningManager","title":"Defaults for Testnet-1"},{"location":"configuration/environment/#defaults-for-mainnet","text":"Section Param Default Value Description connections server_addr \"127.0.0.1:11337\" Server socket address to which it should bind to connections inbound_limit 128 Maximum number of concurrent connections the server should accept connections outbound_limit 8 Maximum number of opened connections to other peers this node has connections known_peers [] Other peer addresses this node knows about at start connections bootstrap_peers_period_seconds 5 Period of the outbound peer bootstrapping process (in seconds) connections storage_peers_period_seconds 30 Period of the known peers backup into storage process (in seconds) connections handshake_timeout_seconds 5 Timeout for the handshake process (in seconds) storage db_path \".witnet-rust-mainnet\" Directory containing the database files consensus_constants checkpoint_zero_timestamp 19_999_999_999_999 Timestamp at checkpoint 0 (the start of epoch 0) consensus_constants checkpoints_period_seconds 90 Seconds between the start of an epoch and the start of the next one jsonrpc enabled true Enable JSON-RPC server jsonrpc server_address \"127.0.0.1:11338\" JSON-RPC server socket address mining enabled true Enable MiningManager","title":"Defaults for Mainnet"},{"location":"configuration/toml-file/","text":"Custom TOML configuration file \u00b6 A custom witnet.toml file can be used to configure parameters of the node. In order for the node to be able to read this file, it should exist in the current working directory where the node is run. Another way is to just tell the node where the config file resides using a command line option. See the CLI reference for more info. TOML file example \u00b6 environment = \"testnet-1\" # or \"mainnet\" [connections] # section for connections-related params server_addr = \"127.0.0.1:1234\" inbound_limit = 128 outbound_limit = 1 known_peers = [\"40.121.131.135:21337\"] bootstrap_peers_period_seconds = 30 storage_peers_period_seconds = 30 handshake_timeout_seconds = 5 [storage] # section for storage-related params db_path = \".wit\" [consensus_constants] # consensus-critical constants checkpoint_zero_timestamp = 1548855420 checkpoints_period_seconds = 90 [jsonrpc] # section for params related to JSON-RPC API enabled = true server_address = \"127.0.0.1:4321\" [mining] # mining-related params enabled = true # ... more options Configuration params \u00b6 Section Param Default Value in testnet-1 Description connections server_addr \"127.0.0.1:21337\" Server socket address to which it should bind to connections inbound_limit 128 Maximum number of concurrent connections the server should accept connections outbound_limit 1 Maximum number of opened connections to other peers this node has connections known_peers [\"40.121.131.135:21337\"] Other peer addresses this node knows about at start connections bootstrap_peers_period_seconds 30 Period of the outbound peer bootstrapping process (in seconds) connections storage_peers_period_seconds 30 Period of the known peers backup into storage process (in seconds) connections handshake_timeout_seconds 5 Timeout for the handshake process (in seconds) storage db_path \".witnet-rust-testnet-1\" Directory containing the database files consensus_constants checkpoint_zero_timestamp 1548855420 Timestamp at checkpoint 0 (the start of epoch 0) consensus_constants checkpoints_period_seconds 90 Seconds between the start of an epoch and the start of the next one jsonrpc enabled true Enable JSON-RPC server jsonrpc server_address \"127.0.0.1:21338\" JSON-RPC server socket address mining enabled true Enable MiningManager These are the defaults for testnet-1 . See environment for the specific values for all the environments. The parameters in the [consensus_constants] section are ignored when the environment is set to mainnet .","title":"Custom toml file"},{"location":"configuration/toml-file/#custom-toml-configuration-file","text":"A custom witnet.toml file can be used to configure parameters of the node. In order for the node to be able to read this file, it should exist in the current working directory where the node is run. Another way is to just tell the node where the config file resides using a command line option. See the CLI reference for more info.","title":"Custom TOML configuration file"},{"location":"configuration/toml-file/#toml-file-example","text":"environment = \"testnet-1\" # or \"mainnet\" [connections] # section for connections-related params server_addr = \"127.0.0.1:1234\" inbound_limit = 128 outbound_limit = 1 known_peers = [\"40.121.131.135:21337\"] bootstrap_peers_period_seconds = 30 storage_peers_period_seconds = 30 handshake_timeout_seconds = 5 [storage] # section for storage-related params db_path = \".wit\" [consensus_constants] # consensus-critical constants checkpoint_zero_timestamp = 1548855420 checkpoints_period_seconds = 90 [jsonrpc] # section for params related to JSON-RPC API enabled = true server_address = \"127.0.0.1:4321\" [mining] # mining-related params enabled = true # ... more options","title":"TOML file example"},{"location":"configuration/toml-file/#configuration-params","text":"Section Param Default Value in testnet-1 Description connections server_addr \"127.0.0.1:21337\" Server socket address to which it should bind to connections inbound_limit 128 Maximum number of concurrent connections the server should accept connections outbound_limit 1 Maximum number of opened connections to other peers this node has connections known_peers [\"40.121.131.135:21337\"] Other peer addresses this node knows about at start connections bootstrap_peers_period_seconds 30 Period of the outbound peer bootstrapping process (in seconds) connections storage_peers_period_seconds 30 Period of the known peers backup into storage process (in seconds) connections handshake_timeout_seconds 5 Timeout for the handshake process (in seconds) storage db_path \".witnet-rust-testnet-1\" Directory containing the database files consensus_constants checkpoint_zero_timestamp 1548855420 Timestamp at checkpoint 0 (the start of epoch 0) consensus_constants checkpoints_period_seconds 90 Seconds between the start of an epoch and the start of the next one jsonrpc enabled true Enable JSON-RPC server jsonrpc server_address \"127.0.0.1:21338\" JSON-RPC server socket address mining enabled true Enable MiningManager These are the defaults for testnet-1 . See environment for the specific values for all the environments. The parameters in the [consensus_constants] section are ignored when the environment is set to mainnet .","title":"Configuration params"},{"location":"get-started/design-overview/","text":"Page under construction. Check back soon. \u00b6","title":"Design Overview"},{"location":"get-started/design-overview/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"get-started/what-is-witnet/","text":"What is Witnet \u00b6 The Witnet protocol, as outlined by the Witnet Whitepaper , allows a network of computers to act as a \"decentralized oracle\" that retrieves, attests and delivers information to smart contracts without having to place trust in a single entity. Wait, what? Ok, lets go one step at a time. Smart Contracts Are Not What You Think \u00b6 Over the last years, blockchain technology has promised to revolutionize business by allowing creation of \"smart contracts\" that, unlike paper contracts, are impossible to breach. Actually, those smart contracts are nothing more than small programs that can be run in a trustless manner. That is: once they are created, no one can stop them from doing exactly what they were created for. They just obey their own source code, and censorship is just impossible. This is a really powerful idea. If you can write a smart contract that: implements the logic of an agreement, and can execute the clauses of the contract on its own (like paying Alice or Bob depending on the outcome of some event), then you have a contract that is capable of enforcing itself and leaves no room for contestation. Boom . Blockchain Oracles, And Their Problem \u00b6 Given that smart contracts need to be completely deterministic 1 , they do not support input of data from non-deterministic sources such as APIs or websites. As a result, smart contracts are mostly isolated from the rest of the Internet, which dramatically reduces their transformative potential. At the end of the day, the output of a program does not depend solely on its source code, but also on the input data it operates upon. Of course, as the creator of a smart contract, you can create a method that allows you and only you to act as an \"oracle\" by introducing information from the outside at will. But you would be completely breaking the trustless nature of a smart contract. If trust is put in a single entity, there you have a single point of failure that can easily be hacked or corrupted. Smart contracts connected to the real world will not be completely trustless and will not release their full potential until we have ways to feed them information trustlessly. This is often called \"the oracle problem\" . The Solution: A Decentralized Oracle Network \u00b6 The Witnet protocol aims to create an overlay network that connects smart contracts to any online data source. Sport results, stock prices, weather forecasts or even other blockchains can be easily queried (preferably through APIs). The protocol describes a distributed network of peer nodes\u2014which we fondly call witnesses \u2014who earn Wit tokens as a reward for retrieving web data and reporting it directly to the smart contracts. The bottom line is that a considerable number of randomly selected, anonymous peers retrieving information from one or more sources can converge into a single truth about the data they retrieved if a majority of them are incentivized to report the retrieved data honestly and they apply a common consensus algorithm that resolves inconsistencies. This Decentralized Oracle Network (DON) maintains and distributes a block chain data structure that serves as a common ledger for the operation of the protocol as well as for the wit token, which is central to incentivizing the network players to abide by the protocol and make them liable for any misbehavior. Witnesses are also in charge of validating transactions in the network and bundling them into blocks that get appended to the blockchain periodically. The process by which witnesses retrieve, attest and deliver data in behalf of the smart contracts is in some way similar to mining in other blockchains. However, fulfilling these tasks and collecting the rewards is not that expensive in terms of computation. The protocol has been conceived to ensure utmost decentralization and fairnes, so each witness' weight in the network is not aligned to their computing power. Instead, the probability for every witness to be assigned tasks or mine new blocks is directly proportional to their past performance in terms of honesty: their reputation. Tip Of course, the so-called miners are not actual human beings sitting in front of a computer, fulfilling assignments coming from an Internet overlord that commands them to use their web browser to navigate to a certain website and take a snapshot or copy some text that they must report. Indeed, the miners are just computers running a software (Witnet-rust) that automatically receive and execute a series of tasks without the owner of the computer having to actively do anything else than installing it. 100% Truth, 0% Trust \u00b6 Data retrieved, attested and delivered using the Witnet protocol is reliable not because of authority but because it comes from anonymous nodes who are incentivized to remain honest and to compete for rewards. In addition, integrity of this data is guaranteed by a consensus algorithm that detects fraudsters, who are immediately punished. The progressive reputation protocol plays a central role in maintaining every participant active and honest by creating short, middle and long term incentives for them to abide by the protocol and not to tamper with the data they broker. Info Please note that Witnet's aim is not spotting fake data, but guaranteeing a 1:1 match between what is published online\u2014regardless of its truthness\u2014and the data that is eventually delivered the smart contracts. Who Is Behind Witnet \u00b6 Witnet is an open source project originally devised by Stampery , the leaders of blockchain-powered data certification. The protocol is now being developed by Witnet Foundation in collaboration with a community of independent contributors. Ever since Stampery was founded in 2014, they have been on a mission: replacing blind trust with mathematical proof. Witnet is the next step towards this goal. Stampery is backed by top venture capital funds and angel investors, including Tim Draper and Blockchain Capital. The Stampery team has also been involved in the development of Aragon , Trailbot , Mongoaudit and Loqui IM . Otherwise, the contracts could have totally different output values when executed across all the nodes maintaining the blockchain, therefore causing inconsistencies that would lead to breaking the network consensus. \u21a9","title":"What is Witnet"},{"location":"get-started/what-is-witnet/#what-is-witnet","text":"The Witnet protocol, as outlined by the Witnet Whitepaper , allows a network of computers to act as a \"decentralized oracle\" that retrieves, attests and delivers information to smart contracts without having to place trust in a single entity. Wait, what? Ok, lets go one step at a time.","title":"What is Witnet"},{"location":"get-started/what-is-witnet/#smart-contracts-are-not-what-you-think","text":"Over the last years, blockchain technology has promised to revolutionize business by allowing creation of \"smart contracts\" that, unlike paper contracts, are impossible to breach. Actually, those smart contracts are nothing more than small programs that can be run in a trustless manner. That is: once they are created, no one can stop them from doing exactly what they were created for. They just obey their own source code, and censorship is just impossible. This is a really powerful idea. If you can write a smart contract that: implements the logic of an agreement, and can execute the clauses of the contract on its own (like paying Alice or Bob depending on the outcome of some event), then you have a contract that is capable of enforcing itself and leaves no room for contestation. Boom .","title":"Smart Contracts Are Not What You Think"},{"location":"get-started/what-is-witnet/#blockchain-oracles-and-their-problem","text":"Given that smart contracts need to be completely deterministic 1 , they do not support input of data from non-deterministic sources such as APIs or websites. As a result, smart contracts are mostly isolated from the rest of the Internet, which dramatically reduces their transformative potential. At the end of the day, the output of a program does not depend solely on its source code, but also on the input data it operates upon. Of course, as the creator of a smart contract, you can create a method that allows you and only you to act as an \"oracle\" by introducing information from the outside at will. But you would be completely breaking the trustless nature of a smart contract. If trust is put in a single entity, there you have a single point of failure that can easily be hacked or corrupted. Smart contracts connected to the real world will not be completely trustless and will not release their full potential until we have ways to feed them information trustlessly. This is often called \"the oracle problem\" .","title":"Blockchain Oracles, And Their Problem"},{"location":"get-started/what-is-witnet/#the-solution-a-decentralized-oracle-network","text":"The Witnet protocol aims to create an overlay network that connects smart contracts to any online data source. Sport results, stock prices, weather forecasts or even other blockchains can be easily queried (preferably through APIs). The protocol describes a distributed network of peer nodes\u2014which we fondly call witnesses \u2014who earn Wit tokens as a reward for retrieving web data and reporting it directly to the smart contracts. The bottom line is that a considerable number of randomly selected, anonymous peers retrieving information from one or more sources can converge into a single truth about the data they retrieved if a majority of them are incentivized to report the retrieved data honestly and they apply a common consensus algorithm that resolves inconsistencies. This Decentralized Oracle Network (DON) maintains and distributes a block chain data structure that serves as a common ledger for the operation of the protocol as well as for the wit token, which is central to incentivizing the network players to abide by the protocol and make them liable for any misbehavior. Witnesses are also in charge of validating transactions in the network and bundling them into blocks that get appended to the blockchain periodically. The process by which witnesses retrieve, attest and deliver data in behalf of the smart contracts is in some way similar to mining in other blockchains. However, fulfilling these tasks and collecting the rewards is not that expensive in terms of computation. The protocol has been conceived to ensure utmost decentralization and fairnes, so each witness' weight in the network is not aligned to their computing power. Instead, the probability for every witness to be assigned tasks or mine new blocks is directly proportional to their past performance in terms of honesty: their reputation. Tip Of course, the so-called miners are not actual human beings sitting in front of a computer, fulfilling assignments coming from an Internet overlord that commands them to use their web browser to navigate to a certain website and take a snapshot or copy some text that they must report. Indeed, the miners are just computers running a software (Witnet-rust) that automatically receive and execute a series of tasks without the owner of the computer having to actively do anything else than installing it.","title":"The Solution: A Decentralized Oracle Network"},{"location":"get-started/what-is-witnet/#100-truth-0-trust","text":"Data retrieved, attested and delivered using the Witnet protocol is reliable not because of authority but because it comes from anonymous nodes who are incentivized to remain honest and to compete for rewards. In addition, integrity of this data is guaranteed by a consensus algorithm that detects fraudsters, who are immediately punished. The progressive reputation protocol plays a central role in maintaining every participant active and honest by creating short, middle and long term incentives for them to abide by the protocol and not to tamper with the data they broker. Info Please note that Witnet's aim is not spotting fake data, but guaranteeing a 1:1 match between what is published online\u2014regardless of its truthness\u2014and the data that is eventually delivered the smart contracts.","title":"100% Truth, 0% Trust"},{"location":"get-started/what-is-witnet/#who-is-behind-witnet","text":"Witnet is an open source project originally devised by Stampery , the leaders of blockchain-powered data certification. The protocol is now being developed by Witnet Foundation in collaboration with a community of independent contributors. Ever since Stampery was founded in 2014, they have been on a mission: replacing blind trust with mathematical proof. Witnet is the next step towards this goal. Stampery is backed by top venture capital funds and angel investors, including Tim Draper and Blockchain Capital. The Stampery team has also been involved in the development of Aragon , Trailbot , Mongoaudit and Loqui IM . Otherwise, the contracts could have totally different output values when executed across all the nodes maintaining the blockchain, therefore causing inconsistencies that would lead to breaking the network consensus. \u21a9","title":"Who Is Behind Witnet"},{"location":"get-started/why-rust/","text":"Why Rust? \u00b6 Having its own underlying blockchain, Witnet requires code that is as fast as C or C++ but memory safe to prevent security vulnerabilities. At the same time, we want to produce concurrent code that can take advantage of modern hardware. After analyzing the possible languages to use, we found that Rust is a fast, memory safe and highly concurrent language which allows for writing complex multithreaded code without race conditions or dangling pointers. It allows fearless concurrency without compromising on performance. Having an undeniable influence from functional languages like ML or Haskell, Rust is very expressive yet it uses high level abstractions. This makes it easy to write correct and readable code, which in turn translates into faster and more productive development. Rust is statically typed but it sports a really nice type inferer which makes code succinct and readable. The absence of a garbage collector and low runtime requirements makes it easy to embed Rust code inside other languages like Python, Ruby or Nodejs. This is fundamental for building the bridges between Witnet and other blockchains as well as with the headless browser that will allow Witnet to perform web content retrievals. The Rust compiler is simply awesome, offering the most helpful messages we have seen in a compiler. It also has incremental compilation, which helps developers save their valuable time. No more reinventing the wheel. Unlike C or C++, Rust has a package manager\u200a\u2014\u200aa tool called cargo. Besides managing the dependencies of the project, cargo gives you the option to build, run, test, generate documentation and publish your own package to a community driven package repository. Metaprogramming. Rust macros allow for reusing code in a concise, well-abstracted way with a powerful compile-time correctness checking. And last but not least, Rust has an ever-welcoming community that is always willing to help and is currently growing at a very healthy pace. In addition, it is currently in a stage in which the ecosystem is mature enough so that you d Summing up, here are the 8 reasons why Witnet will make the most of Rust: Performance Memory safety Concurrency Influence from functional languages Statically typed with type inference Awesome compiler and tooling Metaprogramming Thriving community Tip By the way, do you love Rust and want to join one of the most exciting projects using it in the blockchain space? We\u2019re hiring! See our current open positions on AngelList .","title":"Why Rust?"},{"location":"get-started/why-rust/#why-rust","text":"Having its own underlying blockchain, Witnet requires code that is as fast as C or C++ but memory safe to prevent security vulnerabilities. At the same time, we want to produce concurrent code that can take advantage of modern hardware. After analyzing the possible languages to use, we found that Rust is a fast, memory safe and highly concurrent language which allows for writing complex multithreaded code without race conditions or dangling pointers. It allows fearless concurrency without compromising on performance. Having an undeniable influence from functional languages like ML or Haskell, Rust is very expressive yet it uses high level abstractions. This makes it easy to write correct and readable code, which in turn translates into faster and more productive development. Rust is statically typed but it sports a really nice type inferer which makes code succinct and readable. The absence of a garbage collector and low runtime requirements makes it easy to embed Rust code inside other languages like Python, Ruby or Nodejs. This is fundamental for building the bridges between Witnet and other blockchains as well as with the headless browser that will allow Witnet to perform web content retrievals. The Rust compiler is simply awesome, offering the most helpful messages we have seen in a compiler. It also has incremental compilation, which helps developers save their valuable time. No more reinventing the wheel. Unlike C or C++, Rust has a package manager\u200a\u2014\u200aa tool called cargo. Besides managing the dependencies of the project, cargo gives you the option to build, run, test, generate documentation and publish your own package to a community driven package repository. Metaprogramming. Rust macros allow for reusing code in a concise, well-abstracted way with a powerful compile-time correctness checking. And last but not least, Rust has an ever-welcoming community that is always willing to help and is currently growing at a very healthy pace. In addition, it is currently in a stage in which the ecosystem is mature enough so that you d Summing up, here are the 8 reasons why Witnet will make the most of Rust: Performance Memory safety Concurrency Influence from functional languages Statically typed with type inference Awesome compiler and tooling Metaprogramming Thriving community Tip By the way, do you love Rust and want to join one of the most exciting projects using it in the blockchain space? We\u2019re hiring! See our current open positions on AngelList .","title":"Why Rust?"},{"location":"get-started/installation/from-source/","text":"Running witnet-rust from source code \u00b6 Install compilation dependencies \u00b6 Rust 2018 ( stable channel) \u00b6 curl https://sh.rustup.rs -sSf | sh source $HOME/.cargo/env rustup default stable OpenSSL / libssl \u00b6 GNU/Linux (apt) apt install libssl-dev GNU/Linux (pacman) pacman -S openssl macOS brew install openssl CLang compiler \u00b6 GNU/Linux (apt) apt install clang GNU/Linux (pacman) pacman -S clang macOS xcode-select --install Protocol Buffers compiler \u00b6 GNU/Linux (apt) apt install protobuf-compiler GNU/Linux (pacman) pacman -S protobuf macOS brew install protobuf Git client \u00b6 GNU/Linux (apt) apt install git GNU/Linux (pacman) pacman -S git macOS brew install git MkDocs Python packages \u00b6 (Optional, only if generating documentation) pip install mkdocs pip install pymdown-extensions pip install mkdocs-material Checkout source code from GitHub \u00b6 HTTPS git clone https://github.com/witnet/witnet-rust.git cd witnet-rust SSH git clone git@github.com:witnet/witnet-rust.git cd witnet-rust Run with cargo \u00b6 By default, this line will run a Witnet node and connect to the Testnet using the default configuration: cargo run node For more witnet-rust commands ( cli , wallet , etc.) you can read the Witnet-rust CLI documentation .","title":"From source code"},{"location":"get-started/installation/from-source/#running-witnet-rust-from-source-code","text":"","title":"Running witnet-rust from source code"},{"location":"get-started/installation/from-source/#install-compilation-dependencies","text":"","title":"Install compilation dependencies"},{"location":"get-started/installation/from-source/#rust-2018-stable-channel","text":"curl https://sh.rustup.rs -sSf | sh source $HOME/.cargo/env rustup default stable","title":"Rust 2018 (stable channel)"},{"location":"get-started/installation/from-source/#openssl-libssl","text":"GNU/Linux (apt) apt install libssl-dev GNU/Linux (pacman) pacman -S openssl macOS brew install openssl","title":"OpenSSL / libssl"},{"location":"get-started/installation/from-source/#clang-compiler","text":"GNU/Linux (apt) apt install clang GNU/Linux (pacman) pacman -S clang macOS xcode-select --install","title":"CLang compiler"},{"location":"get-started/installation/from-source/#protocol-buffers-compiler","text":"GNU/Linux (apt) apt install protobuf-compiler GNU/Linux (pacman) pacman -S protobuf macOS brew install protobuf","title":"Protocol Buffers compiler"},{"location":"get-started/installation/from-source/#git-client","text":"GNU/Linux (apt) apt install git GNU/Linux (pacman) pacman -S git macOS brew install git","title":"Git client"},{"location":"get-started/installation/from-source/#mkdocs-python-packages","text":"(Optional, only if generating documentation) pip install mkdocs pip install pymdown-extensions pip install mkdocs-material","title":"MkDocs Python packages"},{"location":"get-started/installation/from-source/#checkout-source-code-from-github","text":"HTTPS git clone https://github.com/witnet/witnet-rust.git cd witnet-rust SSH git clone git@github.com:witnet/witnet-rust.git cd witnet-rust","title":"Checkout source code from GitHub"},{"location":"get-started/installation/from-source/#run-with-cargo","text":"By default, this line will run a Witnet node and connect to the Testnet using the default configuration: cargo run node For more witnet-rust commands ( cli , wallet , etc.) you can read the Witnet-rust CLI documentation .","title":"Run with cargo"},{"location":"get-started/installation/gnu-linux/","text":"Running witnet-rust on GNU/Linux \u00b6 Download the witnet-rust package \u00b6 GNU/Linux packages are available in our GitHub repository: Witnet-rust for desktop GNU/Linux (x86_64) Witnet-rust for Raspberry Pi GNU/Linux (armv6l) Unpacking and granting execution permission \u00b6 tar -zxf witnet-*-linux-gnu.tar.gz chmod +x ./witnet Running the binary \u00b6 Running the witnet-rust binary cannot be easier. By default, this line will run a Witnet node and connect to the Testnet using the default configuration: ./witnet node For more witnet-rust components ( cli , wallet , etc.) you can read the Witnet-rust CLI documentation .","title":"GNU/Linux"},{"location":"get-started/installation/gnu-linux/#running-witnet-rust-on-gnulinux","text":"","title":"Running witnet-rust on GNU/Linux"},{"location":"get-started/installation/gnu-linux/#download-the-witnet-rust-package","text":"GNU/Linux packages are available in our GitHub repository: Witnet-rust for desktop GNU/Linux (x86_64) Witnet-rust for Raspberry Pi GNU/Linux (armv6l)","title":"Download the witnet-rust package"},{"location":"get-started/installation/gnu-linux/#unpacking-and-granting-execution-permission","text":"tar -zxf witnet-*-linux-gnu.tar.gz chmod +x ./witnet","title":"Unpacking and granting execution permission"},{"location":"get-started/installation/gnu-linux/#running-the-binary","text":"Running the witnet-rust binary cannot be easier. By default, this line will run a Witnet node and connect to the Testnet using the default configuration: ./witnet node For more witnet-rust components ( cli , wallet , etc.) you can read the Witnet-rust CLI documentation .","title":"Running the binary"},{"location":"get-started/installation/macos/","text":"Running witnet-rust on macOS \u00b6 Download the witnet-rust package \u00b6 macOS ( darwin ) packages are available in our GitHub repository: Witnet-rust for macOS (darwin) Unpacking and granting execution permission \u00b6 tar -zxf witnet-*-darwin.tar.gz chmod +x ./witnet Running the binary \u00b6 Running the witnet-rust binary cannot be easier. By default, this line will run a Witnet node and connect to the Testnet using the default configuration: ./witnet node For more witnet-rust components ( cli , wallet , etc.) you can read the Witnet-rust CLI documentation .","title":"macOS"},{"location":"get-started/installation/macos/#running-witnet-rust-on-macos","text":"","title":"Running witnet-rust on macOS"},{"location":"get-started/installation/macos/#download-the-witnet-rust-package","text":"macOS ( darwin ) packages are available in our GitHub repository: Witnet-rust for macOS (darwin)","title":"Download the witnet-rust package"},{"location":"get-started/installation/macos/#unpacking-and-granting-execution-permission","text":"tar -zxf witnet-*-darwin.tar.gz chmod +x ./witnet","title":"Unpacking and granting execution permission"},{"location":"get-started/installation/macos/#running-the-binary","text":"Running the witnet-rust binary cannot be easier. By default, this line will run a Witnet node and connect to the Testnet using the default configuration: ./witnet node For more witnet-rust components ( cli , wallet , etc.) you can read the Witnet-rust CLI documentation .","title":"Running the binary"},{"location":"get-started/installation/windows/","text":"Installing witnet-rust on Windows \u00b6 About Windows support Windows is not officially supported by this project at the moment. However, you can try to build witnet-rust from the source code following this instructions .","title":"Windows"},{"location":"get-started/installation/windows/#installing-witnet-rust-on-windows","text":"About Windows support Windows is not officially supported by this project at the moment. However, you can try to build witnet-rust from the source code following this instructions .","title":"Installing witnet-rust on Windows"},{"location":"interface/cli/","text":"Command Line Interface (CLI) \u00b6 The cli subcommand provides a human friendly command-line interface to the JSON-RPC API . Usage \u00b6 See all the available options by running the help command. cargo run -- can be used to replace witnet in a development environment. $ witnet cli --help $ cargo run -- cli --help The JSON-RPC server address is obtained from the configuration file . The path of this file can be set using the -c or --config flag. This flag must appear after cli . $ witnet cli -c witnet.toml getBlockChain $ witnet cli getBlockChain Block for epoch #46924 had digest e706995269bfc4fb5f4ab9082765a1bdb48fc6e58cdf5f95621c9e3f849301ed Block for epoch #46925 had digest 2dc469691916a862154eb92473278ea8591ace910ec7ecb560797cbb91fdc01e If there is any error, the process will return a non-zero exit code. $ witnet cli getBlockChain ERROR 2019-01-03T12:01:51Z: witnet: Error: Connection refused (os error 111) The executable implements the usual logging API, which can be enabled using RUST_LOG=witnet=debug : $ RUST_LOG=witnet=debug witnet cli getBlockChain INFO 2019-01-03T12:04:43Z: witnet::json_rpc_client: Connecting to JSON-RPC server at 127.0.0.1:21338 ERROR 2019-01-03T12:04:43Z: witnet: Error: Connection refused (os error 111) Commands \u00b6 raw \u00b6 The raw command allows sending raw JSON-RPC requests from the command line. It can be used in an interactive way: each line of user input will be sent to the JSON-RPC server without any modifications: $ witnet cli -c witnet.toml raw Each block represents a method call: the first line is a request, the second line is a response. hi { \"jsonrpc\" : \"2.0\" , \"error\" : { \"code\" :- 32700 , \"message\" : \"Parse error\" }, \"id\" : null } { \"jsonrpc\" : \"2.0\" , \"method\" : \"getBlockChain\" , \"id\" : 1 } { \"jsonrpc\" : \"2.0\" , \"result\" : [[ 242037 , \"3f8c9ed0fa721e39de9483f61f290f76a541757a828e54a8d951101b1940c59a\" ]], \"id\" : 1 } { \"jsonrpc\" : \"2.0\" , \"method\" : \"someInvalidMethod\" , \"id\" : 2 } { \"jsonrpc\" : \"2.0\" , \"error\" : { \"code\" :- 32601 , \"message\" : \"Method not found\" }, \"id\" : 2 } bye { \"jsonrpc\" : \"2.0\" , \"error\" : { \"code\" :- 32700 , \"message\" : \"Parse error\" }, \"id\" : null } Alternatively, the input can be read from a file using pipes, as is usual in Unix-like environments: $ cat get_block_chain.txt | witnet cli raw {\"jsonrpc\":\"2.0\",\"result\":[[242037,\"3f8c9ed0fa721e39de9483f61f290f76a541757a828e54a8d951101b1940c59a\"]],\"id\":1} getBlockChain \u00b6 Returns the hashes of all the blocks in the blockchain, one per line: $ witnet cli getBlockChain -c witnet_01.toml Block for epoch #46924 had digest e706995269bfc4fb5f4ab9082765a1bdb48fc6e58cdf5f95621c9e3f849301ed Block for epoch #46925 had digest 2dc469691916a862154eb92473278ea8591ace910ec7ecb560797cbb91fdc01e getOutput \u00b6 Returns the output of the transaction that matches the provided output pointer. $ witnet cli getOutput <output pointer> The format of the <output pointer> argument is <transaction id>:<output index> , where: transaction id : Is the 32 hex digits of the transaction id output index : Is a number identifying the index of the output in the transaction Example \u00b6 Request \u00b6 $ witnet cli getOutput 1234567890abcdef111111111111111111111111111111111111111111111111:1 Response \u00b6 { \"jsonrpc\" : \"2.0\" , \"result\" : { \"DataRequest\" : { \"backup_witnesses\" : 0 , \"commit_fee\" : 0 , \"data_request\" : { \"aggregate\" : { \"script\" : [ 0 ]}, \"consensus\" : { \"script\" : [ 0 ]}, \"deliver\" : [{ \"kind\" : \"HTTP-GET\" , \"url\" : \"https://hooks.zapier.com/hooks/catch/3860543/l2awcd/\" }], \"not_before\" : 0 , \"retrieve\" : [{ \"kind\" : \"HTTP-GET\" , \"script\" : [ 0 ], \"url\" : \"https://openweathermap.org/data/2.5/weather?id=2950159&appid=b6907d289e10d714a6e88b30761fae22\" }]}, \"pkh\" : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ], \"reveal_fee\" : 0 , \"tally_fee\" : 0 , \"time_lock\" : 0 , \"value\" : 0 , \"witnesses\" : 0 }}, \"id\" : \"1\" }","title":"Command Line Interface (CLI)"},{"location":"interface/cli/#command-line-interface-cli","text":"The cli subcommand provides a human friendly command-line interface to the JSON-RPC API .","title":"Command Line Interface (CLI)"},{"location":"interface/cli/#usage","text":"See all the available options by running the help command. cargo run -- can be used to replace witnet in a development environment. $ witnet cli --help $ cargo run -- cli --help The JSON-RPC server address is obtained from the configuration file . The path of this file can be set using the -c or --config flag. This flag must appear after cli . $ witnet cli -c witnet.toml getBlockChain $ witnet cli getBlockChain Block for epoch #46924 had digest e706995269bfc4fb5f4ab9082765a1bdb48fc6e58cdf5f95621c9e3f849301ed Block for epoch #46925 had digest 2dc469691916a862154eb92473278ea8591ace910ec7ecb560797cbb91fdc01e If there is any error, the process will return a non-zero exit code. $ witnet cli getBlockChain ERROR 2019-01-03T12:01:51Z: witnet: Error: Connection refused (os error 111) The executable implements the usual logging API, which can be enabled using RUST_LOG=witnet=debug : $ RUST_LOG=witnet=debug witnet cli getBlockChain INFO 2019-01-03T12:04:43Z: witnet::json_rpc_client: Connecting to JSON-RPC server at 127.0.0.1:21338 ERROR 2019-01-03T12:04:43Z: witnet: Error: Connection refused (os error 111)","title":"Usage"},{"location":"interface/cli/#commands","text":"","title":"Commands"},{"location":"interface/cli/#raw","text":"The raw command allows sending raw JSON-RPC requests from the command line. It can be used in an interactive way: each line of user input will be sent to the JSON-RPC server without any modifications: $ witnet cli -c witnet.toml raw Each block represents a method call: the first line is a request, the second line is a response. hi { \"jsonrpc\" : \"2.0\" , \"error\" : { \"code\" :- 32700 , \"message\" : \"Parse error\" }, \"id\" : null } { \"jsonrpc\" : \"2.0\" , \"method\" : \"getBlockChain\" , \"id\" : 1 } { \"jsonrpc\" : \"2.0\" , \"result\" : [[ 242037 , \"3f8c9ed0fa721e39de9483f61f290f76a541757a828e54a8d951101b1940c59a\" ]], \"id\" : 1 } { \"jsonrpc\" : \"2.0\" , \"method\" : \"someInvalidMethod\" , \"id\" : 2 } { \"jsonrpc\" : \"2.0\" , \"error\" : { \"code\" :- 32601 , \"message\" : \"Method not found\" }, \"id\" : 2 } bye { \"jsonrpc\" : \"2.0\" , \"error\" : { \"code\" :- 32700 , \"message\" : \"Parse error\" }, \"id\" : null } Alternatively, the input can be read from a file using pipes, as is usual in Unix-like environments: $ cat get_block_chain.txt | witnet cli raw {\"jsonrpc\":\"2.0\",\"result\":[[242037,\"3f8c9ed0fa721e39de9483f61f290f76a541757a828e54a8d951101b1940c59a\"]],\"id\":1}","title":"raw"},{"location":"interface/cli/#getblockchain","text":"Returns the hashes of all the blocks in the blockchain, one per line: $ witnet cli getBlockChain -c witnet_01.toml Block for epoch #46924 had digest e706995269bfc4fb5f4ab9082765a1bdb48fc6e58cdf5f95621c9e3f849301ed Block for epoch #46925 had digest 2dc469691916a862154eb92473278ea8591ace910ec7ecb560797cbb91fdc01e","title":"getBlockChain"},{"location":"interface/cli/#getoutput","text":"Returns the output of the transaction that matches the provided output pointer. $ witnet cli getOutput <output pointer> The format of the <output pointer> argument is <transaction id>:<output index> , where: transaction id : Is the 32 hex digits of the transaction id output index : Is a number identifying the index of the output in the transaction","title":"getOutput"},{"location":"interface/cli/#example","text":"","title":"Example"},{"location":"interface/cli/#request","text":"$ witnet cli getOutput 1234567890abcdef111111111111111111111111111111111111111111111111:1","title":"Request"},{"location":"interface/cli/#response","text":"{ \"jsonrpc\" : \"2.0\" , \"result\" : { \"DataRequest\" : { \"backup_witnesses\" : 0 , \"commit_fee\" : 0 , \"data_request\" : { \"aggregate\" : { \"script\" : [ 0 ]}, \"consensus\" : { \"script\" : [ 0 ]}, \"deliver\" : [{ \"kind\" : \"HTTP-GET\" , \"url\" : \"https://hooks.zapier.com/hooks/catch/3860543/l2awcd/\" }], \"not_before\" : 0 , \"retrieve\" : [{ \"kind\" : \"HTTP-GET\" , \"script\" : [ 0 ], \"url\" : \"https://openweathermap.org/data/2.5/weather?id=2950159&appid=b6907d289e10d714a6e88b30761fae22\" }]}, \"pkh\" : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ], \"reveal_fee\" : 0 , \"tally_fee\" : 0 , \"time_lock\" : 0 , \"value\" : 0 , \"witnesses\" : 0 }}, \"id\" : \"1\" }","title":"Response"},{"location":"interface/json-rpc/","text":"JSON-RPC \u00b6 JSON-RPC is a stateless, light-weight remote procedure call (RPC) protocol. Primarily this specification defines several data structures and the rules around their processing. It is transport agnostic in that the concepts can be used within the same process, over sockets, over http, or in many various message passing environments. It uses JSON ( RFC 4627 ) as data format. For more details, see the JSON-RPC 2.0 Specification . Server \u00b6 By default, a JSON-RPC server is started at 127.0.0.1:21338 . It can be disabled in the configuration file . Protocol \u00b6 A message must be a valid utf8 string finished with a newline ( \\n ). The parser will start processing the request when it finds the first newline. Therefore, the JSON string cannot contain any newlines expect for the final one. NewLineCodec Methods \u00b6 See json_rpc_methods.rs for the implementation details. inventory \u00b6 Make the node process, validate and potentially broadcast a new inventory item. @params: InventoryItem /// Inventory element: block, transaction, etc #[derive(Debug, Eq, PartialEq, Clone, Serialize, Deserialize)] pub enum InventoryItem { /// Error #[serde(rename = \"error\" )] Error , /// Transaction #[serde(rename = \"transaction\" )] Transaction ( Transaction ), /// Block #[serde(rename = \"block\" )] Block ( Block ), } @returns: boolean indicating success, or parse error Example: {\"jsonrpc\": \"2.0\", \"method\": \"inventory\", \"params\": {\"block\":{\"block_header\":{\"version\":1,\"beacon\":{\"checkpoint\":2,\"hash_prev_block\":{\"SHA256\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4]}},\"hash_merkle_root\":{\"SHA256\":[3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3]}},\"proof\":{\"block_sig\":null,\"influence\":99999},\"txns\":[null]}}, \"id\": 1} Response: {\"jsonrpc\":\"2.0\",\"result\":true,\"id\":1} getBlockChain \u00b6 Get the list of all the known block hashes. Returns a list of (epoch, block_hash) pairs. Example: {\"jsonrpc\": \"2.0\",\"method\": \"getBlockChain\", \"id\": 1} Response: {\"jsonrpc\":\"2.0\",\"result\":[[0,\"ed28899af8c3148a4162736af942bc68c4466da93c5124dabfaa7c582af49e30\"],[1,\"9c9038cfb31a7050796920f91b17f4a68c7e9a795ee8962916b35d39fc1efefc\"]],\"id\":1} getOutputPointer \u00b6 Get the outputPointer that matches with the input provided. Returns an OuputPointer . Example: {\"jsonrpc\": \"2.0\",\"method\": \"getOutput\", \"params\": {\"transaction_id\":{\"SHA256\":[17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17]},\"output_index\":1}, \"id\": \"1\"} Response: {\"jsonrpc\":\"2.0\",\"result\":{\"DataRequest\":{\"backup_witnesses\":0,\"commit_fee\":0,\"data_request\":{\"aggregate\":{\"script\":[0]},\"consensus\":{\"script\":[0]},\"deliver\":[{\"kind\":\"HTTP-GET\",\"url\":\"https://hooks.zapier.com/hooks/catch/3860543/l2awcd/\"}],\"not_before\":0,\"retrieve\":[{\"kind\":\"HTTP-GET\",\"script\":[0],\"url\":\"https://openweathermap.org/data/2.5/weather?id=2950159&appid=b6907d289e10d714a6e88b30761fae22\"}]},\"pkh\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"reveal_fee\":0,\"tally_fee\":0,\"time_lock\":0,\"value\":0,\"witnesses\":0}},\"id\":\"1\"}","title":"JSON-RPC"},{"location":"interface/json-rpc/#json-rpc","text":"JSON-RPC is a stateless, light-weight remote procedure call (RPC) protocol. Primarily this specification defines several data structures and the rules around their processing. It is transport agnostic in that the concepts can be used within the same process, over sockets, over http, or in many various message passing environments. It uses JSON ( RFC 4627 ) as data format. For more details, see the JSON-RPC 2.0 Specification .","title":"JSON-RPC"},{"location":"interface/json-rpc/#server","text":"By default, a JSON-RPC server is started at 127.0.0.1:21338 . It can be disabled in the configuration file .","title":"Server"},{"location":"interface/json-rpc/#protocol","text":"A message must be a valid utf8 string finished with a newline ( \\n ). The parser will start processing the request when it finds the first newline. Therefore, the JSON string cannot contain any newlines expect for the final one. NewLineCodec","title":"Protocol"},{"location":"interface/json-rpc/#methods","text":"See json_rpc_methods.rs for the implementation details.","title":"Methods"},{"location":"interface/json-rpc/#inventory","text":"Make the node process, validate and potentially broadcast a new inventory item. @params: InventoryItem /// Inventory element: block, transaction, etc #[derive(Debug, Eq, PartialEq, Clone, Serialize, Deserialize)] pub enum InventoryItem { /// Error #[serde(rename = \"error\" )] Error , /// Transaction #[serde(rename = \"transaction\" )] Transaction ( Transaction ), /// Block #[serde(rename = \"block\" )] Block ( Block ), } @returns: boolean indicating success, or parse error Example: {\"jsonrpc\": \"2.0\", \"method\": \"inventory\", \"params\": {\"block\":{\"block_header\":{\"version\":1,\"beacon\":{\"checkpoint\":2,\"hash_prev_block\":{\"SHA256\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4]}},\"hash_merkle_root\":{\"SHA256\":[3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3]}},\"proof\":{\"block_sig\":null,\"influence\":99999},\"txns\":[null]}}, \"id\": 1} Response: {\"jsonrpc\":\"2.0\",\"result\":true,\"id\":1}","title":"inventory"},{"location":"interface/json-rpc/#getblockchain","text":"Get the list of all the known block hashes. Returns a list of (epoch, block_hash) pairs. Example: {\"jsonrpc\": \"2.0\",\"method\": \"getBlockChain\", \"id\": 1} Response: {\"jsonrpc\":\"2.0\",\"result\":[[0,\"ed28899af8c3148a4162736af942bc68c4466da93c5124dabfaa7c582af49e30\"],[1,\"9c9038cfb31a7050796920f91b17f4a68c7e9a795ee8962916b35d39fc1efefc\"]],\"id\":1}","title":"getBlockChain"},{"location":"interface/json-rpc/#getoutputpointer","text":"Get the outputPointer that matches with the input provided. Returns an OuputPointer . Example: {\"jsonrpc\": \"2.0\",\"method\": \"getOutput\", \"params\": {\"transaction_id\":{\"SHA256\":[17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17]},\"output_index\":1}, \"id\": \"1\"} Response: {\"jsonrpc\":\"2.0\",\"result\":{\"DataRequest\":{\"backup_witnesses\":0,\"commit_fee\":0,\"data_request\":{\"aggregate\":{\"script\":[0]},\"consensus\":{\"script\":[0]},\"deliver\":[{\"kind\":\"HTTP-GET\",\"url\":\"https://hooks.zapier.com/hooks/catch/3860543/l2awcd/\"}],\"not_before\":0,\"retrieve\":[{\"kind\":\"HTTP-GET\",\"script\":[0],\"url\":\"https://openweathermap.org/data/2.5/weather?id=2950159&appid=b6907d289e10d714a6e88b30761fae22\"}]},\"pkh\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"reveal_fee\":0,\"tally_fee\":0,\"time_lock\":0,\"value\":0,\"witnesses\":0}},\"id\":\"1\"}","title":"getOutputPointer"},{"location":"protocol/blocks/","text":"Page under construction. Check back soon. \u00b6","title":"Blocks"},{"location":"protocol/blocks/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"protocol/mining/","text":"Page under construction. Check back soon. \u00b6","title":"Mining"},{"location":"protocol/mining/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"protocol/reputation/","text":"Page under construction. Check back soon. \u00b6","title":"Reputation"},{"location":"protocol/reputation/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"protocol/serialization/","text":"Serialization \u00b6 An open protocol needs portable serialization to easily enable alternative implementations. Witnet uses Protocol Buffers ( version 3 ) to achieve this goal. The Witnet protocol schema is available here . Why Protocol Buffers? \u00b6 At the time of this writing Protocol Buffers is best alternative with support for a standard schema. It has wide support for most popular programming languages and supports the most common data structures. Custom encodings \u00b6 Sometimes Protocol Buffers do not provide the necessary flexibility when defining custom types. For example, Protocol Buffers do not support fixed size arrays so the verification that a hash has the correct size is done at a higher level. All the structures which use a custom serialization can be found in proto/mod.rs . The following structures are represented as bytes in the protobuf schema: ( || denotes concatenation) Signature : bytes [ u8 ; 65 ] => r || s || v Address : bytes [ u8 ; 6 ] => ( Ipv4 ) ip || port [ u8 ; 18 ] => ( Ipv6 ) ip0 || ip1 || ip2 || ip3 || port Integers \u00b6 Another important point is integer support: in Protocol Buffers the smallest integer size is 32 bits. But a uint32 uses variable length encoding, meaning that it can take from 1 to 5 bytes to encode a number depending on its magnitude. Fixed-size integers are also available, as fixed32 and fixed64 . The default integer mapping is the following: Rust Protobuf u16 uint32 u32 fixed32 u64 fixed64 i8 sint32 i16 sint32 i32 sfixed32 i64 sfixed64 However 32 and 64-bit integers can also be encoded using variable length encoding when that makes sense, for example when the number is expected to be low. The Rust structs do not need any modifications for this type of changes, a u32 can be converted from and into a sfixed32 as well as a sint32 . Hashing \u00b6 It is possible to construct two different protobuf messages which decode to the same value. In order to ensure that these two messages have the same hash, the message bytes are not hashed directly: they are first decoded from protobuf to Rust structs, running the necessary validations, then encoded again as protobuf, and that new encoding is hashed.","title":"Serialization"},{"location":"protocol/serialization/#serialization","text":"An open protocol needs portable serialization to easily enable alternative implementations. Witnet uses Protocol Buffers ( version 3 ) to achieve this goal. The Witnet protocol schema is available here .","title":"Serialization"},{"location":"protocol/serialization/#why-protocol-buffers","text":"At the time of this writing Protocol Buffers is best alternative with support for a standard schema. It has wide support for most popular programming languages and supports the most common data structures.","title":"Why Protocol Buffers?"},{"location":"protocol/serialization/#custom-encodings","text":"Sometimes Protocol Buffers do not provide the necessary flexibility when defining custom types. For example, Protocol Buffers do not support fixed size arrays so the verification that a hash has the correct size is done at a higher level. All the structures which use a custom serialization can be found in proto/mod.rs . The following structures are represented as bytes in the protobuf schema: ( || denotes concatenation) Signature : bytes [ u8 ; 65 ] => r || s || v Address : bytes [ u8 ; 6 ] => ( Ipv4 ) ip || port [ u8 ; 18 ] => ( Ipv6 ) ip0 || ip1 || ip2 || ip3 || port","title":"Custom encodings"},{"location":"protocol/serialization/#integers","text":"Another important point is integer support: in Protocol Buffers the smallest integer size is 32 bits. But a uint32 uses variable length encoding, meaning that it can take from 1 to 5 bytes to encode a number depending on its magnitude. Fixed-size integers are also available, as fixed32 and fixed64 . The default integer mapping is the following: Rust Protobuf u16 uint32 u32 fixed32 u64 fixed64 i8 sint32 i16 sint32 i32 sfixed32 i64 sfixed64 However 32 and 64-bit integers can also be encoded using variable length encoding when that makes sense, for example when the number is expected to be low. The Rust structs do not need any modifications for this type of changes, a u32 can be converted from and into a sfixed32 as well as a sint32 .","title":"Integers"},{"location":"protocol/serialization/#hashing","text":"It is possible to construct two different protobuf messages which decode to the same value. In order to ensure that these two messages have the same hash, the message bytes are not hashed directly: they are first decoded from protobuf to Rust structs, running the necessary validations, then encoded again as protobuf, and that new encoding is hashed.","title":"Hashing"},{"location":"protocol/task-assignment/","text":"Page under construction. Check back soon. \u00b6","title":"Task assignment"},{"location":"protocol/task-assignment/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"protocol/transactions/","text":"Page under construction. Check back soon. \u00b6","title":"Introduction"},{"location":"protocol/transactions/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"protocol/witscript/","text":"Page under construction. Check back soon. \u00b6","title":"WitScript"},{"location":"protocol/witscript/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"protocol/data-requests/overview/","text":"Data requests \u00b6 Data requests are the cornerstone of the Witnet protocol. They allow clients to have witness nodes retrieve , aggregate and deliver data on their behalf on demand. Request life cycle \u00b6 Once a data request has been published by a client, it will go through 4 distinct phases: retrieval , aggregation , consensus and delivery . These phases are linear and constitute a single, unidirectional data flow. \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2551 Client \u2551 \u2551 Witnesses \u2551 \u2551 Miner \u2551 \u2551 Bridge \u2551 \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563 \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563 \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563 \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563 \u2551 Publish \u2551 => \u2551 Retrieve => Aggregate \u2551 => \u2551 Consensus \u2551 => \u2551 Deliver \u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u2560\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2563 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u2551 Retrieve => Aggregate \u2551 \u2560\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2563 \u2551 ... (as many as requested) \u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d In each phase, its input data is the output data of the previous phase. For the sake of deterministic execution, data flowing through the different phases is strongly typed. The type of a value or data structure defines the operations that can be done on the data. In each phase, its input data type is the output data type of the previous phase. Particularly, the aggregation and consensus phases gather multiple values or structures emitted by their precedent phases, so they always receive an Array . For more information on data types, you can read the RADON documentation , which provides a detailed description of all the types and the operators they provide. The RAD Engine \u00b6 The RAD Engine is the component in charge of processing data requests coming from Witnet clients. That is, coordinating retrieval, aggregation, consensus and delivery of data strictly as specified in the requests. All data requests contain explicit instructions on what the RAD Engine must do during every phase. These instructions, specified using RAD Object Notation (RADON) , are interpreted by the RAD Engine. Just in case you were asking, RAD stands for Retrieve , Aggregate and Deliver . RAD Object Notation (RADON) \u00b6 The RAD Object Notation (RADON) is a low-level, declarative, functional, strongly-typed, Non-Turing complete programming language. A RADON script is formed by a list of ordered calls (tuples of operators and arguments) that are sequentially interpreted and applied by the RAD Engine on the output of the previous call. Creating data requests \u00b6 The RAD Engine is only capable of interpreting well-formed RADON scripts . Even though human beings can safely write RADON without their heads exploding \ud83e\udd2f, they are just expected to do not. The higher-level RADlang programming language should be used instead for writing data requests in a much more expressive and user-friendly way. The Sheikah desktop app is intended to be used as an IDE for Witnet data requests, so it will act as a compiler for transforming RADlang into RADON. While RADlang and Sheikah are maintained by Witnet Foundation, other third-party developers can create their own high-level programming languages to abstract away from the complexity of RADON.","title":"Overview"},{"location":"protocol/data-requests/overview/#data-requests","text":"Data requests are the cornerstone of the Witnet protocol. They allow clients to have witness nodes retrieve , aggregate and deliver data on their behalf on demand.","title":"Data requests"},{"location":"protocol/data-requests/overview/#request-life-cycle","text":"Once a data request has been published by a client, it will go through 4 distinct phases: retrieval , aggregation , consensus and delivery . These phases are linear and constitute a single, unidirectional data flow. \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2551 Client \u2551 \u2551 Witnesses \u2551 \u2551 Miner \u2551 \u2551 Bridge \u2551 \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563 \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563 \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563 \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563 \u2551 Publish \u2551 => \u2551 Retrieve => Aggregate \u2551 => \u2551 Consensus \u2551 => \u2551 Deliver \u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u2560\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2563 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u2551 Retrieve => Aggregate \u2551 \u2560\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2563 \u2551 ... (as many as requested) \u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d In each phase, its input data is the output data of the previous phase. For the sake of deterministic execution, data flowing through the different phases is strongly typed. The type of a value or data structure defines the operations that can be done on the data. In each phase, its input data type is the output data type of the previous phase. Particularly, the aggregation and consensus phases gather multiple values or structures emitted by their precedent phases, so they always receive an Array . For more information on data types, you can read the RADON documentation , which provides a detailed description of all the types and the operators they provide.","title":"Request life cycle"},{"location":"protocol/data-requests/overview/#the-rad-engine","text":"The RAD Engine is the component in charge of processing data requests coming from Witnet clients. That is, coordinating retrieval, aggregation, consensus and delivery of data strictly as specified in the requests. All data requests contain explicit instructions on what the RAD Engine must do during every phase. These instructions, specified using RAD Object Notation (RADON) , are interpreted by the RAD Engine. Just in case you were asking, RAD stands for Retrieve , Aggregate and Deliver .","title":"The RAD Engine"},{"location":"protocol/data-requests/overview/#rad-object-notation-radon","text":"The RAD Object Notation (RADON) is a low-level, declarative, functional, strongly-typed, Non-Turing complete programming language. A RADON script is formed by a list of ordered calls (tuples of operators and arguments) that are sequentially interpreted and applied by the RAD Engine on the output of the previous call.","title":"RAD Object Notation (RADON)"},{"location":"protocol/data-requests/overview/#creating-data-requests","text":"The RAD Engine is only capable of interpreting well-formed RADON scripts . Even though human beings can safely write RADON without their heads exploding \ud83e\udd2f, they are just expected to do not. The higher-level RADlang programming language should be used instead for writing data requests in a much more expressive and user-friendly way. The Sheikah desktop app is intended to be used as an IDE for Witnet data requests, so it will act as a compiler for transforming RADlang into RADON. While RADlang and Sheikah are maintained by Witnet Foundation, other third-party developers can create their own high-level programming languages to abstract away from the complexity of RADON.","title":"Creating data requests"},{"location":"protocol/data-requests/radlang/","text":"Page under construction. Check back soon. \u00b6","title":"RADlang"},{"location":"protocol/data-requests/radlang/#page-under-construction-check-back-soon","text":"","title":"Page under construction. Check back soon."},{"location":"protocol/data-requests/radon/constants/","text":"Constants \u00b6 Types \u00b6 Byte Decimal Constant 0x00 0 TYPE_BOOLEAN 0x01 1 TYPE_INT 0x02 2 TYPE_FLOAT 0x03 3 TYPE_STRING 0x04 4 TYPE_ARRAY 0x05 5 TYPE_MAP 0x06 6 TYPE_MIXED 0x07 7 TYPE_NULL 0x08 8 TYPE_RESULT Operators \u00b6 Boolean operators \u00b6 Byte Decimal Constant 0x00 0 BOOLEAN_MATCH 0x01 1 BOOLEAN_NEG 0x02 2 BOOLEAN_TOSTRING Int operators \u00b6 Byte Decimal Constant 0x00 0 INT_ABS 0x01 1 INT_MATCH 0x02 2 INT_MODULO 0x03 3 INT_MULT 0x04 4 INT_NEG 0x05 5 INT_POW 0x06 6 INT_RECIP 0x07 7 INT_SUM 0x08 8 INT_TOFLOAT 0x09 9 INT_TOSTRING Float operators \u00b6 Byte Decimal Constant 0x00 0 FLOAT_ABS 0x01 1 FLOAT_CEIL 0x02 2 FLOAT_FLOOR 0x03 3 FLOAT_MODULO 0x04 4 FLOAT_MULT 0x05 5 FLOAT_NEG 0x06 6 FLOAT_POW 0x07 7 FLOAT_RECIP 0x08 8 FLOAT_ROUND 0x09 9 FLOAT_SUM 0x0a 10 FLOAT_TOSTRING 0x0b 11 FLOAT_TRUNC String operators \u00b6 Byte Decimal Constant 0x00 0 STRING_HASH 0x01 1 STRING_LENGTH 0x02 2 STRING_MATCH 0x03 3 STRING_PARSEJSON 0x04 4 STRING_PARSEXML 0x05 5 STRING_TOBOOLEAN 0x06 6 STRING_TOFLOAT 0x07 7 STRING_TOINT 0x08 8 STRING_TOLOWERCASE 0x09 9 STRING_TOUPPERCASE Array operators \u00b6 Byte Decimal Constant 0x00 0 ARRAY_COUNT 0x01 1 ARRAY_EVERY 0x02 2 ARRAY_FILTER 0x03 3 ARRAY_FLATTEN 0x04 4 ARRAY_GET 0x05 5 ARRAY_MAP 0x06 6 ARRAY_REDUCE 0x07 7 ARRAY_SOME 0x08 8 ARRAY_SORT 0x09 9 ARRAY_TAKE Map operators \u00b6 Byte Decimal Constant 0x00 0 MAP_ENTRIES 0x00 0 MAP_GET 0x00 0 MAP_KEYS 0x00 0 MAP_VALUES Mixed operators \u00b6 Byte Decimal Constant 0x00 0 MIXED_TOARRAY 0x01 1 MIXED_TOBOOLEAN 0x02 2 MIXED_TOFLOAT 0x03 3 MIXED_TOINT 0x04 4 MIXED_TOMAP Result operators \u00b6 Byte Decimal Constant 0x00 0 RESULT_GET 0x01 1 RESULT_GETOR 0x02 2 RESULT_ISOK Hash functions \u00b6 Byte Decimal Constant 0x00 0 BLAKE_256 0x01 1 BLAKE_512 0x02 2 BLAKE2S_256 0x03 3 BLAKE2B_512 0x04 4 MD5_128 0x05 5 RIPEMD_128 0x06 6 RIPEMD_160 0x07 7 RIPEMD_320 0x08 8 SHA1_160 0x09 9 SHA2_224 0x0a 10 SHA2_256 0x0b 11 SHA2_384 0x0c 12 SHA2_512 0x0d 13 SHA3_224 0x0e 14 SHA3_256 0x0f 15 SHA3_384 0x10 16 SHA3_512 0x11 17 WHIRLPOOL_512 Filtering functions \u00b6 Byte Decimal Constant 0x00 0 FILTER_GT 0x01 1 FILTER_LT 0x02 2 FILTER_EQ 0x03 3 FILTER_DEV_ABS 0x04 4 FILTER_DEV_REL 0x05 5 FILTER_DEV_STD 0x06 6 FILTER_TOP 0x07 7 FILTER_BOTTOM 0x80 128 FILTER_NOT_GT 0x81 129 FILTER_NOT_LT 0x82 130 FILTER_NOT_EQ 0x83 131 FILTER_NOT_DEV_ABS 0x84 132 FILTER_NOT_DEV_REL 0x85 133 FILTER_NOT_DEV_STD 0x86 134 FILTER_NOT_TOP 0x87 135 FILTER_NOT_BOTTOM Tip Negative filtering functions constants always equate to the value of their positive counterpart plus 128 . Reducing functions \u00b6 Byte Decimal Constant 0x00 0 REDUCER_MIN 0x01 1 REDUCER_MAX 0x02 2 REDUCER_MODE 0x03 3 REDUCER_AVG_MEAN 0x04 4 REDUCER_AVG_MEAN_W 0x05 5 REDUCER_AVG_MEDIAN 0x06 6 REDUCER_AVG_MEDIAN_W 0x07 7 REDUCER_DEV_STD 0x08 8 REDUCER_DEV_AVG 0x09 9 REDUCER_DEV_MED 0x0a 10 REDUCER_DEV_MAX","title":"Constants"},{"location":"protocol/data-requests/radon/constants/#constants","text":"","title":"Constants"},{"location":"protocol/data-requests/radon/constants/#types","text":"Byte Decimal Constant 0x00 0 TYPE_BOOLEAN 0x01 1 TYPE_INT 0x02 2 TYPE_FLOAT 0x03 3 TYPE_STRING 0x04 4 TYPE_ARRAY 0x05 5 TYPE_MAP 0x06 6 TYPE_MIXED 0x07 7 TYPE_NULL 0x08 8 TYPE_RESULT","title":"Types"},{"location":"protocol/data-requests/radon/constants/#operators","text":"","title":"Operators"},{"location":"protocol/data-requests/radon/constants/#boolean-operators","text":"Byte Decimal Constant 0x00 0 BOOLEAN_MATCH 0x01 1 BOOLEAN_NEG 0x02 2 BOOLEAN_TOSTRING","title":"Boolean operators"},{"location":"protocol/data-requests/radon/constants/#int-operators","text":"Byte Decimal Constant 0x00 0 INT_ABS 0x01 1 INT_MATCH 0x02 2 INT_MODULO 0x03 3 INT_MULT 0x04 4 INT_NEG 0x05 5 INT_POW 0x06 6 INT_RECIP 0x07 7 INT_SUM 0x08 8 INT_TOFLOAT 0x09 9 INT_TOSTRING","title":"Int operators"},{"location":"protocol/data-requests/radon/constants/#float-operators","text":"Byte Decimal Constant 0x00 0 FLOAT_ABS 0x01 1 FLOAT_CEIL 0x02 2 FLOAT_FLOOR 0x03 3 FLOAT_MODULO 0x04 4 FLOAT_MULT 0x05 5 FLOAT_NEG 0x06 6 FLOAT_POW 0x07 7 FLOAT_RECIP 0x08 8 FLOAT_ROUND 0x09 9 FLOAT_SUM 0x0a 10 FLOAT_TOSTRING 0x0b 11 FLOAT_TRUNC","title":"Float operators"},{"location":"protocol/data-requests/radon/constants/#string-operators","text":"Byte Decimal Constant 0x00 0 STRING_HASH 0x01 1 STRING_LENGTH 0x02 2 STRING_MATCH 0x03 3 STRING_PARSEJSON 0x04 4 STRING_PARSEXML 0x05 5 STRING_TOBOOLEAN 0x06 6 STRING_TOFLOAT 0x07 7 STRING_TOINT 0x08 8 STRING_TOLOWERCASE 0x09 9 STRING_TOUPPERCASE","title":"String operators"},{"location":"protocol/data-requests/radon/constants/#array-operators","text":"Byte Decimal Constant 0x00 0 ARRAY_COUNT 0x01 1 ARRAY_EVERY 0x02 2 ARRAY_FILTER 0x03 3 ARRAY_FLATTEN 0x04 4 ARRAY_GET 0x05 5 ARRAY_MAP 0x06 6 ARRAY_REDUCE 0x07 7 ARRAY_SOME 0x08 8 ARRAY_SORT 0x09 9 ARRAY_TAKE","title":"Array operators"},{"location":"protocol/data-requests/radon/constants/#map-operators","text":"Byte Decimal Constant 0x00 0 MAP_ENTRIES 0x00 0 MAP_GET 0x00 0 MAP_KEYS 0x00 0 MAP_VALUES","title":"Map operators"},{"location":"protocol/data-requests/radon/constants/#mixed-operators","text":"Byte Decimal Constant 0x00 0 MIXED_TOARRAY 0x01 1 MIXED_TOBOOLEAN 0x02 2 MIXED_TOFLOAT 0x03 3 MIXED_TOINT 0x04 4 MIXED_TOMAP","title":"Mixed operators"},{"location":"protocol/data-requests/radon/constants/#result-operators","text":"Byte Decimal Constant 0x00 0 RESULT_GET 0x01 1 RESULT_GETOR 0x02 2 RESULT_ISOK","title":"Result operators"},{"location":"protocol/data-requests/radon/constants/#hash-functions","text":"Byte Decimal Constant 0x00 0 BLAKE_256 0x01 1 BLAKE_512 0x02 2 BLAKE2S_256 0x03 3 BLAKE2B_512 0x04 4 MD5_128 0x05 5 RIPEMD_128 0x06 6 RIPEMD_160 0x07 7 RIPEMD_320 0x08 8 SHA1_160 0x09 9 SHA2_224 0x0a 10 SHA2_256 0x0b 11 SHA2_384 0x0c 12 SHA2_512 0x0d 13 SHA3_224 0x0e 14 SHA3_256 0x0f 15 SHA3_384 0x10 16 SHA3_512 0x11 17 WHIRLPOOL_512","title":"Hash functions"},{"location":"protocol/data-requests/radon/constants/#filtering-functions","text":"Byte Decimal Constant 0x00 0 FILTER_GT 0x01 1 FILTER_LT 0x02 2 FILTER_EQ 0x03 3 FILTER_DEV_ABS 0x04 4 FILTER_DEV_REL 0x05 5 FILTER_DEV_STD 0x06 6 FILTER_TOP 0x07 7 FILTER_BOTTOM 0x80 128 FILTER_NOT_GT 0x81 129 FILTER_NOT_LT 0x82 130 FILTER_NOT_EQ 0x83 131 FILTER_NOT_DEV_ABS 0x84 132 FILTER_NOT_DEV_REL 0x85 133 FILTER_NOT_DEV_STD 0x86 134 FILTER_NOT_TOP 0x87 135 FILTER_NOT_BOTTOM Tip Negative filtering functions constants always equate to the value of their positive counterpart plus 128 .","title":"Filtering functions"},{"location":"protocol/data-requests/radon/constants/#reducing-functions","text":"Byte Decimal Constant 0x00 0 REDUCER_MIN 0x01 1 REDUCER_MAX 0x02 2 REDUCER_MODE 0x03 3 REDUCER_AVG_MEAN 0x04 4 REDUCER_AVG_MEAN_W 0x05 5 REDUCER_AVG_MEDIAN 0x06 6 REDUCER_AVG_MEDIAN_W 0x07 7 REDUCER_DEV_STD 0x08 8 REDUCER_DEV_AVG 0x09 9 REDUCER_DEV_MED 0x0a 10 REDUCER_DEV_MAX","title":"Reducing functions"},{"location":"protocol/data-requests/radon/encoding/","text":"RADON encoding \u00b6 RADON scripts are encoded using MessagePack , a very efficient, compact and widely supported data structure encoding. Before encoding, a RADON script looks like this: [ STRING_PARSEJSON , MIXED_TOMAP , [ MAP_GET , \"weather\" ], MIXED_TOMAP , [ MAP_GET , \"temp\" ], MIXED_TOFLOAT ] After encoding, we get an impressively compact (22 bytes long) output: // Base64 lgMEkgCnd2VhdGhlcgSSAKR0ZW1wAg Constants All across this documentation, unquoted uppercase names like STRING_PARSEJSON identify different operators and constants that equate to a single byte when encoded. A list of constants can be found in the Constants section .","title":"Encoding"},{"location":"protocol/data-requests/radon/encoding/#radon-encoding","text":"RADON scripts are encoded using MessagePack , a very efficient, compact and widely supported data structure encoding. Before encoding, a RADON script looks like this: [ STRING_PARSEJSON , MIXED_TOMAP , [ MAP_GET , \"weather\" ], MIXED_TOMAP , [ MAP_GET , \"temp\" ], MIXED_TOFLOAT ] After encoding, we get an impressively compact (22 bytes long) output: // Base64 lgMEkgCnd2VhdGhlcgSSAKR0ZW1wAg Constants All across this documentation, unquoted uppercase names like STRING_PARSEJSON identify different operators and constants that equate to a single byte when encoded. A list of constants can be found in the Constants section .","title":"RADON encoding"},{"location":"protocol/data-requests/radon/examples/","text":"Examples \u00b6 Retrieval phase \u00b6 [ // String STRING_PARSEJSON , // Mixed MIXED_TOMAP , // Map<String, Mixed> [ MAP_GET , \"main\" ], // Mixed MIXED_TOMAP , // Map<String, Mixed> [ MAP_GET , \"temp\" ], // Mixed MIXED_TOFLOAT // Float ] // Result<Float> This example retrieval script does the following on the result of this OpenWeatherMap API call : Parse the input String as a JSON document (retrieval always starts with String ), Treat the structure as a Map<String, Mixed> , Take the value of the \"main\" key, Treat the structure as a Map<String, Mixed> . Take the value of the \"temp\" key, Emit the value as a Float . Aggregation phase \u00b6 [ // Array<Result<Float>> ARRAY_FLATMAP , // Array<Float> [ ARRAY_FILTER , FILTER_GT , - 30 ], // Array<Float> [ ARRAY_FILTER , FILTER_LT , 50 ], // Array<Float> [ ARRAY_FILTER , FILTER_DEV_ABS , 2 ], // Array<Float> [ ARRAY_REDUCE , REDUCER_AVG_MEAN ] // Float ] // Result<Float> This example aggregation script does the following: Drop every negative Result ( Err items) from the input Array , Drop values less or equal than -30 , Drop values greater or equal than 50 , Drop values deviating from the average more than 2 , Calculate and emit the arithmetic mean of the remaining values in the Array . Consensus phase \u00b6 [ // Array<Result<Float>> ARRAY_FLATMAP , [ ARRAY_REDUCE , REDUCE_AVG_MEAN ] // Float ] // Result<Float> This example consensus script does the following: Drop every negative Result ( Err items) from the input Array , Calculate and emit the arithmetic mean of the remaining values in the Array .","title":"Examples"},{"location":"protocol/data-requests/radon/examples/#examples","text":"","title":"Examples"},{"location":"protocol/data-requests/radon/examples/#retrieval-phase","text":"[ // String STRING_PARSEJSON , // Mixed MIXED_TOMAP , // Map<String, Mixed> [ MAP_GET , \"main\" ], // Mixed MIXED_TOMAP , // Map<String, Mixed> [ MAP_GET , \"temp\" ], // Mixed MIXED_TOFLOAT // Float ] // Result<Float> This example retrieval script does the following on the result of this OpenWeatherMap API call : Parse the input String as a JSON document (retrieval always starts with String ), Treat the structure as a Map<String, Mixed> , Take the value of the \"main\" key, Treat the structure as a Map<String, Mixed> . Take the value of the \"temp\" key, Emit the value as a Float .","title":"Retrieval phase"},{"location":"protocol/data-requests/radon/examples/#aggregation-phase","text":"[ // Array<Result<Float>> ARRAY_FLATMAP , // Array<Float> [ ARRAY_FILTER , FILTER_GT , - 30 ], // Array<Float> [ ARRAY_FILTER , FILTER_LT , 50 ], // Array<Float> [ ARRAY_FILTER , FILTER_DEV_ABS , 2 ], // Array<Float> [ ARRAY_REDUCE , REDUCER_AVG_MEAN ] // Float ] // Result<Float> This example aggregation script does the following: Drop every negative Result ( Err items) from the input Array , Drop values less or equal than -30 , Drop values greater or equal than 50 , Drop values deviating from the average more than 2 , Calculate and emit the arithmetic mean of the remaining values in the Array .","title":"Aggregation phase"},{"location":"protocol/data-requests/radon/examples/#consensus-phase","text":"[ // Array<Result<Float>> ARRAY_FLATMAP , [ ARRAY_REDUCE , REDUCE_AVG_MEAN ] // Float ] // Result<Float> This example consensus script does the following: Drop every negative Result ( Err items) from the input Array , Calculate and emit the arithmetic mean of the remaining values in the Array .","title":"Consensus phase"},{"location":"protocol/data-requests/radon/exceptions/","text":"Exception handling \u00b6 When a call in a RADON script causes a runtime exception, the script execution flow is immediately stopped. But do not panic: this does not seem the entire data request will fail. RADON has a solid strategy for recovering from those situations. Exceptions generated in a certain phase in the data request life cycle do progress to the next phase wrapped in a Result<V> with value Err . This provides a type safe API for handling success and errors in a uniform way, and gives the developer the choice to recover from exceptions as appropriate for the use case (dropping errors, mapping them into default values, etc.)","title":"Exception handling"},{"location":"protocol/data-requests/radon/exceptions/#exception-handling","text":"When a call in a RADON script causes a runtime exception, the script execution flow is immediately stopped. But do not panic: this does not seem the entire data request will fail. RADON has a solid strategy for recovering from those situations. Exceptions generated in a certain phase in the data request life cycle do progress to the next phase wrapped in a Result<V> with value Err . This provides a type safe API for handling success and errors in a uniform way, and gives the developer the choice to recover from exceptions as appropriate for the use case (dropping errors, mapping them into default values, etc.)","title":"Exception handling"},{"location":"protocol/data-requests/radon/functions/","text":"Predefined functions \u00b6 Filtering functions \u00b6 gt : must be greater than the provided value. lt : must be less than the provided value. eq : must equal the provided value. dev-$type : must not deviate from the average. This has three subtypes: dev-abs : must not deviate from the average more than the provided absolute value. dev-rel : must not deviate from the average more than the provided relative value (e.g.: 0.5 is 50%). dev-std : must not deviate from the average more than value times the standard deviation of the values in the Array , where value is typically a Float between 1 (picky) and 3 (relaxed). top : must be amongst the value highest values in the Array . bottom : must be amongst the value lowest values in the Array . not-$function : applies the opposite of any of the previous functions (e.g.: not-lt equates to \"greater or equal than\" ). The implicit signature for all of the filtering functions is: ( value : T ) : Boolean Some functions that compare individual values to the values in the Array are pointless if used along the some operator as they will make it return False every time. These include: top bottom Reducing functions \u00b6 min : takes the minimum value. max : takes the maximum value. mode : takes the mode . That is, the value that appears the more often. avg-$type : calculates the average of the values in the Array . This has four subtypes: avg-mean : arithmetic mean . avg-mean-w : weighted mean . avg-median : median . avg-median-w : weighted median . dev-$type : measures the dispersion of the values in the Array . This has four subtypes: dev-std : standard deviation . dev-avg : average absolute deviation . dev-med : median absolute deviation . dev-max : maximum absolute deviation . Hash functions \u00b6 BLAKE family: blake-256 blake-512 blake2s-256 blake2b-512 MD5: md5-128 RIPEMD family: ripemd-128 ripemd-160 ripemd-320 SHA1: sha1-160 SHA2 family: sha2-224 sha2-256 sha2-384 sha2-512 SHA3 family: sha3-224 sha3-256 sha3-384 sha3-512 Whirlpool: whirlpool-512 Safety of deprecated hash functions The md5-128 and sha1-160 hash functions are provided solely for the sake of backward compatibility with legacy software and systems. Depending on the use case, they may not live up to minimum acceptable security standards. Please refrain from using those for new software and systems unless strictly necessary.","title":"Predefined functions"},{"location":"protocol/data-requests/radon/functions/#predefined-functions","text":"","title":"Predefined functions"},{"location":"protocol/data-requests/radon/functions/#filtering-functions","text":"gt : must be greater than the provided value. lt : must be less than the provided value. eq : must equal the provided value. dev-$type : must not deviate from the average. This has three subtypes: dev-abs : must not deviate from the average more than the provided absolute value. dev-rel : must not deviate from the average more than the provided relative value (e.g.: 0.5 is 50%). dev-std : must not deviate from the average more than value times the standard deviation of the values in the Array , where value is typically a Float between 1 (picky) and 3 (relaxed). top : must be amongst the value highest values in the Array . bottom : must be amongst the value lowest values in the Array . not-$function : applies the opposite of any of the previous functions (e.g.: not-lt equates to \"greater or equal than\" ). The implicit signature for all of the filtering functions is: ( value : T ) : Boolean Some functions that compare individual values to the values in the Array are pointless if used along the some operator as they will make it return False every time. These include: top bottom","title":"Filtering functions"},{"location":"protocol/data-requests/radon/functions/#reducing-functions","text":"min : takes the minimum value. max : takes the maximum value. mode : takes the mode . That is, the value that appears the more often. avg-$type : calculates the average of the values in the Array . This has four subtypes: avg-mean : arithmetic mean . avg-mean-w : weighted mean . avg-median : median . avg-median-w : weighted median . dev-$type : measures the dispersion of the values in the Array . This has four subtypes: dev-std : standard deviation . dev-avg : average absolute deviation . dev-med : median absolute deviation . dev-max : maximum absolute deviation .","title":"Reducing functions"},{"location":"protocol/data-requests/radon/functions/#hash-functions","text":"BLAKE family: blake-256 blake-512 blake2s-256 blake2b-512 MD5: md5-128 RIPEMD family: ripemd-128 ripemd-160 ripemd-320 SHA1: sha1-160 SHA2 family: sha2-224 sha2-256 sha2-384 sha2-512 SHA3 family: sha3-224 sha3-256 sha3-384 sha3-512 Whirlpool: whirlpool-512 Safety of deprecated hash functions The md5-128 and sha1-160 hash functions are provided solely for the sake of backward compatibility with legacy software and systems. Depending on the use case, they may not live up to minimum acceptable security standards. Please refrain from using those for new software and systems unless strictly necessary.","title":"Hash functions"},{"location":"protocol/data-requests/radon/subscripts/","text":"Subscripts \u00b6 Some operators like allow specifying particular sequences of calls (scripts) that will be executed inside the scope of the operator itself. We name those as subscripts . That is the case for the Array<T>::map<0>(subscript: (item: T) => O) operator, which applies a subscript in parallel on every T item found in the input Array<T> and then collects the results of the (item: T) => 0 subscripts into a single Array<O> that commits to have the same number of items as the input Array<T> . Therefore, the first call in a subscript must be compatible with the type of the input.","title":"Subscripts"},{"location":"protocol/data-requests/radon/subscripts/#subscripts","text":"Some operators like allow specifying particular sequences of calls (scripts) that will be executed inside the scope of the operator itself. We name those as subscripts . That is the case for the Array<T>::map<0>(subscript: (item: T) => O) operator, which applies a subscript in parallel on every T item found in the input Array<T> and then collects the results of the (item: T) => 0 subscripts into a single Array<O> that commits to have the same number of items as the input Array<T> . Therefore, the first call in a subscript must be compatible with the type of the input.","title":"Subscripts"},{"location":"protocol/data-requests/radon/wrapping/","text":"Implicit Result<V> wrapping \u00b6 When the last call in a RADON script is successfully executed, its result does not progress directly to the next phase in the data request life cycle. Instead, it is first wrapped in a Result<T> with value Ok<T> , where T is the return data type of the last call in the script.","title":"Implicit `Result<V>` wrapping"},{"location":"protocol/data-requests/radon/wrapping/#implicit-resultv-wrapping","text":"When the last call in a RADON script is successfully executed, its result does not progress directly to the next phase in the data request life cycle. Instead, it is first wrapped in a Result<T> with value Ok<T> , where T is the return data type of the last call in the script.","title":"Implicit Result&lt;V&gt; wrapping"},{"location":"protocol/data-requests/radon/types/array/","text":"Array<T> type \u00b6 An Array<T> is an ordered sequence of zero, one or more values or data structures of the same type, T . Array.count() \u00b6 count () : Int ARRAY_COUNT The count operator just takes an Array<T> and returns its length as an Int . Array.every(function) \u00b6 every ( function : ( item : T ) => Boolean )) : Boolean [ ARRAY_EVERY , function ] The .every operator returns True if the result of applying a function on every each of the items in a given Array<T> is True . It returns False otherwise. The supplied (input: T): O function can be either be a valid subscript over type T or one of the predefined filtering functions . This operator can throw a runtime exception under several circumstances, including: T in the input Array<T> is Mixed Array.filter(function) \u00b6 filter ( function : ( item : T ) => Boolean ) : Array < T > [ ARRAY_FILTER , function ] This operator applies a filtering function on an Array . That is, it will apply the function on every item in the Array and drop those returning False values. The supplied (input: T): O function can be either be a valid subscript over type T or one of the predefined filtering functions . This operator can throw a runtime exception under several circumstances, including: T in the input Array<T> is Mixed Array.flatten() \u00b6 flatten ( depth : Int ) : Array < T > ARRAY_FLATTEN The flatten operator returns a new Array<T> with all the contained Array<T> concatenated into it recursively up to the supplied depth : Int . As Result<T> is equivalent to an Array<T> with zero or one item, applying flatten on an Array<Result<T>> conveniently returns an Array<T> containing only the unwrapped positive results. Example: flattening Array<Result<T>> into Array<T> [ // Array<Int> [ ARRAY_MAP , [ // Int [ INT_MULT , 2 ] // Int ] ], // Array<Result<Int>> ARRAY_FLATTEN , // Array<Int>> [ ARRAY_REDUCE , REDUCER_AVG_MEAN ] // Int ] // Result<Int> Array.get(index) \u00b6 get ( index : Int ) : T [ ARRAY_GET , index ] The get operator returns the T item at index : Int in an Array<T> . This operator can throw a runtime exception if the supplied index : Int is out of the range of the input Array<T> . Exceptions are handled as specified in the [Exception handling] section. Incentive safety This operator may introduce adverse incentives if used in the aggregation or consensus stages. Array.map(operator) \u00b6 map < O > ( function : ( item : T ) => O ) : Array < Result < O >> [ ARRAY_MAP , operator ] The map operator returns a new Array with the results of executing a supplied (item: T): O function on every T element in the input Array<T> , each wrapped in a Result . The supplied (input: T): O function must be a valid subscript over type T . It could happen that the supplied operator failed on some of the T values in the input Array<T> . In such case, breaking the data flow and throwing a runtime exception would be unacceptable. Instead, the map operator wraps each of the items in the returned Array into a Result . Therefore, the return type of the map operator is Array<Result<O>> , where O is the return type of the supplied (item: T): O operator. Example [ // String STRING_PARSEJSON , // Mixed [ MIXED_TOARRAY , TYPE_FLOAT ], // Array<Float> [ ARRAY_MAP , FLOAT_TRUNC ], // Array<Result<Float>> [ ARRAY_FLATMAP ], // Array<Float>, [ ARRAY_REDUCE , REDUCER_AVG_MEAN ] // Float ] // Result<Float> Array.reduce(function) \u00b6 reduce ( function : ( item : T ) => T )) : T [ ARRAY_REDUCE , function ] The reduce operator aggregates the items in the input Array<T> using a the supplied (input: T): O function and returns a single item of type T . The supplied (input: T): O function can be either a valid subscript over type T or one of the [predefined reducing functions][reducer]. This operator can throw a runtime exception under several circumstances, including: T in the input Array<T> is Mixed the reduction function is not mode and T in the input Array<T> is not Int or Float Array.some(function) \u00b6 some ( function : ( item : T ) => Boolean ) : Boolean [ ARRAY_SOME , function ] The some operator returns True if the result of applying a function on at least one of the items in a given Array<T> is True . It returns False otherwise. The supplied (item: T): Boolean function can be either one of the predefined filtering functions or a valid subscript with input type T and output type Boolean . Array.sort(mapFunction, ascending) \u00b6 sort < V > ( mapFunction : ( item : T ) => V , ascending : Boolean = True ) : Array < T > [ ARRAY_SORT , mapFunction , ascending ] The sort operator returns a new Array<T> with the very same items from the input Array<T> but ordered according to the sorting criteria defined by the supplied mapFunction: (item: T) => V and ascending : Boolean arguments. The supplied mapFunction: (item: T) => V must be a valid subscript over type T , and its V output type must be one of the value types: Boolean , Int , Float or String . This function gives the sort operator the power to sort the items in the input Array<T> not by their values but by the values resulting from applying some computation on them. Example [ // Array<Map<String, Int>> [ ARRAY_SORT , [ // Map<String, Int> [ MAP_GET , \"age\" ] // Int ], False ] // Array<Map<String, Int>> ] // Result<Array<Map<String, Int>>> Remember The \"identity\" subscript (one that returns its own input without any transformation) is expressed in RADON as an empty Array : [ ARRAY_SORT , [] ] Incentive safety This operator may introduce adverse incentives if used in the aggregation or consensus stages. Array.take(min, max) \u00b6 take ( min? : Int , max? : Int ) : Array < T > [ ARRAY_TAKE , min , max ] // Providing both a minimum and a maximum The take operator returns a new Array<T> with at least the min : Int first items in the input Array<T> and at most max : Int items. Take at least / Take at most / Take exactly This operator can be easily used to reproduce the \"take at least N items\" and \"take at most N items\" behaviors separately: [ ARRAY_TAKE , 5 ] // \"take at least 5 items\" [ ARRAY_TAKE , 0 , 10 ] // \"take at most 10 items\" Conversely, this will take exactly 7 item (or fail if there are not enough items): [ ARRAY_TAKE , 7 , 7 ] This operator can throw a runtime exception if the input Array<T> does not contain enough items to satisfy the minimum amount of items required by the supplied min : Int argument. Incentive safety This operator may introduce adverse incentives if used in the aggregation or consensus stages.","title":"Array<V>"},{"location":"protocol/data-requests/radon/types/array/#arrayt-type","text":"An Array<T> is an ordered sequence of zero, one or more values or data structures of the same type, T .","title":"Array&lt;T&gt; type"},{"location":"protocol/data-requests/radon/types/array/#arraycount","text":"count () : Int ARRAY_COUNT The count operator just takes an Array<T> and returns its length as an Int .","title":"Array.count()"},{"location":"protocol/data-requests/radon/types/array/#arrayeveryfunction","text":"every ( function : ( item : T ) => Boolean )) : Boolean [ ARRAY_EVERY , function ] The .every operator returns True if the result of applying a function on every each of the items in a given Array<T> is True . It returns False otherwise. The supplied (input: T): O function can be either be a valid subscript over type T or one of the predefined filtering functions . This operator can throw a runtime exception under several circumstances, including: T in the input Array<T> is Mixed","title":"Array.every(function)"},{"location":"protocol/data-requests/radon/types/array/#arrayfilterfunction","text":"filter ( function : ( item : T ) => Boolean ) : Array < T > [ ARRAY_FILTER , function ] This operator applies a filtering function on an Array . That is, it will apply the function on every item in the Array and drop those returning False values. The supplied (input: T): O function can be either be a valid subscript over type T or one of the predefined filtering functions . This operator can throw a runtime exception under several circumstances, including: T in the input Array<T> is Mixed","title":"Array.filter(function)"},{"location":"protocol/data-requests/radon/types/array/#arrayflatten","text":"flatten ( depth : Int ) : Array < T > ARRAY_FLATTEN The flatten operator returns a new Array<T> with all the contained Array<T> concatenated into it recursively up to the supplied depth : Int . As Result<T> is equivalent to an Array<T> with zero or one item, applying flatten on an Array<Result<T>> conveniently returns an Array<T> containing only the unwrapped positive results. Example: flattening Array<Result<T>> into Array<T> [ // Array<Int> [ ARRAY_MAP , [ // Int [ INT_MULT , 2 ] // Int ] ], // Array<Result<Int>> ARRAY_FLATTEN , // Array<Int>> [ ARRAY_REDUCE , REDUCER_AVG_MEAN ] // Int ] // Result<Int>","title":"Array.flatten()"},{"location":"protocol/data-requests/radon/types/array/#arraygetindex","text":"get ( index : Int ) : T [ ARRAY_GET , index ] The get operator returns the T item at index : Int in an Array<T> . This operator can throw a runtime exception if the supplied index : Int is out of the range of the input Array<T> . Exceptions are handled as specified in the [Exception handling] section. Incentive safety This operator may introduce adverse incentives if used in the aggregation or consensus stages.","title":"Array.get(index)"},{"location":"protocol/data-requests/radon/types/array/#arraymapoperator","text":"map < O > ( function : ( item : T ) => O ) : Array < Result < O >> [ ARRAY_MAP , operator ] The map operator returns a new Array with the results of executing a supplied (item: T): O function on every T element in the input Array<T> , each wrapped in a Result . The supplied (input: T): O function must be a valid subscript over type T . It could happen that the supplied operator failed on some of the T values in the input Array<T> . In such case, breaking the data flow and throwing a runtime exception would be unacceptable. Instead, the map operator wraps each of the items in the returned Array into a Result . Therefore, the return type of the map operator is Array<Result<O>> , where O is the return type of the supplied (item: T): O operator. Example [ // String STRING_PARSEJSON , // Mixed [ MIXED_TOARRAY , TYPE_FLOAT ], // Array<Float> [ ARRAY_MAP , FLOAT_TRUNC ], // Array<Result<Float>> [ ARRAY_FLATMAP ], // Array<Float>, [ ARRAY_REDUCE , REDUCER_AVG_MEAN ] // Float ] // Result<Float>","title":"Array.map(operator)"},{"location":"protocol/data-requests/radon/types/array/#arrayreducefunction","text":"reduce ( function : ( item : T ) => T )) : T [ ARRAY_REDUCE , function ] The reduce operator aggregates the items in the input Array<T> using a the supplied (input: T): O function and returns a single item of type T . The supplied (input: T): O function can be either a valid subscript over type T or one of the [predefined reducing functions][reducer]. This operator can throw a runtime exception under several circumstances, including: T in the input Array<T> is Mixed the reduction function is not mode and T in the input Array<T> is not Int or Float","title":"Array.reduce(function)"},{"location":"protocol/data-requests/radon/types/array/#arraysomefunction","text":"some ( function : ( item : T ) => Boolean ) : Boolean [ ARRAY_SOME , function ] The some operator returns True if the result of applying a function on at least one of the items in a given Array<T> is True . It returns False otherwise. The supplied (item: T): Boolean function can be either one of the predefined filtering functions or a valid subscript with input type T and output type Boolean .","title":"Array.some(function)"},{"location":"protocol/data-requests/radon/types/array/#arraysortmapfunction-ascending","text":"sort < V > ( mapFunction : ( item : T ) => V , ascending : Boolean = True ) : Array < T > [ ARRAY_SORT , mapFunction , ascending ] The sort operator returns a new Array<T> with the very same items from the input Array<T> but ordered according to the sorting criteria defined by the supplied mapFunction: (item: T) => V and ascending : Boolean arguments. The supplied mapFunction: (item: T) => V must be a valid subscript over type T , and its V output type must be one of the value types: Boolean , Int , Float or String . This function gives the sort operator the power to sort the items in the input Array<T> not by their values but by the values resulting from applying some computation on them. Example [ // Array<Map<String, Int>> [ ARRAY_SORT , [ // Map<String, Int> [ MAP_GET , \"age\" ] // Int ], False ] // Array<Map<String, Int>> ] // Result<Array<Map<String, Int>>> Remember The \"identity\" subscript (one that returns its own input without any transformation) is expressed in RADON as an empty Array : [ ARRAY_SORT , [] ] Incentive safety This operator may introduce adverse incentives if used in the aggregation or consensus stages.","title":"Array.sort(mapFunction, ascending)"},{"location":"protocol/data-requests/radon/types/array/#arraytakemin-max","text":"take ( min? : Int , max? : Int ) : Array < T > [ ARRAY_TAKE , min , max ] // Providing both a minimum and a maximum The take operator returns a new Array<T> with at least the min : Int first items in the input Array<T> and at most max : Int items. Take at least / Take at most / Take exactly This operator can be easily used to reproduce the \"take at least N items\" and \"take at most N items\" behaviors separately: [ ARRAY_TAKE , 5 ] // \"take at least 5 items\" [ ARRAY_TAKE , 0 , 10 ] // \"take at most 10 items\" Conversely, this will take exactly 7 item (or fail if there are not enough items): [ ARRAY_TAKE , 7 , 7 ] This operator can throw a runtime exception if the input Array<T> does not contain enough items to satisfy the minimum amount of items required by the supplied min : Int argument. Incentive safety This operator may introduce adverse incentives if used in the aggregation or consensus stages.","title":"Array.take(min, max)"},{"location":"protocol/data-requests/radon/types/boolean/","text":"Boolean type \u00b6 The Boolean data type can only take one of two possible values: true or false . Boolean.match(categories, default) \u00b6 match < V > ( categories : Map < Boolean , V > , default : V ) : V [ BOOLEAN_MATCH , [ /** `[key, value]` pairs **/ ] ] The match operator maps the input Boolean into different V values as defined in a Map<Boolean, V> by checking whether it matches against any of its Boolean keys. That is, it classifies the input Boolean value into separate compartments or buckets . If the input Boolean value is found as a key of categories : Map < Boolean , V > , it returns the V value associated to such key. It returns the default : V value otherwise. The V type must be one of the value types: Boolean , Int , Float or String . Example [ BOOLEAN_MATCH , [ [ True , \"Valid\" ], [ False , \"Invalid\" ] ] ] This operator will throw a runtime exception if no default value is provided and the input Boolean value is not found as a key of categories : Map < Boolean , V > . Exceptions are handled as specified in the [Exception handling] section. Boolean.neg() \u00b6 neg () : Boolean BOOLEAN_NEG The neg operator returns the negation of the input Boolean value. That is, it returns True as Boolean only if the input Boolean is False . It returns False as Boolean otherwise. Boolean.toString() \u00b6 toString () : String BOOLEAN_TOSTRING The toString operator returns a String representing the input Boolean value. That is, it returns True as String only if the input Boolean is True . It returns False as String otherwise.","title":"Boolean"},{"location":"protocol/data-requests/radon/types/boolean/#boolean-type","text":"The Boolean data type can only take one of two possible values: true or false .","title":"Boolean type"},{"location":"protocol/data-requests/radon/types/boolean/#booleanmatchcategories-default","text":"match < V > ( categories : Map < Boolean , V > , default : V ) : V [ BOOLEAN_MATCH , [ /** `[key, value]` pairs **/ ] ] The match operator maps the input Boolean into different V values as defined in a Map<Boolean, V> by checking whether it matches against any of its Boolean keys. That is, it classifies the input Boolean value into separate compartments or buckets . If the input Boolean value is found as a key of categories : Map < Boolean , V > , it returns the V value associated to such key. It returns the default : V value otherwise. The V type must be one of the value types: Boolean , Int , Float or String . Example [ BOOLEAN_MATCH , [ [ True , \"Valid\" ], [ False , \"Invalid\" ] ] ] This operator will throw a runtime exception if no default value is provided and the input Boolean value is not found as a key of categories : Map < Boolean , V > . Exceptions are handled as specified in the [Exception handling] section.","title":"Boolean.match(categories, default)"},{"location":"protocol/data-requests/radon/types/boolean/#booleanneg","text":"neg () : Boolean BOOLEAN_NEG The neg operator returns the negation of the input Boolean value. That is, it returns True as Boolean only if the input Boolean is False . It returns False as Boolean otherwise.","title":"Boolean.neg()"},{"location":"protocol/data-requests/radon/types/boolean/#booleantostring","text":"toString () : String BOOLEAN_TOSTRING The toString operator returns a String representing the input Boolean value. That is, it returns True as String only if the input Boolean is True . It returns False as String otherwise.","title":"Boolean.toString()"},{"location":"protocol/data-requests/radon/types/float/","text":"Float type \u00b6 Float.abs() \u00b6 abs () : Float FLOAT_ABS The abs operator returns the absolute value of the input Float number. That is, its distance from zero, without regard of its sign. Float.ceil() \u00b6 ceil () : Int FLOAT_CEIL The ceil operator returns the smallest Int number greater than or equal to the input Float number. Float.floor() \u00b6 floor () : Int FLOAT_FLOOR The floor operator returns the largest Int number less than or equal to the input Float number. Float.modulo(modulus) \u00b6 modulo ( modulus : Int ) : Float [ FLOAT_MODULO , modulus ] The modulo operator returns the remainder after the division of the input Float value by the modulus : Float value supplied as an argument. The resulting value always takes the same sign as the input Float value. Float.mult(factor) \u00b6 mult ( factor : Float ) : Float [ FLOAT_MULT , factor ] The mult operator returns the multiplication of the input Float value and the factor : Float value supplied as an argument. Where is the division operator? Division is not an elementary operator in RADON. It is instead achieved by composing the reciprocal ( recip ) and multiplication ( mult ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section. Float.neg() \u00b6 neg () : Float FLOAT_NEG The neg operator returns the additive inverse, opposite, sign change or negation of the input Float number. That is, the number that, when added to the input number, yields zero. Float.pow(exponent) \u00b6 pow ( exponent : Float ) : Float [ FLOAT_POW , exponent ] The pow operator returns the value of the input Float as base, exponentiated to the exponent : Float power. Where is the nth -root operator? The nth -root is not an elementary operator in RADON. It is instead achieved by composing the reciprocal ( recip ) and nth -power ( pow ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section. Float.recip() \u00b6 recip () : Float FLOAT_RECIP The recip operator returns the multiplicative inverse or reciprocal of the input Float number. That is, the number which multiplied by the input number, yields 1. This operator will throw a runtime exception if the input Float is 0 , given that the reciprocal would be infinity, which is way beyond the bounds of a Float number. Exceptions are handled as specified in the [Exception handling] section. Float.round() \u00b6 round () : Int FLOAT_ROUND The round operator returns the value of the input Float number as an Int by rounding to the nearest integer. Float.sum(addend) \u00b6 sum ( addend : Float ) : Float [ FLOAT_SUM , addend ] The sum operator returns the sum of the input Float value and the addend : Float value supplied as an argument. Where is the difference operator? Difference is not an elementary operator in RADON. It is instead achieved by composing the negation ( neg ) and summation ( sum ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section. Float.toString() \u00b6 toString ( decimals : Int ) : String [ FLOAT_TOSTRING , decimals ] The toString operator returns a String representing the input Float value using the provided base and the minimum number of fractional digits possible. The accepted bases are the same as in [ String::toInt(base) ][StringToInt]. If no base is specified, the default base will be 10 (decimal). Float.trunc() \u00b6 trunc () : Int FLOAT_TRUNC The trunc operator returns the integer part of the input Float number as an Int by removing any fractional digits.","title":"Float"},{"location":"protocol/data-requests/radon/types/float/#float-type","text":"","title":"Float type"},{"location":"protocol/data-requests/radon/types/float/#floatabs","text":"abs () : Float FLOAT_ABS The abs operator returns the absolute value of the input Float number. That is, its distance from zero, without regard of its sign.","title":"Float.abs()"},{"location":"protocol/data-requests/radon/types/float/#floatceil","text":"ceil () : Int FLOAT_CEIL The ceil operator returns the smallest Int number greater than or equal to the input Float number.","title":"Float.ceil()"},{"location":"protocol/data-requests/radon/types/float/#floatfloor","text":"floor () : Int FLOAT_FLOOR The floor operator returns the largest Int number less than or equal to the input Float number.","title":"Float.floor()"},{"location":"protocol/data-requests/radon/types/float/#floatmodulomodulus","text":"modulo ( modulus : Int ) : Float [ FLOAT_MODULO , modulus ] The modulo operator returns the remainder after the division of the input Float value by the modulus : Float value supplied as an argument. The resulting value always takes the same sign as the input Float value.","title":"Float.modulo(modulus)"},{"location":"protocol/data-requests/radon/types/float/#floatmultfactor","text":"mult ( factor : Float ) : Float [ FLOAT_MULT , factor ] The mult operator returns the multiplication of the input Float value and the factor : Float value supplied as an argument. Where is the division operator? Division is not an elementary operator in RADON. It is instead achieved by composing the reciprocal ( recip ) and multiplication ( mult ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section.","title":"Float.mult(factor)"},{"location":"protocol/data-requests/radon/types/float/#floatneg","text":"neg () : Float FLOAT_NEG The neg operator returns the additive inverse, opposite, sign change or negation of the input Float number. That is, the number that, when added to the input number, yields zero.","title":"Float.neg()"},{"location":"protocol/data-requests/radon/types/float/#floatpowexponent","text":"pow ( exponent : Float ) : Float [ FLOAT_POW , exponent ] The pow operator returns the value of the input Float as base, exponentiated to the exponent : Float power. Where is the nth -root operator? The nth -root is not an elementary operator in RADON. It is instead achieved by composing the reciprocal ( recip ) and nth -power ( pow ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section.","title":"Float.pow(exponent)"},{"location":"protocol/data-requests/radon/types/float/#floatrecip","text":"recip () : Float FLOAT_RECIP The recip operator returns the multiplicative inverse or reciprocal of the input Float number. That is, the number which multiplied by the input number, yields 1. This operator will throw a runtime exception if the input Float is 0 , given that the reciprocal would be infinity, which is way beyond the bounds of a Float number. Exceptions are handled as specified in the [Exception handling] section.","title":"Float.recip()"},{"location":"protocol/data-requests/radon/types/float/#floatround","text":"round () : Int FLOAT_ROUND The round operator returns the value of the input Float number as an Int by rounding to the nearest integer.","title":"Float.round()"},{"location":"protocol/data-requests/radon/types/float/#floatsumaddend","text":"sum ( addend : Float ) : Float [ FLOAT_SUM , addend ] The sum operator returns the sum of the input Float value and the addend : Float value supplied as an argument. Where is the difference operator? Difference is not an elementary operator in RADON. It is instead achieved by composing the negation ( neg ) and summation ( sum ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section.","title":"Float.sum(addend)"},{"location":"protocol/data-requests/radon/types/float/#floattostring","text":"toString ( decimals : Int ) : String [ FLOAT_TOSTRING , decimals ] The toString operator returns a String representing the input Float value using the provided base and the minimum number of fractional digits possible. The accepted bases are the same as in [ String::toInt(base) ][StringToInt]. If no base is specified, the default base will be 10 (decimal).","title":"Float.toString()"},{"location":"protocol/data-requests/radon/types/float/#floattrunc","text":"trunc () : Int FLOAT_TRUNC The trunc operator returns the integer part of the input Float number as an Int by removing any fractional digits.","title":"Float.trunc()"},{"location":"protocol/data-requests/radon/types/int/","text":"Int type \u00b6 Int.abs() \u00b6 abs () : Int INT_ABS The abs operator returns the absolute value of the input Int number. That is, its distance from zero, without regard of its sign. Int.match(categories, default) \u00b6 match < V > ( categories : Map < Int , V > , default ?: V ) : V [ INT_MATCH , [ /** `[key, value]` pairs **/ ] , default ] The match operator maps the input Int into different V values as defined in a Map<Int, V> by checking if it matches against any of its Int keys. That is, it classifies the input Int value into separate compartments or buckets . If the input Int value is found as a key of categories : Map < Int , V > , it returns the V value associated to such key. It returns the default : V value otherwise. Example [ INT_MATCH , [ [ 1 , \"One\" ], [ 2 , \"Two\" ], [ 3 , \"Three\" ] ], \"Other\" ] This operator will throw a runtime exception if no default value is provided and the input Int value is not found as a key of categories : Map < Int , V > . Exceptions are handled as specified in the [Exception handling] section. Int.modulo(modulus) \u00b6 modulo ( modulus : Int ) : Int [ INT_MODULO , modulus ] The modulo operator returns the remainder after the division of the input Int value by the modulus : Int value supplied as an argument. The resulting value always takes the same sign as the input Int value. Int.mult(factor) \u00b6 mult ( factor : Int ) : Int [ INT_MULT , factor ] The mult operator returns the multiplication of the input Int value and the factor : Int value supplied as an argument. Where is the division operator? Division is not an elementary operator in RADON. It is instead achieved by composing the reciprocal ( recip ) and multiplication ( mult ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Int type. Exceptions are handled as specified in the [Exception handling] section. Int.neg() \u00b6 neg () : Int INT_NEG The neg operator returns the additive inverse, opposite, sign change or negation of the input Int number. That is, the number that, when added to the input number, yields zero. Int.pow(exponent) \u00b6 pow ( exponent : Float ) : Float [ INT_POW , exponent ] The pow operator returns the value of the input Int as base, exponentiated to the exponent : Float power. Where is the nth -root operator? The nth -root is not an elementary operator in RADON. It is instead achieved by composing the reciprocal ( recip ) and nth -power ( pow ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section. Int.recip() \u00b6 recip () : Float INT_RECIP The recip operator returns the multiplicative inverse or reciprocal of the input Int number. That is, the number which multiplied by the input number, yields 1. This operator will throw a runtime exception if the input Int is 0 , given that the reciprocal would be infinity, which is way beyond the bounds of a Float number. Exceptions are handled as specified in the [Exception handling] section. Int.sum(addend) \u00b6 sum ( addend : Int ) : Int [ INT_SUM , addend ] The sum operator returns the sum of the input Int value and the addend : Int value supplied as an argument. Where is the difference operator? Difference is not an elementary operator in RADON. It is instead achieved by composing the negation ( neg ) and summation ( sum ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Int type. Exceptions are handled as specified in the [Exception handling] section. Int.toFloat() \u00b6 toFloat () : Float INT_TOFLOAT The toFloat operator returns the value of the input Int as a floating point number. Int.toString() \u00b6 toString ( base? : Int ) : String [ INT_TOSTRING , base ] The toString operator returns a String representing the input Int value using the provided base. The accepted bases are the same as in [ String::toInt(base) ][StringToInt]. If no base is specified, the default base will be 10 (decimal).","title":"Int"},{"location":"protocol/data-requests/radon/types/int/#int-type","text":"","title":"Int type"},{"location":"protocol/data-requests/radon/types/int/#intabs","text":"abs () : Int INT_ABS The abs operator returns the absolute value of the input Int number. That is, its distance from zero, without regard of its sign.","title":"Int.abs()"},{"location":"protocol/data-requests/radon/types/int/#intmatchcategories-default","text":"match < V > ( categories : Map < Int , V > , default ?: V ) : V [ INT_MATCH , [ /** `[key, value]` pairs **/ ] , default ] The match operator maps the input Int into different V values as defined in a Map<Int, V> by checking if it matches against any of its Int keys. That is, it classifies the input Int value into separate compartments or buckets . If the input Int value is found as a key of categories : Map < Int , V > , it returns the V value associated to such key. It returns the default : V value otherwise. Example [ INT_MATCH , [ [ 1 , \"One\" ], [ 2 , \"Two\" ], [ 3 , \"Three\" ] ], \"Other\" ] This operator will throw a runtime exception if no default value is provided and the input Int value is not found as a key of categories : Map < Int , V > . Exceptions are handled as specified in the [Exception handling] section.","title":"Int.match(categories, default)"},{"location":"protocol/data-requests/radon/types/int/#intmodulomodulus","text":"modulo ( modulus : Int ) : Int [ INT_MODULO , modulus ] The modulo operator returns the remainder after the division of the input Int value by the modulus : Int value supplied as an argument. The resulting value always takes the same sign as the input Int value.","title":"Int.modulo(modulus)"},{"location":"protocol/data-requests/radon/types/int/#intmultfactor","text":"mult ( factor : Int ) : Int [ INT_MULT , factor ] The mult operator returns the multiplication of the input Int value and the factor : Int value supplied as an argument. Where is the division operator? Division is not an elementary operator in RADON. It is instead achieved by composing the reciprocal ( recip ) and multiplication ( mult ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Int type. Exceptions are handled as specified in the [Exception handling] section.","title":"Int.mult(factor)"},{"location":"protocol/data-requests/radon/types/int/#intneg","text":"neg () : Int INT_NEG The neg operator returns the additive inverse, opposite, sign change or negation of the input Int number. That is, the number that, when added to the input number, yields zero.","title":"Int.neg()"},{"location":"protocol/data-requests/radon/types/int/#intpowexponent","text":"pow ( exponent : Float ) : Float [ INT_POW , exponent ] The pow operator returns the value of the input Int as base, exponentiated to the exponent : Float power. Where is the nth -root operator? The nth -root is not an elementary operator in RADON. It is instead achieved by composing the reciprocal ( recip ) and nth -power ( pow ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section.","title":"Int.pow(exponent)"},{"location":"protocol/data-requests/radon/types/int/#intrecip","text":"recip () : Float INT_RECIP The recip operator returns the multiplicative inverse or reciprocal of the input Int number. That is, the number which multiplied by the input number, yields 1. This operator will throw a runtime exception if the input Int is 0 , given that the reciprocal would be infinity, which is way beyond the bounds of a Float number. Exceptions are handled as specified in the [Exception handling] section.","title":"Int.recip()"},{"location":"protocol/data-requests/radon/types/int/#intsumaddend","text":"sum ( addend : Int ) : Int [ INT_SUM , addend ] The sum operator returns the sum of the input Int value and the addend : Int value supplied as an argument. Where is the difference operator? Difference is not an elementary operator in RADON. It is instead achieved by composing the negation ( neg ) and summation ( sum ) operators. This operator can throw a runtime exception if the resulting value overflows or underflows the range of the Int type. Exceptions are handled as specified in the [Exception handling] section.","title":"Int.sum(addend)"},{"location":"protocol/data-requests/radon/types/int/#inttofloat","text":"toFloat () : Float INT_TOFLOAT The toFloat operator returns the value of the input Int as a floating point number.","title":"Int.toFloat()"},{"location":"protocol/data-requests/radon/types/int/#inttostring","text":"toString ( base? : Int ) : String [ INT_TOSTRING , base ] The toString operator returns a String representing the input Int value using the provided base. The accepted bases are the same as in [ String::toInt(base) ][StringToInt]. If no base is specified, the default base will be 10 (decimal).","title":"Int.toString()"},{"location":"protocol/data-requests/radon/types/map/","text":"Map<K, T> type \u00b6 Map.entries() \u00b6 entries () : Array < Array < Mixed >> MAP_ENTRIES The entries operator returns an Array<Array<Mixed>> containing the keys and values from the input Map<K, T> as [ key, value ]: Array<Mixed> pairs. Map.get(key) \u00b6 get ( key : K ) : T [ MAP_GET , key ] The get operator returns the T value or structure associated to the key : K from a Map<K, T> . This operator can throw a runtime exception if the supplied key : K cannot be found in the input Map<K, T> . Exceptions are handled as specified in the [Exception handling] section. Map.keys() \u00b6 keys () : Array < K > MAP_KEYS The keys operator returns an Array<K> containing the keys of the input Map<K, T> . Map.values() \u00b6 values () : Array < T > MAP_VALUES The values operator returns an Array<T> containing the values of the input Map<K, T> .","title":"Map<V>"},{"location":"protocol/data-requests/radon/types/map/#mapk-t-type","text":"","title":"Map&lt;K, T&gt; type"},{"location":"protocol/data-requests/radon/types/map/#mapentries","text":"entries () : Array < Array < Mixed >> MAP_ENTRIES The entries operator returns an Array<Array<Mixed>> containing the keys and values from the input Map<K, T> as [ key, value ]: Array<Mixed> pairs.","title":"Map.entries()"},{"location":"protocol/data-requests/radon/types/map/#mapgetkey","text":"get ( key : K ) : T [ MAP_GET , key ] The get operator returns the T value or structure associated to the key : K from a Map<K, T> . This operator can throw a runtime exception if the supplied key : K cannot be found in the input Map<K, T> . Exceptions are handled as specified in the [Exception handling] section.","title":"Map.get(key)"},{"location":"protocol/data-requests/radon/types/map/#mapkeys","text":"keys () : Array < K > MAP_KEYS The keys operator returns an Array<K> containing the keys of the input Map<K, T> .","title":"Map.keys()"},{"location":"protocol/data-requests/radon/types/map/#mapvalues","text":"values () : Array < T > MAP_VALUES The values operator returns an Array<T> containing the values of the input Map<K, T> .","title":"Map.values()"},{"location":"protocol/data-requests/radon/types/mixed/","text":"Mixed type \u00b6 The Mixed type represents a value or structure whose type is undecided and cannot be automatically inferred by the interpreter. The operators available for this type assist the interpreter to handle Mixed values and structures in a deterministic way so that it can be safely casted to other, more useful types. Mixed.toArray(type) \u00b6 toArray < T > ( type? : String ) : Array < T > [ MIXED_TOARRAY , type ] The toArray operator tries to cast the input Mixed to an Array<T> structure, where T is any of the RADON types, supplied by name as the type : String argument. If no type : String is supplied, the output type will be Array<Mixed> by default. This operator will throw a runtime exception if the input Mixed cannot be casted to a valid Boolean value. Exceptions are handled as specified in the [Exception handling] section. Mixed.toBoolean() \u00b6 toBoolean () : Boolean MIXED_TOBOOLEAN The toBoolean operator tries to cast the input Mixed to a Boolean value. That is, it returns True if the input is True as either Boolean or String ; or False as Boolean if the input Mixed is False as either Boolean or String . This operator will throw a runtime exception if the input Mixed cannot be casted to a valid Boolean value. Exceptions are handled as specified in the [Exception handling] section. Mixed.toFloat() \u00b6 toFloat () : Float MIXED_TOFLOAT The toFloat operator tries to cast the input Mixed to a Float value. This operator will throw a runtime exception if the input Mixed cannot be casted to a valid Float value for the specified base or if the value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section. Mixed.toInt() \u00b6 toInt ( base? : Int ) : Int [ MIXED_TOINT , base ] The toInt operator parses the input Mixed as an integer of the specified base. The accepted bases are the same as in [ String::toInt(base) ][StringToInt]. If no base is specified, the default base will be 10 (decimal). This operator will throw a runtime exception if: The input Mixed cannot be casted to a valid Int value for the specified base The value overflows or underflows the range of the Int type. Exceptions are handled as specified in the [Exception handling] section. Mixed.toMap(keyType, valueType) \u00b6 toMap < K , T > ( keyType? : String , valueType? : String ) : Map < K , T > [ MIXED_TOMAP , keyType , valueType ] The toArray operator tries to cast the input Mixed to a Map<K, T> structure, where K is only one of the RADON [value types] , supplied by name as the keyType : String argument; and T is any of the RADON types, supplied by name as the valueType : String argument. If no keyType : String is supplied, it will be assumed to be String by default. If no valueType : String is supplied, it will be assumed to be Mixed by default. This operator will throw a runtime exception if the input Mixed cannot be casted to a valid Map<K, T> value. Exceptions are handled as specified in the [Exception handling] section.","title":"Mixed"},{"location":"protocol/data-requests/radon/types/mixed/#mixed-type","text":"The Mixed type represents a value or structure whose type is undecided and cannot be automatically inferred by the interpreter. The operators available for this type assist the interpreter to handle Mixed values and structures in a deterministic way so that it can be safely casted to other, more useful types.","title":"Mixed type"},{"location":"protocol/data-requests/radon/types/mixed/#mixedtoarraytype","text":"toArray < T > ( type? : String ) : Array < T > [ MIXED_TOARRAY , type ] The toArray operator tries to cast the input Mixed to an Array<T> structure, where T is any of the RADON types, supplied by name as the type : String argument. If no type : String is supplied, the output type will be Array<Mixed> by default. This operator will throw a runtime exception if the input Mixed cannot be casted to a valid Boolean value. Exceptions are handled as specified in the [Exception handling] section.","title":"Mixed.toArray(type)"},{"location":"protocol/data-requests/radon/types/mixed/#mixedtoboolean","text":"toBoolean () : Boolean MIXED_TOBOOLEAN The toBoolean operator tries to cast the input Mixed to a Boolean value. That is, it returns True if the input is True as either Boolean or String ; or False as Boolean if the input Mixed is False as either Boolean or String . This operator will throw a runtime exception if the input Mixed cannot be casted to a valid Boolean value. Exceptions are handled as specified in the [Exception handling] section.","title":"Mixed.toBoolean()"},{"location":"protocol/data-requests/radon/types/mixed/#mixedtofloat","text":"toFloat () : Float MIXED_TOFLOAT The toFloat operator tries to cast the input Mixed to a Float value. This operator will throw a runtime exception if the input Mixed cannot be casted to a valid Float value for the specified base or if the value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section.","title":"Mixed.toFloat()"},{"location":"protocol/data-requests/radon/types/mixed/#mixedtoint","text":"toInt ( base? : Int ) : Int [ MIXED_TOINT , base ] The toInt operator parses the input Mixed as an integer of the specified base. The accepted bases are the same as in [ String::toInt(base) ][StringToInt]. If no base is specified, the default base will be 10 (decimal). This operator will throw a runtime exception if: The input Mixed cannot be casted to a valid Int value for the specified base The value overflows or underflows the range of the Int type. Exceptions are handled as specified in the [Exception handling] section.","title":"Mixed.toInt()"},{"location":"protocol/data-requests/radon/types/mixed/#mixedtomapkeytype-valuetype","text":"toMap < K , T > ( keyType? : String , valueType? : String ) : Map < K , T > [ MIXED_TOMAP , keyType , valueType ] The toArray operator tries to cast the input Mixed to a Map<K, T> structure, where K is only one of the RADON [value types] , supplied by name as the keyType : String argument; and T is any of the RADON types, supplied by name as the valueType : String argument. If no keyType : String is supplied, it will be assumed to be String by default. If no valueType : String is supplied, it will be assumed to be Mixed by default. This operator will throw a runtime exception if the input Mixed cannot be casted to a valid Map<K, T> value. Exceptions are handled as specified in the [Exception handling] section.","title":"Mixed.toMap(keyType, valueType)"},{"location":"protocol/data-requests/radon/types/null/","text":"Null type \u00b6 Null has no operators.","title":"Null"},{"location":"protocol/data-requests/radon/types/null/#null-type","text":"Null has no operators.","title":"Null type"},{"location":"protocol/data-requests/radon/types/overview/","text":"RADON data types \u00b6 The basic data types (also called value types ) existing in RADON are modelled to resemble those of most typed programming languages: Boolean Int Float String Additionaly, there exist six complex data types or structure types : Array<T> Map<K, T> Mixed Null Result<T> Each of these nine types and their available operators are explained below. Reading data types documentation Operators for each of the data types in this documentation are specified as: // TypeScript-alike function signature nameOfTheMethod ( argument : TypeOfArgument ) : ReturnTypeOfMethod // Actual usage in RADON TYPE_OPERATORNAME // Operators without arguments [ TYPE_OPERATORNAME , argument ] // Operators with arguments Constants All across this documentation, unquoted uppercase names like STRING_PARSEJSON identify different operators and constants that equate to a single byte when encoded. A list of constants can be found in the Contants section .","title":"Overview"},{"location":"protocol/data-requests/radon/types/overview/#radon-data-types","text":"The basic data types (also called value types ) existing in RADON are modelled to resemble those of most typed programming languages: Boolean Int Float String Additionaly, there exist six complex data types or structure types : Array<T> Map<K, T> Mixed Null Result<T> Each of these nine types and their available operators are explained below. Reading data types documentation Operators for each of the data types in this documentation are specified as: // TypeScript-alike function signature nameOfTheMethod ( argument : TypeOfArgument ) : ReturnTypeOfMethod // Actual usage in RADON TYPE_OPERATORNAME // Operators without arguments [ TYPE_OPERATORNAME , argument ] // Operators with arguments Constants All across this documentation, unquoted uppercase names like STRING_PARSEJSON identify different operators and constants that equate to a single byte when encoded. A list of constants can be found in the Contants section .","title":"RADON data types"},{"location":"protocol/data-requests/radon/types/result/","text":"Result<T> type \u00b6 Result<T> is one of the RADON complex data types. It can be thought as an Array<T> that can only contain zero or one item of type T . In that sense, it is somehow similar to the Option<T> type found in other programming languages. Result.get() \u00b6 get < T > () : T RESULT_GET The get operator unwraps the input Result<T> . That is, it returns its contained value assuming the Result<T> is positive ( Ok<T> ). This operator can throw a runtime exception if the input Result<T> is not positive ( Ok<T> ) but negative ( Err ). Exceptions are handled as specified in the [Exception handling] section. Result.getOr() \u00b6 getOr < T > ( default : T ) : T RESULT_GETOR The getOr operator returns the T value enclosed in the input Result<T> if it is positive ( Ok<T> ). It returns the supplied default : T value otherwise. Result.isOk() \u00b6 isOk () : Boolean RESULT_ISOK The isOk operator returns True as Boolean if the input Result<T> is positive ( Ok<T> ). It returns False as Boolean otherwise. Checking if a Result is negative ( Err ) is not an elementary operator in RADON. It is instead achieved by composing the isOk and negation ( neg ) operators.","title":"Result<V>"},{"location":"protocol/data-requests/radon/types/result/#resultt-type","text":"Result<T> is one of the RADON complex data types. It can be thought as an Array<T> that can only contain zero or one item of type T . In that sense, it is somehow similar to the Option<T> type found in other programming languages.","title":"Result&lt;T&gt; type"},{"location":"protocol/data-requests/radon/types/result/#resultget","text":"get < T > () : T RESULT_GET The get operator unwraps the input Result<T> . That is, it returns its contained value assuming the Result<T> is positive ( Ok<T> ). This operator can throw a runtime exception if the input Result<T> is not positive ( Ok<T> ) but negative ( Err ). Exceptions are handled as specified in the [Exception handling] section.","title":"Result.get()"},{"location":"protocol/data-requests/radon/types/result/#resultgetor","text":"getOr < T > ( default : T ) : T RESULT_GETOR The getOr operator returns the T value enclosed in the input Result<T> if it is positive ( Ok<T> ). It returns the supplied default : T value otherwise.","title":"Result.getOr()"},{"location":"protocol/data-requests/radon/types/result/#resultisok","text":"isOk () : Boolean RESULT_ISOK The isOk operator returns True as Boolean if the input Result<T> is positive ( Ok<T> ). It returns False as Boolean otherwise. Checking if a Result is negative ( Err ) is not an elementary operator in RADON. It is instead achieved by composing the isOk and negation ( neg ) operators.","title":"Result.isOk()"},{"location":"protocol/data-requests/radon/types/string/","text":"String type \u00b6 String.hash(function) \u00b6 hash ( function : String ) : String [ STRING_HASH , function ] Applies a hash function on the input String and returns its digest as an hexadecimal string. The available hash functions are listed in the Predefined functions section . String.length() \u00b6 length () : Int STRING_LENGTH The length operator returns the number of UTF-8 code units in the input String . String.match(categories, default) \u00b6 match < T > ( categories : Map < String , T > , default ?: T ) : T [ STRING_CATEGORIZE , [ /** `[key, value]` pairs **/ ], default ] The match operator maps the input String into different T values as defined in a Map<String, T> by checking if it matches against any of its String keys. That is, it classifies the input String value into separate compartments or buckets . If the input String value is found as a key of categories : Map < String , T > , it returns the T value associated to such key. It returns the default : T value otherwise. Example [ STRING_CATEGORIZE , [ [ \"rainy\" , 0 ], [ \"stormy\" , 0 ], [ \"sunny\" , 1 ] ], 2 ] This operator will throw a runtime exception if no default value is provided and the input String value is not found as a key of categories : Map < String , T > . Exceptions are handled as specified in the [Exception handling] section. String.parseJSON() \u00b6 parseJSON () : Mixed STRING_PARSEJSON Parses the input String into a Map<String, Mixed> assuming it is a correctly formed JSON document. This operator can throw a runtime exception if: The input String is not a well-formed JSON document. The type of some value in the document cannot be inferred. Exceptions are handled as specified in the [Exception handling] section. String.parseXML() \u00b6 parseXML () : Map < String , Mixed > STRING_PARSEXML Parses the input String into a Map<String, Mixed> assuming it is a correctly formed XML document. This operator can throw a runtime exception if: The input String is not a well-formed XML document. The type of some value in the document cannot be inferred. Exceptions are handled as specified in the [Exception handling] section. String.toBoolean() \u00b6 toBoolean () : Boolean STRING_TOBOOLEAN The toBoolean operator parses the input String as a Boolean value. That is, it returns True as Boolean if the input String is True ; or False as Boolean if the input String is False . This operator will throw a runtime exception if the input String is not a valid Boolean value. Exceptions are handled as specified in the [Exception handling] section. String.toFloat() \u00b6 toFloat () : Float STRING_TOFLOAT The toFloat operator parses the input String as a floating point number. This operator will throw a runtime exception if: The input String is not a valid Float value for the specified base. The value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section. String.toInt() \u00b6 toInt ( base? : Int ) : Int [ STRING_TOINT , base ] The toInt operator parses the input String as an integer of the specified base. The accepted bases are: Base Name Example 2 Binary 1011111011101111 8 Octal 137357 10 Decimal 48879 16 Hexadecimal BEEF 32 Base32 X3XQ 64 Base64 vu8 If no base is specified, the default base will be 10 (decimal). This operator will throw a runtime exception if: The input String is not a valid Int value for the specified base. The value overflows or underflows the range of the Int type. Exceptions are handled as specified in the [Exception handling] section. String.toLowerCase() \u00b6 toLowerCase () : String STRING_TOLOWERCASE Returns the input String value converted to uppercase. String.toUpperCase() \u00b6 toUpperCase () : String STRING_TOUPPERCASE Returns the input String value converted to lowercase.","title":"String"},{"location":"protocol/data-requests/radon/types/string/#string-type","text":"","title":"String type"},{"location":"protocol/data-requests/radon/types/string/#stringhashfunction","text":"hash ( function : String ) : String [ STRING_HASH , function ] Applies a hash function on the input String and returns its digest as an hexadecimal string. The available hash functions are listed in the Predefined functions section .","title":"String.hash(function)"},{"location":"protocol/data-requests/radon/types/string/#stringlength","text":"length () : Int STRING_LENGTH The length operator returns the number of UTF-8 code units in the input String .","title":"String.length()"},{"location":"protocol/data-requests/radon/types/string/#stringmatchcategories-default","text":"match < T > ( categories : Map < String , T > , default ?: T ) : T [ STRING_CATEGORIZE , [ /** `[key, value]` pairs **/ ], default ] The match operator maps the input String into different T values as defined in a Map<String, T> by checking if it matches against any of its String keys. That is, it classifies the input String value into separate compartments or buckets . If the input String value is found as a key of categories : Map < String , T > , it returns the T value associated to such key. It returns the default : T value otherwise. Example [ STRING_CATEGORIZE , [ [ \"rainy\" , 0 ], [ \"stormy\" , 0 ], [ \"sunny\" , 1 ] ], 2 ] This operator will throw a runtime exception if no default value is provided and the input String value is not found as a key of categories : Map < String , T > . Exceptions are handled as specified in the [Exception handling] section.","title":"String.match(categories, default)"},{"location":"protocol/data-requests/radon/types/string/#stringparsejson","text":"parseJSON () : Mixed STRING_PARSEJSON Parses the input String into a Map<String, Mixed> assuming it is a correctly formed JSON document. This operator can throw a runtime exception if: The input String is not a well-formed JSON document. The type of some value in the document cannot be inferred. Exceptions are handled as specified in the [Exception handling] section.","title":"String.parseJSON()"},{"location":"protocol/data-requests/radon/types/string/#stringparsexml","text":"parseXML () : Map < String , Mixed > STRING_PARSEXML Parses the input String into a Map<String, Mixed> assuming it is a correctly formed XML document. This operator can throw a runtime exception if: The input String is not a well-formed XML document. The type of some value in the document cannot be inferred. Exceptions are handled as specified in the [Exception handling] section.","title":"String.parseXML()"},{"location":"protocol/data-requests/radon/types/string/#stringtoboolean","text":"toBoolean () : Boolean STRING_TOBOOLEAN The toBoolean operator parses the input String as a Boolean value. That is, it returns True as Boolean if the input String is True ; or False as Boolean if the input String is False . This operator will throw a runtime exception if the input String is not a valid Boolean value. Exceptions are handled as specified in the [Exception handling] section.","title":"String.toBoolean()"},{"location":"protocol/data-requests/radon/types/string/#stringtofloat","text":"toFloat () : Float STRING_TOFLOAT The toFloat operator parses the input String as a floating point number. This operator will throw a runtime exception if: The input String is not a valid Float value for the specified base. The value overflows or underflows the range of the Float type. Exceptions are handled as specified in the [Exception handling] section.","title":"String.toFloat()"},{"location":"protocol/data-requests/radon/types/string/#stringtoint","text":"toInt ( base? : Int ) : Int [ STRING_TOINT , base ] The toInt operator parses the input String as an integer of the specified base. The accepted bases are: Base Name Example 2 Binary 1011111011101111 8 Octal 137357 10 Decimal 48879 16 Hexadecimal BEEF 32 Base32 X3XQ 64 Base64 vu8 If no base is specified, the default base will be 10 (decimal). This operator will throw a runtime exception if: The input String is not a valid Int value for the specified base. The value overflows or underflows the range of the Int type. Exceptions are handled as specified in the [Exception handling] section.","title":"String.toInt()"},{"location":"protocol/data-requests/radon/types/string/#stringtolowercase","text":"toLowerCase () : String STRING_TOLOWERCASE Returns the input String value converted to uppercase.","title":"String.toLowerCase()"},{"location":"protocol/data-requests/radon/types/string/#stringtouppercase","text":"toUpperCase () : String STRING_TOUPPERCASE Returns the input String value converted to lowercase.","title":"String.toUpperCase()"},{"location":"protocol/network/constants/","text":"Constants \u00b6 Constant values are immutable within Witnet protocol versions. A change in the constants necessarily requires a new protocol version. Witnet versions \u00b6 Witnet network protocol versions, defined as u32 , are listed below: Version Initial Release Major Changes 010 To be determined Magic numbers \u00b6 These constant values indicate the originating network in the message headers: Magic number Network 0x00 mainnet 0xF1 testnet-1 Node capabilities \u00b6 Node capabilities are defined as 64 bits sequences of masked flags, so that nodes may advertise which subset of services they are supporting. Currently, only one node capability is specified in the Witnet network protocol. Flag Name Description 0x0000000000000001 NODE_NETWORK Witnet full node which is the default operation mode User agents \u00b6 List of known user agents. Currently, only 1 user agent is being implemented: User Agent Description /Witnet-rust:0.1.0 Witnet node implemented in Rust and version 0.1.0","title":"Constants"},{"location":"protocol/network/constants/#constants","text":"Constant values are immutable within Witnet protocol versions. A change in the constants necessarily requires a new protocol version.","title":"Constants"},{"location":"protocol/network/constants/#witnet-versions","text":"Witnet network protocol versions, defined as u32 , are listed below: Version Initial Release Major Changes 010 To be determined","title":"Witnet versions"},{"location":"protocol/network/constants/#magic-numbers","text":"These constant values indicate the originating network in the message headers: Magic number Network 0x00 mainnet 0xF1 testnet-1","title":"Magic numbers"},{"location":"protocol/network/constants/#node-capabilities","text":"Node capabilities are defined as 64 bits sequences of masked flags, so that nodes may advertise which subset of services they are supporting. Currently, only one node capability is specified in the Witnet network protocol. Flag Name Description 0x0000000000000001 NODE_NETWORK Witnet full node which is the default operation mode","title":"Node capabilities"},{"location":"protocol/network/constants/#user-agents","text":"List of known user agents. Currently, only 1 user agent is being implemented: User Agent Description /Witnet-rust:0.1.0 Witnet node implemented in Rust and version 0.1.0","title":"User agents"},{"location":"protocol/network/overview/","text":"Witnet Network Protocol \u00b6 Witnet network protocol is inspired by other blockchain network protocols such as Bitcoin, Ethereum, Exonum, Mimblewimble Grin and Rchain. Some of the aforementioned blockchains architecture have been taken into consideration as their reference implementations are also coded in Rust. The Witnet network protocol can be deconstructed into different message protocols: Handshake: negotiation between peers to establish valid Witnet protocol sessions Peer discovery: exchange lists of known peers Heartbeat: exchange beacons indicating that the session is active Inventory exchange: synchronization of objects (blocks, transactions, etc.) between peers Additionally, for the aforementioned protocols, some constants and specific data structures have been specified, such as: Block IP Address Transaction References \u00b6 Bitcoin: Developer Reference - Bitcoin Wiki GitHub - bitcoin/bitcoin: Bitcoin Core integration/staging tree GitHub - paritytech/parity-bitcoin: The Parity Bitcoin client Ethereum: Wiki \u00b7 GitHub GitHub - ethereum/go-ethereum: Official Go implementation of the Ethereum protocol GitHub - paritytech/parity-ethereum: The fast, light, and robust EVM and WASM client. Exonum: Exonum Documentation GitHub - exonum/exonum: An extensible open-source framework for creating private/permissioned blockchain applications Mimblewimble Grin: Grin, the Tech | Simple, privacy-focused, scalable MimbleWimble chain implementation. Wiki \u00b7 GitHub GitHub - mimblewimble/grin: Minimal implementation of the MimbleWimble protocol. RChain: Documentation GitHub - rchain/rchain","title":"Overview"},{"location":"protocol/network/overview/#witnet-network-protocol","text":"Witnet network protocol is inspired by other blockchain network protocols such as Bitcoin, Ethereum, Exonum, Mimblewimble Grin and Rchain. Some of the aforementioned blockchains architecture have been taken into consideration as their reference implementations are also coded in Rust. The Witnet network protocol can be deconstructed into different message protocols: Handshake: negotiation between peers to establish valid Witnet protocol sessions Peer discovery: exchange lists of known peers Heartbeat: exchange beacons indicating that the session is active Inventory exchange: synchronization of objects (blocks, transactions, etc.) between peers Additionally, for the aforementioned protocols, some constants and specific data structures have been specified, such as: Block IP Address Transaction","title":"Witnet Network Protocol"},{"location":"protocol/network/overview/#references","text":"Bitcoin: Developer Reference - Bitcoin Wiki GitHub - bitcoin/bitcoin: Bitcoin Core integration/staging tree GitHub - paritytech/parity-bitcoin: The Parity Bitcoin client Ethereum: Wiki \u00b7 GitHub GitHub - ethereum/go-ethereum: Official Go implementation of the Ethereum protocol GitHub - paritytech/parity-ethereum: The fast, light, and robust EVM and WASM client. Exonum: Exonum Documentation GitHub - exonum/exonum: An extensible open-source framework for creating private/permissioned blockchain applications Mimblewimble Grin: Grin, the Tech | Simple, privacy-focused, scalable MimbleWimble chain implementation. Wiki \u00b7 GitHub GitHub - mimblewimble/grin: Minimal implementation of the MimbleWimble protocol. RChain: Documentation GitHub - rchain/rchain","title":"References"},{"location":"protocol/network/data-structures/block/","text":"Block \u00b6 In the Witnet network protocol, a Block is formatted as follows: Field Type Description block_header BlockHeader The header of the block proof LeadershipProof A miner-provided Proof of Eligibility txns repeated Transaction A keyed signature of the block header A non-empty list of transactions is always provided because the mint transaction should always be included. Block header structure \u00b6 The block header ( BlockHeader ) is composed of the following fields: Field Type Description version uint32 The block version number indicating the block validation rules beacon CheckpointBeacon A checkpoint beacon for the epoch that this block is closing hash_merkle_root Hash A 256-bit hash based on all of the transactions committed to this block Checkpoint beacon structure \u00b6 The checkpoint beacon ( CheckpointBeacon ) is composed of the following fields: Field Type Description checkpoint fixed32 The serial number for this epoch hash_prev_block Hash The 256-bit hash of the previous block Proof of Eligibility \u00b6 The Proof of Eligibility ( LeadershipProof ) signature is computed by simply signing the beacon field of the block header using the same private key as for the signature . Signature structures are defined in the Signature section.","title":"Block"},{"location":"protocol/network/data-structures/block/#block","text":"In the Witnet network protocol, a Block is formatted as follows: Field Type Description block_header BlockHeader The header of the block proof LeadershipProof A miner-provided Proof of Eligibility txns repeated Transaction A keyed signature of the block header A non-empty list of transactions is always provided because the mint transaction should always be included.","title":"Block"},{"location":"protocol/network/data-structures/block/#block-header-structure","text":"The block header ( BlockHeader ) is composed of the following fields: Field Type Description version uint32 The block version number indicating the block validation rules beacon CheckpointBeacon A checkpoint beacon for the epoch that this block is closing hash_merkle_root Hash A 256-bit hash based on all of the transactions committed to this block","title":"Block header structure"},{"location":"protocol/network/data-structures/block/#checkpoint-beacon-structure","text":"The checkpoint beacon ( CheckpointBeacon ) is composed of the following fields: Field Type Description checkpoint fixed32 The serial number for this epoch hash_prev_block Hash The 256-bit hash of the previous block","title":"Checkpoint beacon structure"},{"location":"protocol/network/data-structures/block/#proof-of-eligibility","text":"The Proof of Eligibility ( LeadershipProof ) signature is computed by simply signing the beacon field of the block header using the same private key as for the signature . Signature structures are defined in the Signature section.","title":"Proof of Eligibility"},{"location":"protocol/network/data-structures/ip-address/","text":"IP Address \u00b6 IP addresses in Witnet protocol may be IPv4 or IPv6 and they are encoded as bytes, as a concatenation of ip and port. The kind is inferred based on the length: 6 bytes for IPv4 and 18 bytes for IPv6. The fields are encoded using Big-Endian representation. ( || denotes concatenation) [u8; 6] => (Ipv4) ip || port [u8; 18] => (Ipv6) ip0 || ip1 || ip2 || ip3 || port","title":"IP Address"},{"location":"protocol/network/data-structures/ip-address/#ip-address","text":"IP addresses in Witnet protocol may be IPv4 or IPv6 and they are encoded as bytes, as a concatenation of ip and port. The kind is inferred based on the length: 6 bytes for IPv4 and 18 bytes for IPv6. The fields are encoded using Big-Endian representation. ( || denotes concatenation) [u8; 6] => (Ipv4) ip || port [u8; 18] => (Ipv6) ip0 || ip1 || ip2 || ip3 || port","title":"IP Address"},{"location":"protocol/network/data-structures/signature/","text":"Signature \u00b6 Signatures are a tagged union of the supported cryptosystems: Kind Description Secp256k1Signature ECDSA over secp256k1 Keyed signatures augment the previous format by adding a field for the public key that was used for producing the signature: Field Type Description signature Signature A variable-length digital signature public_key bytes The public key matching the private key used for producing the signature Cryptosystems \u00b6 Currently supported cryptosystems within the Witnet network protocol: Cryptosystem Signature size Public key size None 0 bytes 0 bytes ECDSA over secp256k1 65 bytes 33 bytes Secp256k1Signature \u00b6 ECDSA signatures over the secp256k1 curve consist of: Field Type Description r bytes The signature value R (32 bytes) s bytes The signature value S (33 bytes) ECDSA public keys must always use compression and thus their length is 33 bytes.","title":"Signature"},{"location":"protocol/network/data-structures/signature/#signature","text":"Signatures are a tagged union of the supported cryptosystems: Kind Description Secp256k1Signature ECDSA over secp256k1 Keyed signatures augment the previous format by adding a field for the public key that was used for producing the signature: Field Type Description signature Signature A variable-length digital signature public_key bytes The public key matching the private key used for producing the signature","title":"Signature"},{"location":"protocol/network/data-structures/signature/#cryptosystems","text":"Currently supported cryptosystems within the Witnet network protocol: Cryptosystem Signature size Public key size None 0 bytes 0 bytes ECDSA over secp256k1 65 bytes 33 bytes","title":"Cryptosystems"},{"location":"protocol/network/data-structures/signature/#secp256k1signature","text":"ECDSA signatures over the secp256k1 curve consist of: Field Type Description r bytes The signature value R (32 bytes) s bytes The signature value S (33 bytes) ECDSA public keys must always use compression and thus their length is 33 bytes.","title":"Secp256k1Signature"},{"location":"protocol/network/data-structures/transaction/","text":"Transaction \u00b6 In the Witnet network protocol, a transaction is formatted as follows: Field Type Description version uint32 The transaction data format version number inputs repeated Input A list of transaction inputs outputs repeated Output A list of 1 or more transaction outputs signatures repeated KeyedSignature A list of keyed signatures (as many as inputs) Long story short, inputs contain data that proves ability to \"pull\" value from past transactions into a new transaction, while outputs redistribute such value and lock them under new spending conditions. Signatures ensure integrity of the transaction and complement input's function when it comes to prove ability to unlock funds from past transactions. Generally, the sum of the values of the outputs in a transaction must not exceed the sum of the values of the inputs, so as to guarantee that value is not created out of thin air. The only exception to this rule is the mint transaction, which every block's miner node must include at the beginning of the transactions list contained in it. Mint transactions, which are roughly equivalent to Bitcoin's coinbase , have no inputs and only one output, thus effectively minting a fixed amount of new value. As it is the case for many other unspent output based cryptocurrencies, for every transaction, any value surplus after detracting the total output value from the total input value is considered to be the miner fee , which can be redeemed by the miner of the block in which the transaction gets anchored. Outputs \u00b6 Outputs gather the value brought into transactions by inputs and lock fractions of that value under new spending conditions. Transactions may contain different types of outputs: Value transfer: roughly equivalent to Bitcoin's P2PKH/P2WPKH, where the output specifies the hash of a public key. Client Data Request (DR): publishes a request for data. It must include scripts for retrieval, aggregation, consensus and, optionally, deliver clauses. Commit: used by witnesses to (1) commit the results of their retrieval tasks without revealing the actual value of the retrieved data, and (2) pledge their share of the value attached to the data request as a reward. Reveal: used by witnesses to (1) reveal the actual value of the retrieved data that they committed in their previous commit , and once again to (2) pledge their share of the value attached to the data request as a reward. Tally: used by the block miner to (1) publish the result of a data request after consensus, and (2) refund the unspent commit outputs to the data request creator. Different output types also cause the transactions they are in to be validated using specific validation rules. Value transfer outputs \u00b6 Value transfer outputs (VTO) very much resemble Bitcoin's pay-to-public-key (P2PKH) outputs. For anyone to spend a value transfer output, they must sign the spending transaction with a private key whose matching public key's SHA256 hash digest starts with the exact 20 bytes explicitly stated in the output itself. As those 20 bytes represent an entropy of 2^160 taken from the output of a hash function that is generally accepted to be secure under the random oracle model , it can be safely assumed that a signature that satisfies such requirements was likely produced with a particular private key and therefore whoever provided the signature is also in possession of such private key. The pkh field is defined as the first 20 bytes of the digest of a public key. VTOs can be time locked so as to prevent further transactions from spending their value before a certain date and time. Data structure \u00b6 Field Type Description pkh bytes Slice of the digest of a public key (20 bytes) value uint64 Transaction value time_lock uint64 The UTC Unix timestamp before which the output can not be spent Specific validation rules \u00b6 VTOs take their value from the aggregate of all the inputs in the transactions. The number of VTOs in a single transaction is virtually unlimited as long as the VTOs are all contiguous and located at the end of the outputs list. A single VTO spending from no inputs is considered to be a mint transaction, which is only acceptable if located first in the list of transactions of a block. The value brought into a transaction by an input pointing to a VTO can be freely assigned to any output of any type, unless otherwise restricted by the specific validation rules for such output type. Data Request outputs \u00b6 Data request outputs publish requests for retrieving, aggregating and delivering data from external sources. At the same time, they specify and lock fees that will reward the different players involved throughout the life cycle of a data request, i.e. the nodes retrieving the data (a.k.a. witnesses ) and the miner nodes responsible for timely including commit , reveal and tally transactions into new blocks. During the reveal stage, some eligible witnesses who published commitments may not follow up with their reveals. This could happen if they are not able to see their commitment transactions timely included in a block (e.g. because of network errors). Miners are actually not obliged to include all the reveal transactions and eventually end up assigning rewards to the committers. This is because there is no way for the network to enforce punishment on them for neglecting or trying to conceal those transactions because there is no guarantee that they will be known to them in discrete time or even known whatsoever. However, for every of those transactions that they include in a block, they are eligible for collecting special fees as explicitly specified and set aside for them in the original data request output, i.e. the reveal_fee and tally_fee . It is therefore to be expected that miners will include as many of those transactions as known to them as for maximizing their profit. This type of output also provides the digest of the public key to which the requester wants any unassigned rewards to be refunded. This digest does not necessarily need to match the public key used to sign the transaction where this output is included, which allows requesters to \"donate\" those funds to a third party or to simply move them to another public key of their own. Data structure \u00b6 Field Type Description pkh bytes Slice of the digest of a public key (20 bytes) data_request RadRequest Data request scripts as a byte array value uint64 Transaction value that will be used as reward to be distributed after consensus has been reached and fees have been subtracted witnesses uint32 Minimum amount of witness nodes that will be employed for resolving this data request (max 65535) backup_witnesses uint32 Number of backup witnesses that will be employed for resolving this data request (max 65535) commit_fee uint64 Miner fee for each valid commit output included in the block during the commit stage reveal_fee uint64 Miner fee for each valid reveal output included in the block during the reveal stage tally_fee uint64 Miner fee for each valid value transfer output included in the block during the tally stage time_lock uint64 The UTC Unix timestamp after which data request shall be executed Values, rewards and fees \u00b6 The minimum data request reward to be eventually distributed in the tally among nodes that agreed with the consensus is defined as follows: dr_reward_min = value - (witnesses * commit_fee) - (witnesses * reveal_fee) - (witnesses * tally_fee) Specific validation rules \u00b6 Multiple data request outputs can be included into a single transaction as long as the inputs are greater than outputs rule still hold true. The difference with VTOs is that the total output value for data request outputs also include the commit fee , reveal fee and tally fee . The value brought into a transaction by an input pointing to a data request output can only be spent by commit outputs. Commit outputs \u00b6 Commit outputs are used by witnesses for submitting a commitment of the results of their retrieval and aggregation tasks without revealing the actual value of the data. This prevents other eligible witness nodes from not executing the data request, just trying to replay other witness nodes' reported results. When creating commitments, a randomly generated secret value called nonce is paired with the actual value that resulted from executing the data request, again to prevent other witness nodes from acting lazy, trying to guess and replay others' commitments. An unforeseeable and time-bound source of pseudo-randomness is also included into the mix when creating the commitment, so that this computation cannot be performed ahead of time. Namely, this source of randomness is the latest checkpoint beacon, which contains the identifier of the latest block in the chain, which is extremely hard to predict. Therefore, the algorithm for computing a commitment is: SHA256(result || nonce || beacon) Data structure \u00b6 Field Type Description commitment bytes Digest of the data request's aggregation stage, salted by a nonce and the previous checkpoint beacon value uint64 Remaining transaction value that will be used as reward to be distributed after consensus has been reached Values, rewards and fees \u00b6 The value of the commit output depends on the target number of witness nodes employed, as stated in the data request itself: commit_value = (data_request_value / witnesses) - commit_fee Specific validation rules \u00b6 Commit outputs can only take value from data request inputs whose index in the inputs list is the same as their own index in the outputs list. Multiple commit outputs can exist in a single transaction, but each of them needs to be coupled with a data request input occupying the same index in the inputs list as their own in the outputs list. Predictably, as a result of the previous rule, each of the multiple commit outputs only takes value from the data request input with the same index. The value brought into a transaction by an input pointing to a commit output can only be spent by reveal or tally outputs. Reveal outputs \u00b6 Reveal outputs are created and published by every witness node who previously published a commitment only after they have verified that a sufficient number of other witness nodes have published their own commitments for the same data request. This is to prevent others from forging commitments without actually executing the retrieval and aggregation as requested. This type of output contains the result of executing the retrieval and aggregation stage scripts of a data request. It also provides the digest of the public key to which the witness node wants the reward to be assigned if the revealed value passes the consensus stage function as explicitly defined by the original data request. This digest does not necessarily need to match the public key used by the witness node for eligibility (i.e. mining and request resolving). This allows witness nodes to \"donate\" the rewards to a third party or to simply move them to another public key of their own. Data structure \u00b6 Field Type Description reveal bytes The result of executing the retrieval and aggregation stage scripts of a data inputs can onrequest pkh bytes Slice of the digest of a public key (20 bytes) value uint64 Remaining transaction value that will be used as reward to be distributed after consensus has been reached Values, rewards and fees \u00b6 The value of the reveal output depends on the number of witness nodes employed, as stated in the data request itself: reveal_value = commit_value - reveal_fee Specific validation rules \u00b6 Reveal outputs can only take value from commit inputs whose index in the inputs list is the same as their own index in the outputs list. Multiple reveal outputs can exist in a single transaction, but each of them needs to be coupled with a commit input occupying the same index in the inputs list as their own in the outputs list. Predictably, as a result of the previous rule, each of the multiple reveal outputs only takes value from the commit input with the same index. The value brought into a transaction by an input pointing to a reveal output can only be spent by value transfer outputs. Any transaction including an input pointing to a reveal output must also include exactly only one tally output. Tally outputs \u00b6 Tally outputs are used by block miners for publishing the result of running each data request's consensus stage script on the data revealed by the witness nodes that were lucky enough to be eligible for doing so. Tally outputs are only present in transactions created by miners for joining all the reveal outputs for the same data request and eventually creating new outputs for rewarding the \"revealers\". Thus, those transactions will contain at most as many value transfer outputs as witnesses were originally employed plus the tally output itself. Singularly, the pkh found in tally outputs is not the digest of the public key of the miner or any witness node, but that of the request creator, as explicitly stated in the original data request. This allows refunding any value left after distributing all rewards and fees. Data structure \u00b6 Field Type Description result bytes Data request result as computed by applying the consensus stage function as specified by the data request on every reveal input in the same transaction as this output pkh bytes Slice of the digest of the public key of the data request creator (20 bytes) value uint64 Remaining transaction value that has not been used as reward or fee of the data request Values, rewards and fees \u00b6 The value of the tally output is the remaining value after distributing all rewards and fees among witnesses and miners respectively: reveal_value = data_request_value - committers * commit_fee - revealers * (reveal_fee + tally_fee + reward) Specific validation rules \u00b6 Any transaction can contain at most one tally output. Transactions containing tally outputs must not be broadcast through the inventory announcement protocol. As a result of the previous rule, transactions containing tally outputs can only be included into a block by the miner of the block. The value brought into a transaction by an input pointing to a tally output can be freely assigned to any output of any type, unless otherwise restricted by the specific validation rules for such output type. Inputs \u00b6 Transaction inputs are references to outputs from past transactions. They \"pull\" all the value from those outputs and make it available for being spent by the outputs in the same transaction they are in. This data structure\u2014which pairs a transaction's identifier with the index of one of its outputs\u2014unambiguously points to a unique output from a specific transaction. Every input included in a transaction needs to be coupled with a signature in the signatures section. Some inputs also provide additional pieces of data as required to fulfill the specific spending conditions of the outputs they are pointing to. These pieces of data are called claims , and allow the party creating a transaction to prove their right to spend the referred output and convince every other node in the network to consider the transaction to be valid and to broadcast it. Different output types require their spending inputs to provide specific claims in order to fulfill their spending conditions. All input structures consist at least of the following fields: Field Type Description transaction_id Hash A transaction identifier output_index uint32 The index of a specific output in the transaction Inputs trying to spend outputs of type data request and commit have additional fields for their specific claims, as described below. Data request input \u00b6 Every data request output can be spent by as many data request inputs as defined in the output itself, which has a field explicitly stating such number. For a witness node to be able to put aside a share of the reward from the data for itself, it must provide an input with a Proof of Eligibility (PoE) claim: a cryptographically verifiable proof of their right to act as a witness for such data request in the current epoch. In addition, for every other node in the network to be able to verify such proof, this PoE must be produced using a private key that matches the the public key included in the signatures section of the transaction. Thus, the data request input structure consists of the following fields: Field Type Description transaction_id Hash A transaction identifier output_index uint32 The index of a specific output in the transaction poe bytes Proof of Eligibility produced with same keypair as the transaction signature Commit input \u00b6 Commit inputs are used by witness nodes for proving that they actually executed the data request in a timely manner and revealing the actual result value that they secretly committed in their commit transactions. Therefore, the claims in commit inputs provide every element that was used for producing the previously published commitment but was unknown to the rest of the nodes in the network by that moment. Namely, those claims are the reveal and nonce values. Thus, the commit input structure consists of the following fields: Field Type Description transaction_id Hash A transaction identifier output_index uint32 The index of a specific output in the transaction reveal bytes The result of executing the retrieval and aggregation stages of the data request nonce fixed64 The nonce used for generating the previously published commitment Reveal input \u00b6 Reveal inputs abide by the general input format without adding any specific claim. The only distinctive feature of reveal inputs is that they do not require matching signatures, as the transactions where these inputs can be included are always built by the nodes who produce the blocks where they are anchored, and in doing so, they already provide the signature of the entire list of transactions in the block's header. Signatures \u00b6 As aforementioned, transactions should include as many signatures as inputs. In every transaction, signatures complement the material required for satisfying the spending conditions that encumbered the past transaction outputs that the inputs in the transaction are trying to spend. Signatures and inputs are matched positionally, i.e. the first claim is checked against the first input and so forth. Signatures prove ownership of a certain private key by providing a signature of the identifier of the transaction produced with such key and the serialization of the matching public key. Transaction signatures are structured as keyed signatures . Only the reveal inputs do not require matching signatures, as the transactions where these inputs can be included are always built by the nodes who produce the blocks where they are anchored, and in doing so, they already provide the signature of the entire list of transactions in the block's header.","title":"Transaction"},{"location":"protocol/network/data-structures/transaction/#transaction","text":"In the Witnet network protocol, a transaction is formatted as follows: Field Type Description version uint32 The transaction data format version number inputs repeated Input A list of transaction inputs outputs repeated Output A list of 1 or more transaction outputs signatures repeated KeyedSignature A list of keyed signatures (as many as inputs) Long story short, inputs contain data that proves ability to \"pull\" value from past transactions into a new transaction, while outputs redistribute such value and lock them under new spending conditions. Signatures ensure integrity of the transaction and complement input's function when it comes to prove ability to unlock funds from past transactions. Generally, the sum of the values of the outputs in a transaction must not exceed the sum of the values of the inputs, so as to guarantee that value is not created out of thin air. The only exception to this rule is the mint transaction, which every block's miner node must include at the beginning of the transactions list contained in it. Mint transactions, which are roughly equivalent to Bitcoin's coinbase , have no inputs and only one output, thus effectively minting a fixed amount of new value. As it is the case for many other unspent output based cryptocurrencies, for every transaction, any value surplus after detracting the total output value from the total input value is considered to be the miner fee , which can be redeemed by the miner of the block in which the transaction gets anchored.","title":"Transaction"},{"location":"protocol/network/data-structures/transaction/#outputs","text":"Outputs gather the value brought into transactions by inputs and lock fractions of that value under new spending conditions. Transactions may contain different types of outputs: Value transfer: roughly equivalent to Bitcoin's P2PKH/P2WPKH, where the output specifies the hash of a public key. Client Data Request (DR): publishes a request for data. It must include scripts for retrieval, aggregation, consensus and, optionally, deliver clauses. Commit: used by witnesses to (1) commit the results of their retrieval tasks without revealing the actual value of the retrieved data, and (2) pledge their share of the value attached to the data request as a reward. Reveal: used by witnesses to (1) reveal the actual value of the retrieved data that they committed in their previous commit , and once again to (2) pledge their share of the value attached to the data request as a reward. Tally: used by the block miner to (1) publish the result of a data request after consensus, and (2) refund the unspent commit outputs to the data request creator. Different output types also cause the transactions they are in to be validated using specific validation rules.","title":"Outputs"},{"location":"protocol/network/data-structures/transaction/#value-transfer-outputs","text":"Value transfer outputs (VTO) very much resemble Bitcoin's pay-to-public-key (P2PKH) outputs. For anyone to spend a value transfer output, they must sign the spending transaction with a private key whose matching public key's SHA256 hash digest starts with the exact 20 bytes explicitly stated in the output itself. As those 20 bytes represent an entropy of 2^160 taken from the output of a hash function that is generally accepted to be secure under the random oracle model , it can be safely assumed that a signature that satisfies such requirements was likely produced with a particular private key and therefore whoever provided the signature is also in possession of such private key. The pkh field is defined as the first 20 bytes of the digest of a public key. VTOs can be time locked so as to prevent further transactions from spending their value before a certain date and time.","title":"Value transfer outputs"},{"location":"protocol/network/data-structures/transaction/#data-structure","text":"Field Type Description pkh bytes Slice of the digest of a public key (20 bytes) value uint64 Transaction value time_lock uint64 The UTC Unix timestamp before which the output can not be spent","title":"Data structure"},{"location":"protocol/network/data-structures/transaction/#specific-validation-rules","text":"VTOs take their value from the aggregate of all the inputs in the transactions. The number of VTOs in a single transaction is virtually unlimited as long as the VTOs are all contiguous and located at the end of the outputs list. A single VTO spending from no inputs is considered to be a mint transaction, which is only acceptable if located first in the list of transactions of a block. The value brought into a transaction by an input pointing to a VTO can be freely assigned to any output of any type, unless otherwise restricted by the specific validation rules for such output type.","title":"Specific validation rules"},{"location":"protocol/network/data-structures/transaction/#data-request-outputs","text":"Data request outputs publish requests for retrieving, aggregating and delivering data from external sources. At the same time, they specify and lock fees that will reward the different players involved throughout the life cycle of a data request, i.e. the nodes retrieving the data (a.k.a. witnesses ) and the miner nodes responsible for timely including commit , reveal and tally transactions into new blocks. During the reveal stage, some eligible witnesses who published commitments may not follow up with their reveals. This could happen if they are not able to see their commitment transactions timely included in a block (e.g. because of network errors). Miners are actually not obliged to include all the reveal transactions and eventually end up assigning rewards to the committers. This is because there is no way for the network to enforce punishment on them for neglecting or trying to conceal those transactions because there is no guarantee that they will be known to them in discrete time or even known whatsoever. However, for every of those transactions that they include in a block, they are eligible for collecting special fees as explicitly specified and set aside for them in the original data request output, i.e. the reveal_fee and tally_fee . It is therefore to be expected that miners will include as many of those transactions as known to them as for maximizing their profit. This type of output also provides the digest of the public key to which the requester wants any unassigned rewards to be refunded. This digest does not necessarily need to match the public key used to sign the transaction where this output is included, which allows requesters to \"donate\" those funds to a third party or to simply move them to another public key of their own.","title":"Data Request outputs"},{"location":"protocol/network/data-structures/transaction/#data-structure_1","text":"Field Type Description pkh bytes Slice of the digest of a public key (20 bytes) data_request RadRequest Data request scripts as a byte array value uint64 Transaction value that will be used as reward to be distributed after consensus has been reached and fees have been subtracted witnesses uint32 Minimum amount of witness nodes that will be employed for resolving this data request (max 65535) backup_witnesses uint32 Number of backup witnesses that will be employed for resolving this data request (max 65535) commit_fee uint64 Miner fee for each valid commit output included in the block during the commit stage reveal_fee uint64 Miner fee for each valid reveal output included in the block during the reveal stage tally_fee uint64 Miner fee for each valid value transfer output included in the block during the tally stage time_lock uint64 The UTC Unix timestamp after which data request shall be executed","title":"Data structure"},{"location":"protocol/network/data-structures/transaction/#values-rewards-and-fees","text":"The minimum data request reward to be eventually distributed in the tally among nodes that agreed with the consensus is defined as follows: dr_reward_min = value - (witnesses * commit_fee) - (witnesses * reveal_fee) - (witnesses * tally_fee)","title":"Values, rewards and fees"},{"location":"protocol/network/data-structures/transaction/#specific-validation-rules_1","text":"Multiple data request outputs can be included into a single transaction as long as the inputs are greater than outputs rule still hold true. The difference with VTOs is that the total output value for data request outputs also include the commit fee , reveal fee and tally fee . The value brought into a transaction by an input pointing to a data request output can only be spent by commit outputs.","title":"Specific validation rules"},{"location":"protocol/network/data-structures/transaction/#commit-outputs","text":"Commit outputs are used by witnesses for submitting a commitment of the results of their retrieval and aggregation tasks without revealing the actual value of the data. This prevents other eligible witness nodes from not executing the data request, just trying to replay other witness nodes' reported results. When creating commitments, a randomly generated secret value called nonce is paired with the actual value that resulted from executing the data request, again to prevent other witness nodes from acting lazy, trying to guess and replay others' commitments. An unforeseeable and time-bound source of pseudo-randomness is also included into the mix when creating the commitment, so that this computation cannot be performed ahead of time. Namely, this source of randomness is the latest checkpoint beacon, which contains the identifier of the latest block in the chain, which is extremely hard to predict. Therefore, the algorithm for computing a commitment is: SHA256(result || nonce || beacon)","title":"Commit outputs"},{"location":"protocol/network/data-structures/transaction/#data-structure_2","text":"Field Type Description commitment bytes Digest of the data request's aggregation stage, salted by a nonce and the previous checkpoint beacon value uint64 Remaining transaction value that will be used as reward to be distributed after consensus has been reached","title":"Data structure"},{"location":"protocol/network/data-structures/transaction/#values-rewards-and-fees_1","text":"The value of the commit output depends on the target number of witness nodes employed, as stated in the data request itself: commit_value = (data_request_value / witnesses) - commit_fee","title":"Values, rewards and fees"},{"location":"protocol/network/data-structures/transaction/#specific-validation-rules_2","text":"Commit outputs can only take value from data request inputs whose index in the inputs list is the same as their own index in the outputs list. Multiple commit outputs can exist in a single transaction, but each of them needs to be coupled with a data request input occupying the same index in the inputs list as their own in the outputs list. Predictably, as a result of the previous rule, each of the multiple commit outputs only takes value from the data request input with the same index. The value brought into a transaction by an input pointing to a commit output can only be spent by reveal or tally outputs.","title":"Specific validation rules"},{"location":"protocol/network/data-structures/transaction/#reveal-outputs","text":"Reveal outputs are created and published by every witness node who previously published a commitment only after they have verified that a sufficient number of other witness nodes have published their own commitments for the same data request. This is to prevent others from forging commitments without actually executing the retrieval and aggregation as requested. This type of output contains the result of executing the retrieval and aggregation stage scripts of a data request. It also provides the digest of the public key to which the witness node wants the reward to be assigned if the revealed value passes the consensus stage function as explicitly defined by the original data request. This digest does not necessarily need to match the public key used by the witness node for eligibility (i.e. mining and request resolving). This allows witness nodes to \"donate\" the rewards to a third party or to simply move them to another public key of their own.","title":"Reveal outputs"},{"location":"protocol/network/data-structures/transaction/#data-structure_3","text":"Field Type Description reveal bytes The result of executing the retrieval and aggregation stage scripts of a data inputs can onrequest pkh bytes Slice of the digest of a public key (20 bytes) value uint64 Remaining transaction value that will be used as reward to be distributed after consensus has been reached","title":"Data structure"},{"location":"protocol/network/data-structures/transaction/#values-rewards-and-fees_2","text":"The value of the reveal output depends on the number of witness nodes employed, as stated in the data request itself: reveal_value = commit_value - reveal_fee","title":"Values, rewards and fees"},{"location":"protocol/network/data-structures/transaction/#specific-validation-rules_3","text":"Reveal outputs can only take value from commit inputs whose index in the inputs list is the same as their own index in the outputs list. Multiple reveal outputs can exist in a single transaction, but each of them needs to be coupled with a commit input occupying the same index in the inputs list as their own in the outputs list. Predictably, as a result of the previous rule, each of the multiple reveal outputs only takes value from the commit input with the same index. The value brought into a transaction by an input pointing to a reveal output can only be spent by value transfer outputs. Any transaction including an input pointing to a reveal output must also include exactly only one tally output.","title":"Specific validation rules"},{"location":"protocol/network/data-structures/transaction/#tally-outputs","text":"Tally outputs are used by block miners for publishing the result of running each data request's consensus stage script on the data revealed by the witness nodes that were lucky enough to be eligible for doing so. Tally outputs are only present in transactions created by miners for joining all the reveal outputs for the same data request and eventually creating new outputs for rewarding the \"revealers\". Thus, those transactions will contain at most as many value transfer outputs as witnesses were originally employed plus the tally output itself. Singularly, the pkh found in tally outputs is not the digest of the public key of the miner or any witness node, but that of the request creator, as explicitly stated in the original data request. This allows refunding any value left after distributing all rewards and fees.","title":"Tally outputs"},{"location":"protocol/network/data-structures/transaction/#data-structure_4","text":"Field Type Description result bytes Data request result as computed by applying the consensus stage function as specified by the data request on every reveal input in the same transaction as this output pkh bytes Slice of the digest of the public key of the data request creator (20 bytes) value uint64 Remaining transaction value that has not been used as reward or fee of the data request","title":"Data structure"},{"location":"protocol/network/data-structures/transaction/#values-rewards-and-fees_3","text":"The value of the tally output is the remaining value after distributing all rewards and fees among witnesses and miners respectively: reveal_value = data_request_value - committers * commit_fee - revealers * (reveal_fee + tally_fee + reward)","title":"Values, rewards and fees"},{"location":"protocol/network/data-structures/transaction/#specific-validation-rules_4","text":"Any transaction can contain at most one tally output. Transactions containing tally outputs must not be broadcast through the inventory announcement protocol. As a result of the previous rule, transactions containing tally outputs can only be included into a block by the miner of the block. The value brought into a transaction by an input pointing to a tally output can be freely assigned to any output of any type, unless otherwise restricted by the specific validation rules for such output type.","title":"Specific validation rules"},{"location":"protocol/network/data-structures/transaction/#inputs","text":"Transaction inputs are references to outputs from past transactions. They \"pull\" all the value from those outputs and make it available for being spent by the outputs in the same transaction they are in. This data structure\u2014which pairs a transaction's identifier with the index of one of its outputs\u2014unambiguously points to a unique output from a specific transaction. Every input included in a transaction needs to be coupled with a signature in the signatures section. Some inputs also provide additional pieces of data as required to fulfill the specific spending conditions of the outputs they are pointing to. These pieces of data are called claims , and allow the party creating a transaction to prove their right to spend the referred output and convince every other node in the network to consider the transaction to be valid and to broadcast it. Different output types require their spending inputs to provide specific claims in order to fulfill their spending conditions. All input structures consist at least of the following fields: Field Type Description transaction_id Hash A transaction identifier output_index uint32 The index of a specific output in the transaction Inputs trying to spend outputs of type data request and commit have additional fields for their specific claims, as described below.","title":"Inputs"},{"location":"protocol/network/data-structures/transaction/#data-request-input","text":"Every data request output can be spent by as many data request inputs as defined in the output itself, which has a field explicitly stating such number. For a witness node to be able to put aside a share of the reward from the data for itself, it must provide an input with a Proof of Eligibility (PoE) claim: a cryptographically verifiable proof of their right to act as a witness for such data request in the current epoch. In addition, for every other node in the network to be able to verify such proof, this PoE must be produced using a private key that matches the the public key included in the signatures section of the transaction. Thus, the data request input structure consists of the following fields: Field Type Description transaction_id Hash A transaction identifier output_index uint32 The index of a specific output in the transaction poe bytes Proof of Eligibility produced with same keypair as the transaction signature","title":"Data request input"},{"location":"protocol/network/data-structures/transaction/#commit-input","text":"Commit inputs are used by witness nodes for proving that they actually executed the data request in a timely manner and revealing the actual result value that they secretly committed in their commit transactions. Therefore, the claims in commit inputs provide every element that was used for producing the previously published commitment but was unknown to the rest of the nodes in the network by that moment. Namely, those claims are the reveal and nonce values. Thus, the commit input structure consists of the following fields: Field Type Description transaction_id Hash A transaction identifier output_index uint32 The index of a specific output in the transaction reveal bytes The result of executing the retrieval and aggregation stages of the data request nonce fixed64 The nonce used for generating the previously published commitment","title":"Commit input"},{"location":"protocol/network/data-structures/transaction/#reveal-input","text":"Reveal inputs abide by the general input format without adding any specific claim. The only distinctive feature of reveal inputs is that they do not require matching signatures, as the transactions where these inputs can be included are always built by the nodes who produce the blocks where they are anchored, and in doing so, they already provide the signature of the entire list of transactions in the block's header.","title":"Reveal input"},{"location":"protocol/network/data-structures/transaction/#signatures","text":"As aforementioned, transactions should include as many signatures as inputs. In every transaction, signatures complement the material required for satisfying the spending conditions that encumbered the past transaction outputs that the inputs in the transaction are trying to spend. Signatures and inputs are matched positionally, i.e. the first claim is checked against the first input and so forth. Signatures prove ownership of a certain private key by providing a signature of the identifier of the transaction produced with such key and the serialization of the matching public key. Transaction signatures are structured as keyed signatures . Only the reveal inputs do not require matching signatures, as the transactions where these inputs can be included are always built by the nodes who produce the blocks where they are anchored, and in doing so, they already provide the signature of the entire list of transactions in the block's header.","title":"Signatures"},{"location":"protocol/network/messages/handshake/","text":"Handshake \u00b6 The protocol to connect from a local peer (handshake initiator) to a known remote peer, is known as a \"handshake.\" The handshake starts with a TCP connection to a given IP address and port. The handshake initiator, sends a Version message to the remote peer. Then, the remote peer will analyze the information in order to evaluate if the submitting peer is compatible regarding their supported versions and capabilities. If so, the remote peer will acknowledge the Version message and establish a connection by sending a Verack message. Subsequently, the handshake initiator will expect a Version message from the remote peer. The local peer will also acknowledge by replying with a Verack message. A peer cannot consider a Witnet session to be valid and established until it has received a Verack message (in response to a previously sent Version message) and it has sent a Verack message (as acknowledgement to a previously received Version message). After the TCP connection has been started, both peers will define a timeout to wait for establishing a valid Witnet session. If no Verack is received during these timeouts (e.g. 10 seconds), the TCP connection will be dropped and the remote peer will be discarded from the known peers list. Additionally, Witnet nodes will not reply to any other message types until a valid Witnet session has been successfully established. NodeA NodeB + + ^ | VERSION | ^ | +------------------------------->+ | | | | | | | VERACK | | | +<-------------------------------+ | TimeoutA | | VERSION | | TimeoutB | +<-------------------------------+ | | | | | | | VERACK | | | +------------------------------->+ | | | | | v | | v + + Version message \u00b6 The Version message contains the following information: Field Type Description Version uint32 The Witnet p2p protocol version that the client is using timestamp int64 The current UTC Unix timestamp (seconds since Unix epoch) capabilities fixed64 List of flags of supported services, by default NODE_NETWORK is used sender_address Address The IP address and port of the handshake initiator peer receiver_address Address The IP address and port of the remote peer user_agent string A version showing which software is running the local peer last_epoch fixed32 Last epoch in the local peer blockchain genesis Hash Hash of the genesis block nonce fixed64 Node random nonce, randomly generated every time a version packet is sent (used to detect connections to self) Verack message \u00b6 The Verack message is sent as reply to the version and it only consists of a message header with the command Verack .","title":"Handshake"},{"location":"protocol/network/messages/handshake/#handshake","text":"The protocol to connect from a local peer (handshake initiator) to a known remote peer, is known as a \"handshake.\" The handshake starts with a TCP connection to a given IP address and port. The handshake initiator, sends a Version message to the remote peer. Then, the remote peer will analyze the information in order to evaluate if the submitting peer is compatible regarding their supported versions and capabilities. If so, the remote peer will acknowledge the Version message and establish a connection by sending a Verack message. Subsequently, the handshake initiator will expect a Version message from the remote peer. The local peer will also acknowledge by replying with a Verack message. A peer cannot consider a Witnet session to be valid and established until it has received a Verack message (in response to a previously sent Version message) and it has sent a Verack message (as acknowledgement to a previously received Version message). After the TCP connection has been started, both peers will define a timeout to wait for establishing a valid Witnet session. If no Verack is received during these timeouts (e.g. 10 seconds), the TCP connection will be dropped and the remote peer will be discarded from the known peers list. Additionally, Witnet nodes will not reply to any other message types until a valid Witnet session has been successfully established. NodeA NodeB + + ^ | VERSION | ^ | +------------------------------->+ | | | | | | | VERACK | | | +<-------------------------------+ | TimeoutA | | VERSION | | TimeoutB | +<-------------------------------+ | | | | | | | VERACK | | | +------------------------------->+ | | | | | v | | v + +","title":"Handshake"},{"location":"protocol/network/messages/handshake/#version-message","text":"The Version message contains the following information: Field Type Description Version uint32 The Witnet p2p protocol version that the client is using timestamp int64 The current UTC Unix timestamp (seconds since Unix epoch) capabilities fixed64 List of flags of supported services, by default NODE_NETWORK is used sender_address Address The IP address and port of the handshake initiator peer receiver_address Address The IP address and port of the remote peer user_agent string A version showing which software is running the local peer last_epoch fixed32 Last epoch in the local peer blockchain genesis Hash Hash of the genesis block nonce fixed64 Node random nonce, randomly generated every time a version packet is sent (used to detect connections to self)","title":"Version message"},{"location":"protocol/network/messages/handshake/#verack-message","text":"The Verack message is sent as reply to the version and it only consists of a message header with the command Verack .","title":"Verack message"},{"location":"protocol/network/messages/heartbeat/","text":"Heartbeat \u00b6 The hearbeat protocol's main purpose is to notify to other peers that the node is still active and running. This information may be relevant for managing a list of active peers. The heartbeat protocol is defined by using Ping and Pong messages and it allows to implement different strategies to react to peer inactivity. For example: If during a period of time (e.g. 30 minutes) a peer has not transmitted any messages, it will send a heartbeat as Ping message. If during a period of time (e.g. 90 minutes) no message has been received by a remote peer, the local node will assume that the connection has been closed. NodeA NodeB + + | PING | +----------------------------->+ | PONG | +<-----------------------------+ | | + + Ping and Pong messages \u00b6 The Ping message confirms that the connection is still valid. The Pong message is sent in response to a Ping message. Both contain only 1 field: Field Type Description nonce fixed64 A random number","title":"Heartbeat"},{"location":"protocol/network/messages/heartbeat/#heartbeat","text":"The hearbeat protocol's main purpose is to notify to other peers that the node is still active and running. This information may be relevant for managing a list of active peers. The heartbeat protocol is defined by using Ping and Pong messages and it allows to implement different strategies to react to peer inactivity. For example: If during a period of time (e.g. 30 minutes) a peer has not transmitted any messages, it will send a heartbeat as Ping message. If during a period of time (e.g. 90 minutes) no message has been received by a remote peer, the local node will assume that the connection has been closed. NodeA NodeB + + | PING | +----------------------------->+ | PONG | +<-----------------------------+ | | + +","title":"Heartbeat"},{"location":"protocol/network/messages/heartbeat/#ping-and-pong-messages","text":"The Ping message confirms that the connection is still valid. The Pong message is sent in response to a Ping message. Both contain only 1 field: Field Type Description nonce fixed64 A random number","title":"Ping and Pong messages"},{"location":"protocol/network/messages/inventory/","text":"Inventory Exchange \u00b6 The inventory exchange protocol describes the interaction between nodes in order to synchronize themselves with the network and reestablish the full blockchain (in terms of blocks and transactions). Inventory exchanges envision 2 main scenarios: Block Download , for nodes in need of synchronizing their blockchains by requesting and downloading blocks. Inventory Broadcasting , for nodes willing to broadcast transactional information, such as blocks and transactions. Block Download \u00b6 Block Download is performed by nodes that need to catch up with other nodes by downloading missing blocks in order to reconstruct their blockchains. For example, this is the case of nodes connecting to the blockchain for the first time or after a significant amount of downtime. Starting from the block #0 (the hardcoded genesis block), the nodes need to validate all blocks up to the current tip of the blockchain. Therefore, in case of missing blocks, a local node will initiate the following process of synchronization with its outbound peers: The local node will have already exchanged Version messages with its remote outbound peers. Those Version messages contain the last epoch known to others peers, i.e. the local peer can already compare how many blocks they each have and identify how many are missing. The local node will send a LastBeacon message to all its outbound nodes (after successful handshake protocol). These messages contain the hash of the top block of the local blockchain and the epoch of that block. Remote peers will reply by sending another LastBeacon message containing the hash of the top block of their respective blockchains and the epochs for those top blocks. The peer with the longest blockchain will identify which blocks are required by the other peer in order to allow it to synchronize to its blockchain. The peer will select up to the first consecutive 500 blocks and it will transmit their hashes using an InventoryAnnouncement message. After identifying which blocks are missing (it may already have some of them), the node may request them by using a InventoryRequest message, containing the hashes of the needed blocks. This message will help the node to catch up with the current full blockchain. After receiving the InventoryRequest message, the peer sends the requested blocks individually by using Block messages. The following diagram depicts the previously described process under the assumption that the peer with the longest blockchain is NodeB (step 4). NodeA NodeB + + | LAST_BEACON | +--------------------------->+ | LAST_BEACON | +<---------------------------+ | INVENTORY_ANNOUNCEMENT | +<---------------------------+ | | | | | INVENTORY_REQUEST | +--------------------------->+ | BLOCK | +<-------------------------- + | BLOCK | +<-------------------------- + | BLOCK | +<---------------------------+ | | + + Inventory Broadcasting \u00b6 Similarly to the previously described process of synchronization, any node may contribute to the synchronization of their outbound peers by advertising inventory objects such as blocks and transactions. Inventory broadcasting is also used in case a node creates transactions or mine blocks. The inventory broadcasting can be described as the following sequence of steps: A remote node broadcasts its inventory by sending an InventoryAnnouncement message, containing all the hashes of the advertised inventory objects. After receiving an InventoryAnnouncement message and filtering the inventory objects that may be missing in the local blockchain, the local node sends a InventoryRequest message with the hashes of the needed objects. The remote note receives the InventoryRequest message and sends a Block or Transaction message per requested inventory object (identified by a hash). The following diagram depicts the previous step under the assumption that the local node ( NodeA ) sends a InventoryRequest message requesting 3 blocks and 2 transactions. NodeA NodeB + + | INVENTORY_ANNOUNCEMENT | +<-------------------------------+ | | | INVENTORY_REQUEST | +------------------------------->+ | | | BLOCK | +<-------------------------------+ | BLOCK | +<-------------------------------+ | BLOCK | +<-------------------------------+ | TRANSACTION | +<-------------------------------+ | TRANSACTION | +<-------------------------------+ | | + + LastBeacon message \u00b6 The LastBeacon messages are used in order to notify the hash of the highest known block by the peer together with its epoch. After exchanging LastBeacon messages between peers, the one with the longest blockchain in terms of blocks will send an InventoryAnnouncement message to the other peer. This message will include the list of block hashes starting right after the last known block hash provided by the other peer. The LastBeacon message consists of a message header with the LastBeacon command and a payload containing the beacon for the tip of the chain (the hash of the latest block and its checkpoint) as known to the local peer: Field Type Description highest_block_checkpoint CheckpointBeacon Last beacon (checkpoint + hash) The checkpoint beacon ( CheckpointBeacon ) is composed of the following fields: Field Type Description checkpoint fixed32 The serial number for this epoch hash_prev_block Hash The 256-bit hash of the previous block InventoryAnnouncement message \u00b6 The InventoryAnnouncement message is used to advertise the knowledge of one or more objects (e.g. blocks, transactions, ...). The inventory message can be received unsolicited or in reply to a LastBeacon message. The InventoryAnnouncement message consists of a message header with the InventoryAnnouncement command and a payload containing one or more inventory entries: Field Type Description inventory inventory_entry[] Vector of inventory entries InventoryRequest message \u00b6 The InventoryRequest messages are used in order to request specific objects from other nodes. Usually, InventoryRequest messages are sent after receiving a InventoryAnnouncement message and filtering the already known objects. The response to a InventoryRequest message is often one or more messages carrying the requested objects (e.g.: Block , Transaction , etc.). The InventoryRequest message consists of a message header with the InventoryRequest command and a payload following this format: Field Type Description inventory repeated InventoryEntry Inventory entries that are being requested Block message \u00b6 The Block message is used to transmit a single serialized block as a response to a InventoryRequest message. The Block message consists of a message header with the Block command and a payload containing information for a block following the format defined in the Block section. Transaction message \u00b6 Analogously, the Transaction message is used to transmit a single serialized transaction as a response to a InventoryRequest message. The Transaction message consists of a message header with the Transaction command and a payload containing information for a transaction following the format defined in the Transaction section. Helper data structures \u00b6 Hash \u00b6 The hash ( Hash ) data structure is a tagged union of the supported hashing algorithms: Kind Description SHA256 SHA256 hash type (32 bytes) In the future, the type values may be extended in order to consider additional hash types. InventoryEntry \u00b6 The InventoryEntry data structure is a tagged union of the different inventory item types: Kind Description Error Data with this number may be ignored Tx Hash is related to a transaction Block Hash is related to a block DataRequest Hash is related to a data request DataResult Hash is related to the result of a data request Each type has one field: Field Type Description hash Hash The hash of this item In the future, the type values may be extended in order to consider additional features.","title":"Inventory exchange"},{"location":"protocol/network/messages/inventory/#inventory-exchange","text":"The inventory exchange protocol describes the interaction between nodes in order to synchronize themselves with the network and reestablish the full blockchain (in terms of blocks and transactions). Inventory exchanges envision 2 main scenarios: Block Download , for nodes in need of synchronizing their blockchains by requesting and downloading blocks. Inventory Broadcasting , for nodes willing to broadcast transactional information, such as blocks and transactions.","title":"Inventory Exchange"},{"location":"protocol/network/messages/inventory/#block-download","text":"Block Download is performed by nodes that need to catch up with other nodes by downloading missing blocks in order to reconstruct their blockchains. For example, this is the case of nodes connecting to the blockchain for the first time or after a significant amount of downtime. Starting from the block #0 (the hardcoded genesis block), the nodes need to validate all blocks up to the current tip of the blockchain. Therefore, in case of missing blocks, a local node will initiate the following process of synchronization with its outbound peers: The local node will have already exchanged Version messages with its remote outbound peers. Those Version messages contain the last epoch known to others peers, i.e. the local peer can already compare how many blocks they each have and identify how many are missing. The local node will send a LastBeacon message to all its outbound nodes (after successful handshake protocol). These messages contain the hash of the top block of the local blockchain and the epoch of that block. Remote peers will reply by sending another LastBeacon message containing the hash of the top block of their respective blockchains and the epochs for those top blocks. The peer with the longest blockchain will identify which blocks are required by the other peer in order to allow it to synchronize to its blockchain. The peer will select up to the first consecutive 500 blocks and it will transmit their hashes using an InventoryAnnouncement message. After identifying which blocks are missing (it may already have some of them), the node may request them by using a InventoryRequest message, containing the hashes of the needed blocks. This message will help the node to catch up with the current full blockchain. After receiving the InventoryRequest message, the peer sends the requested blocks individually by using Block messages. The following diagram depicts the previously described process under the assumption that the peer with the longest blockchain is NodeB (step 4). NodeA NodeB + + | LAST_BEACON | +--------------------------->+ | LAST_BEACON | +<---------------------------+ | INVENTORY_ANNOUNCEMENT | +<---------------------------+ | | | | | INVENTORY_REQUEST | +--------------------------->+ | BLOCK | +<-------------------------- + | BLOCK | +<-------------------------- + | BLOCK | +<---------------------------+ | | + +","title":"Block Download"},{"location":"protocol/network/messages/inventory/#inventory-broadcasting","text":"Similarly to the previously described process of synchronization, any node may contribute to the synchronization of their outbound peers by advertising inventory objects such as blocks and transactions. Inventory broadcasting is also used in case a node creates transactions or mine blocks. The inventory broadcasting can be described as the following sequence of steps: A remote node broadcasts its inventory by sending an InventoryAnnouncement message, containing all the hashes of the advertised inventory objects. After receiving an InventoryAnnouncement message and filtering the inventory objects that may be missing in the local blockchain, the local node sends a InventoryRequest message with the hashes of the needed objects. The remote note receives the InventoryRequest message and sends a Block or Transaction message per requested inventory object (identified by a hash). The following diagram depicts the previous step under the assumption that the local node ( NodeA ) sends a InventoryRequest message requesting 3 blocks and 2 transactions. NodeA NodeB + + | INVENTORY_ANNOUNCEMENT | +<-------------------------------+ | | | INVENTORY_REQUEST | +------------------------------->+ | | | BLOCK | +<-------------------------------+ | BLOCK | +<-------------------------------+ | BLOCK | +<-------------------------------+ | TRANSACTION | +<-------------------------------+ | TRANSACTION | +<-------------------------------+ | | + +","title":"Inventory Broadcasting"},{"location":"protocol/network/messages/inventory/#lastbeacon-message","text":"The LastBeacon messages are used in order to notify the hash of the highest known block by the peer together with its epoch. After exchanging LastBeacon messages between peers, the one with the longest blockchain in terms of blocks will send an InventoryAnnouncement message to the other peer. This message will include the list of block hashes starting right after the last known block hash provided by the other peer. The LastBeacon message consists of a message header with the LastBeacon command and a payload containing the beacon for the tip of the chain (the hash of the latest block and its checkpoint) as known to the local peer: Field Type Description highest_block_checkpoint CheckpointBeacon Last beacon (checkpoint + hash) The checkpoint beacon ( CheckpointBeacon ) is composed of the following fields: Field Type Description checkpoint fixed32 The serial number for this epoch hash_prev_block Hash The 256-bit hash of the previous block","title":"LastBeacon message"},{"location":"protocol/network/messages/inventory/#inventoryannouncement-message","text":"The InventoryAnnouncement message is used to advertise the knowledge of one or more objects (e.g. blocks, transactions, ...). The inventory message can be received unsolicited or in reply to a LastBeacon message. The InventoryAnnouncement message consists of a message header with the InventoryAnnouncement command and a payload containing one or more inventory entries: Field Type Description inventory inventory_entry[] Vector of inventory entries","title":"InventoryAnnouncement message"},{"location":"protocol/network/messages/inventory/#inventoryrequest-message","text":"The InventoryRequest messages are used in order to request specific objects from other nodes. Usually, InventoryRequest messages are sent after receiving a InventoryAnnouncement message and filtering the already known objects. The response to a InventoryRequest message is often one or more messages carrying the requested objects (e.g.: Block , Transaction , etc.). The InventoryRequest message consists of a message header with the InventoryRequest command and a payload following this format: Field Type Description inventory repeated InventoryEntry Inventory entries that are being requested","title":"InventoryRequest message"},{"location":"protocol/network/messages/inventory/#block-message","text":"The Block message is used to transmit a single serialized block as a response to a InventoryRequest message. The Block message consists of a message header with the Block command and a payload containing information for a block following the format defined in the Block section.","title":"Block message"},{"location":"protocol/network/messages/inventory/#transaction-message","text":"Analogously, the Transaction message is used to transmit a single serialized transaction as a response to a InventoryRequest message. The Transaction message consists of a message header with the Transaction command and a payload containing information for a transaction following the format defined in the Transaction section.","title":"Transaction message"},{"location":"protocol/network/messages/inventory/#helper-data-structures","text":"","title":"Helper data structures"},{"location":"protocol/network/messages/inventory/#hash","text":"The hash ( Hash ) data structure is a tagged union of the supported hashing algorithms: Kind Description SHA256 SHA256 hash type (32 bytes) In the future, the type values may be extended in order to consider additional hash types.","title":"Hash"},{"location":"protocol/network/messages/inventory/#inventoryentry","text":"The InventoryEntry data structure is a tagged union of the different inventory item types: Kind Description Error Data with this number may be ignored Tx Hash is related to a transaction Block Hash is related to a block DataRequest Hash is related to a data request DataResult Hash is related to the result of a data request Each type has one field: Field Type Description hash Hash The hash of this item In the future, the type values may be extended in order to consider additional features.","title":"InventoryEntry"},{"location":"protocol/network/messages/overview/","text":"Messages \u00b6 All Witnet network protocol messages include a message header identifying which message type is being sent and a command-specific payload. Message Header \u00b6 The message header format is composed of the following fields: Field Type Description magic uint32 Magic value indicating message origin network command Command Message being sent from a predefined list of available commands The command must be one message type from the current available commands defined in the Witnet network protocol: Version Verack GetPeers Peers Ping Pong Block InventoryAnnouncement InventoryRequest LastBeacon Transaction Available commands are detailed in the consecutive sections: Handshake Peer discovery Heartbeat Inventory","title":"Overview"},{"location":"protocol/network/messages/overview/#messages","text":"All Witnet network protocol messages include a message header identifying which message type is being sent and a command-specific payload.","title":"Messages"},{"location":"protocol/network/messages/overview/#message-header","text":"The message header format is composed of the following fields: Field Type Description magic uint32 Magic value indicating message origin network command Command Message being sent from a predefined list of available commands The command must be one message type from the current available commands defined in the Witnet network protocol: Version Verack GetPeers Peers Ping Pong Block InventoryAnnouncement InventoryRequest LastBeacon Transaction Available commands are detailed in the consecutive sections: Handshake Peer discovery Heartbeat Inventory","title":"Message Header"},{"location":"protocol/network/messages/peer-discovery/","text":"Peer discovery \u00b6 Peer discovery protocol allows nodes to exchange information of known peers to other nodes. This information may be used by peer discovery algorithms. Nodes may request to their outbound peers for a list of their known \"recent\" peers. This request is initiated by sending a GetPeers message to a remote peer. The receiving node will reply a Peers message with a list of peer addresses that have been recently seen active in the network (e.g. peers that sent at least a message in the last 90 minutes). Usually, the transmitting node will then update its local list of peer addresses accordingly. NodeA NodeB + + | GET_PEERS | +------------------------------->+ | PEERS | +<-------------------------------+ | | + + Get peers message \u00b6 The GetPeers message has no payload. Peers message \u00b6 The Peers message has a payload containing a list of known peers as: Field Type Description peers repeated Address List of IP addresses of active known peers, as described in the IP address section","title":"Peer Discovery"},{"location":"protocol/network/messages/peer-discovery/#peer-discovery","text":"Peer discovery protocol allows nodes to exchange information of known peers to other nodes. This information may be used by peer discovery algorithms. Nodes may request to their outbound peers for a list of their known \"recent\" peers. This request is initiated by sending a GetPeers message to a remote peer. The receiving node will reply a Peers message with a list of peer addresses that have been recently seen active in the network (e.g. peers that sent at least a message in the last 90 minutes). Usually, the transmitting node will then update its local list of peer addresses accordingly. NodeA NodeB + + | GET_PEERS | +------------------------------->+ | PEERS | +<-------------------------------+ | | + +","title":"Peer discovery"},{"location":"protocol/network/messages/peer-discovery/#get-peers-message","text":"The GetPeers message has no payload.","title":"Get peers message"},{"location":"protocol/network/messages/peer-discovery/#peers-message","text":"The Peers message has a payload containing a list of known peers as: Field Type Description peers repeated Address List of IP addresses of active known peers, as described in the IP address section","title":"Peers message"}]}